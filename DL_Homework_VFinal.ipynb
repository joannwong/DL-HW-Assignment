{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRSPmZBMmt4P"
      },
      "source": [
        "## Mobile Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rDpSD_I3mrxW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Block(nn.Module):\n",
        "    '''Depthwise conv + Pointwise conv'''\n",
        "    def __init__(self, in_planes, out_planes, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        return out\n",
        "\n",
        "\n",
        "class MobileNet(nn.Module):\n",
        "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
        "    cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(MobileNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.layers = self._make_layers(in_planes=32)\n",
        "        self.linear = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def _make_layers(self, in_planes):\n",
        "        layers = []\n",
        "        for x in self.cfg:\n",
        "            out_planes = x if isinstance(x, int) else x[0]\n",
        "            stride = 1 if isinstance(x, int) else x[1]\n",
        "            layers.append(Block(in_planes, out_planes, stride))\n",
        "            in_planes = out_planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layers(out)\n",
        "        out = F.avg_pool2d(out, 2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIniJbfum2sQ"
      },
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p48mqrAkm5rJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "os.makedirs('/content/diagram', exist_ok=True)\n",
        "\n",
        "def plot_loss_acc(train_loss, val_loss, train_acc, val_acc, fig_name):\n",
        "    x = np.arange(len(train_loss))\n",
        "    max_loss = max(max(train_loss), max(val_loss))\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "    ax1.set_xlabel('epoch')\n",
        "    ax1.set_ylabel('loss')\n",
        "    ax1.set_ylim([0,max_loss+1])\n",
        "    lns1 = ax1.plot(x, train_loss, 'yo-', label='train_loss')\n",
        "    lns2 = ax1.plot(x, val_loss, 'go-', label='val_loss')\n",
        "    # ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.set_ylabel('accuracy')\n",
        "    ax2.set_ylim([0,1])\n",
        "    lns3 = ax2.plot(x, train_acc, 'bo-', label='train_acc')\n",
        "    lns4 = ax2.plot(x, val_acc, 'ro-', label='val_acc')\n",
        "    # ax2.tick_params(axis='y', labelcolor='tab:red')\n",
        "\n",
        "    lns = lns1+lns2+lns3+lns4\n",
        "    labs = [l.get_label() for l in lns]\n",
        "    ax2.legend(lns, labs, loc=0)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.title(fig_name)\n",
        "\n",
        "    plt.savefig(os.path.join('/content/diagram', fig_name))\n",
        "    np.savez(os.path.join('/content/diagram', fig_name.replace('.png', '.npz')), train_loss=train_loss, val_loss=val_loss, train_acc=train_acc, val_acc=val_acc)\n",
        "\n",
        "\n",
        "    #plt.savefig(os.path.join('./diagram', fig_name))\n",
        "    #np.savez(os.path.join('./diagram', fig_name.replace('.png ', '.npz')), train_loss=train_loss, val_loss=val_loss, train_acc=train_acc, val_acc=val_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxwHMZ9HnXUg"
      },
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FeL7tp7o3SCR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set CUBLAS_WORKSPACE_CONFIG environment variable\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':16:8'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Cnbuwzzznb2b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7zQ53CPXnusS"
      },
      "outputs": [],
      "source": [
        "# fix random seeds\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.use_deterministic_algorithms(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nebwS-Lood1D"
      },
      "outputs": [],
      "source": [
        "# train val test\n",
        "# AI6103 students: You need to create the dataloaders youself\n",
        "\n",
        "#train_loader, valid_loader = get_train_valid_loader(args.dataset_dir, args.batch_size, True, args.seed, save_images=args.save_images)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KxUkgD1FrkBq"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3sm2QAYo_7j",
        "outputId": "3851cb7d-dd4d-40f6-eb92-f0161deca109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Split data set\n",
        "dataset = torchvision.datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(0.8 * num_train))  # 80% for training, 20% for validation\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[:split], indices[split:]\n",
        "\n",
        "train_sampler = data.sampler.SubsetRandomSampler(train_indices)\n",
        "val_sampler = data.sampler.SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=val_sampler)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyLBFDM-rICz",
        "outputId": "51277e90-afd3-4120-8abf-eb7fffa2b7a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of each class in the new training set:\n",
            "Class 0: 0.0103\n",
            "Class 1: 0.0104\n",
            "Class 2: 0.0098\n",
            "Class 3: 0.0099\n",
            "Class 4: 0.0099\n",
            "Class 5: 0.0101\n",
            "Class 6: 0.0100\n",
            "Class 7: 0.0097\n",
            "Class 8: 0.0103\n",
            "Class 9: 0.0099\n",
            "Class 10: 0.0097\n",
            "Class 11: 0.0101\n",
            "Class 12: 0.0102\n",
            "Class 13: 0.0096\n",
            "Class 14: 0.0097\n",
            "Class 15: 0.0101\n",
            "Class 16: 0.0098\n",
            "Class 17: 0.0101\n",
            "Class 18: 0.0098\n",
            "Class 19: 0.0099\n",
            "Class 20: 0.0100\n",
            "Class 21: 0.0097\n",
            "Class 22: 0.0100\n",
            "Class 23: 0.0099\n",
            "Class 24: 0.0103\n",
            "Class 25: 0.0100\n",
            "Class 26: 0.0101\n",
            "Class 27: 0.0102\n",
            "Class 28: 0.0098\n",
            "Class 29: 0.0097\n",
            "Class 30: 0.0100\n",
            "Class 31: 0.0097\n",
            "Class 32: 0.0103\n",
            "Class 33: 0.0099\n",
            "Class 34: 0.0104\n",
            "Class 35: 0.0097\n",
            "Class 36: 0.0099\n",
            "Class 37: 0.0101\n",
            "Class 38: 0.0100\n",
            "Class 39: 0.0103\n",
            "Class 40: 0.0101\n",
            "Class 41: 0.0098\n",
            "Class 42: 0.0099\n",
            "Class 43: 0.0098\n",
            "Class 44: 0.0102\n",
            "Class 45: 0.0096\n",
            "Class 46: 0.0101\n",
            "Class 47: 0.0101\n",
            "Class 48: 0.0103\n",
            "Class 49: 0.0100\n",
            "Class 50: 0.0097\n",
            "Class 51: 0.0100\n",
            "Class 52: 0.0100\n",
            "Class 53: 0.0103\n",
            "Class 54: 0.0100\n",
            "Class 55: 0.0095\n",
            "Class 56: 0.0097\n",
            "Class 57: 0.0099\n",
            "Class 58: 0.0099\n",
            "Class 59: 0.0101\n",
            "Class 60: 0.0100\n",
            "Class 61: 0.0099\n",
            "Class 62: 0.0097\n",
            "Class 63: 0.0101\n",
            "Class 64: 0.0098\n",
            "Class 65: 0.0103\n",
            "Class 66: 0.0102\n",
            "Class 67: 0.0102\n",
            "Class 68: 0.0103\n",
            "Class 69: 0.0100\n",
            "Class 70: 0.0103\n",
            "Class 71: 0.0104\n",
            "Class 72: 0.0098\n",
            "Class 73: 0.0094\n",
            "Class 74: 0.0103\n",
            "Class 75: 0.0101\n",
            "Class 76: 0.0101\n",
            "Class 77: 0.0096\n",
            "Class 78: 0.0099\n",
            "Class 79: 0.0101\n",
            "Class 80: 0.0099\n",
            "Class 81: 0.0098\n",
            "Class 82: 0.0104\n",
            "Class 83: 0.0100\n",
            "Class 84: 0.0103\n",
            "Class 85: 0.0104\n",
            "Class 86: 0.0104\n",
            "Class 87: 0.0095\n",
            "Class 88: 0.0101\n",
            "Class 89: 0.0098\n",
            "Class 90: 0.0102\n",
            "Class 91: 0.0103\n",
            "Class 92: 0.0097\n",
            "Class 93: 0.0096\n",
            "Class 94: 0.0103\n",
            "Class 95: 0.0099\n",
            "Class 96: 0.0099\n",
            "Class 97: 0.0103\n",
            "Class 98: 0.0100\n",
            "Class 99: 0.0100\n"
          ]
        }
      ],
      "source": [
        "# Show proportion of each class in new training set\n",
        "num_classes = 100\n",
        "class_counts = {class_label: 0 for class_label in range(num_classes)}\n",
        "for idx in train_indices:\n",
        "    _, label = dataset[idx]\n",
        "    class_counts[label] += 1\n",
        "\n",
        "total_samples = len(train_indices)\n",
        "class_proportions = {class_label: count / total_samples for class_label, count in class_counts.items()}\n",
        "\n",
        "print(\"Proportion of each class in the new training set:\")\n",
        "for class_label, proportion in class_proportions.items():\n",
        "    print(f\"Class {class_label}: {proportion:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJxlL5JnsASm",
        "outputId": "fe0b629c-12ce-4c8e-d994-a1f609b8c61b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean - R: 0.5071, G: 0.4865, B: 0.4409\n",
            "Std Dev - R: 0.2673, G: 0.2564, B: 0.2762\n"
          ]
        }
      ],
      "source": [
        "# Compute mean & sd for each colour on the training set\n",
        "imgs = [item[0] for item in dataset] # item[0] and item[1] are image and its label\n",
        "imgs = torch.stack(imgs, dim=0).numpy()\n",
        "\n",
        "# Calculate mean over each channel (r,g,b)\n",
        "mean_r = imgs[:,0,:,:].mean()\n",
        "mean_g = imgs[:,1,:,:].mean()\n",
        "mean_b = imgs[:,2,:,:].mean()\n",
        "\n",
        "# Calculate std over each channel (r,g,b)\n",
        "std_r = imgs[:,0,:,:].std()\n",
        "std_g = imgs[:,1,:,:].std()\n",
        "std_b = imgs[:,2,:,:].std()\n",
        "\n",
        "print(f\"Mean - R: {mean_r:.4f}, G: {mean_g:.4f}, B: {mean_b:.4f}\")\n",
        "print(f\"Std Dev - R: {std_r:.4f}, G: {std_g:.4f}, B: {std_b:.4f}\")\n",
        "# Mean - R: 0.5071, G: 0.4865, B: 0.4409\n",
        "# Std Dev - R: 0.2673, G: 0.2564, B: 0.2762\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXXn4niHzGYO"
      },
      "source": [
        "## Learning Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR = 0.5"
      ],
      "metadata": {
        "id": "72WGlYC1e4xQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ltNaiprkvLeB"
      },
      "outputs": [],
      "source": [
        "lr = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvNhz8FEskkd",
        "outputId": "04a6b4a5-895c-494c-98cd-625ab90d30b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNet(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Block(\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): Block(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): Block(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): Block(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): Block(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (5): Block(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (6): Block(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (7): Block(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (8): Block(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (9): Block(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (10): Block(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (11): Block(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (12): Block(\n",
            "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=1024, out_features=100, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNet(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layers): Sequential(\n",
              "    (0): Block(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): Block(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): Block(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): Block(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): Block(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): Block(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (6): Block(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (7): Block(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (8): Block(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (9): Block(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (10): Block(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (11): Block(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (12): Block(\n",
              "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=1024, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# model\n",
        "model = MobileNet(100)\n",
        "print(model)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EaetXhYAurWL"
      },
      "outputs": [],
      "source": [
        "# criterion\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ivHXO-oBwVb9"
      },
      "outputs": [],
      "source": [
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9) #, weight_decay=args.wd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VXNLp5fWw07I"
      },
      "outputs": [],
      "source": [
        "stat_training_loss = []\n",
        "stat_val_loss = []\n",
        "stat_training_acc = []\n",
        "stat_val_acc = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFJDyXWLwNtC",
        "outputId": "8fdcdf85-91cd-47b5-9387-4ddb6c3789e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15.. Train Loss: 4.5012.. Train Acc: 0.0269.. Validation Loss: 4.2123.. Validation Acc: 0.0470\n",
            "Epoch 2/15.. Train Loss: 4.0277.. Train Acc: 0.0631.. Validation Loss: 3.9128.. Validation Acc: 0.0763\n",
            "Epoch 3/15.. Train Loss: 3.8091.. Train Acc: 0.0931.. Validation Loss: 3.7691.. Validation Acc: 0.1105\n",
            "Epoch 4/15.. Train Loss: 3.6187.. Train Acc: 0.1234.. Validation Loss: 3.6212.. Validation Acc: 0.1228\n",
            "Epoch 5/15.. Train Loss: 3.4626.. Train Acc: 0.1536.. Validation Loss: 3.4932.. Validation Acc: 0.1496\n",
            "Epoch 6/15.. Train Loss: 3.3029.. Train Acc: 0.1812.. Validation Loss: 3.2750.. Validation Acc: 0.1895\n",
            "Epoch 7/15.. Train Loss: 3.1460.. Train Acc: 0.2091.. Validation Loss: 3.3107.. Validation Acc: 0.1891\n",
            "Epoch 8/15.. Train Loss: 2.9961.. Train Acc: 0.2362.. Validation Loss: 2.9719.. Validation Acc: 0.2434\n",
            "Epoch 9/15.. Train Loss: 2.8597.. Train Acc: 0.2621.. Validation Loss: 2.9461.. Validation Acc: 0.2528\n",
            "Epoch 10/15.. Train Loss: 2.7439.. Train Acc: 0.2853.. Validation Loss: 2.8693.. Validation Acc: 0.2695\n",
            "Epoch 11/15.. Train Loss: 2.6440.. Train Acc: 0.3061.. Validation Loss: 2.8362.. Validation Acc: 0.2844\n",
            "Epoch 12/15.. Train Loss: 2.5368.. Train Acc: 0.3290.. Validation Loss: 3.5079.. Validation Acc: 0.3047\n",
            "Epoch 13/15.. Train Loss: 2.4509.. Train Acc: 0.3483.. Validation Loss: 2.5892.. Validation Acc: 0.3311\n",
            "Epoch 14/15.. Train Loss: 2.3629.. Train Acc: 0.3666.. Validation Loss: 2.6029.. Validation Acc: 0.3305\n",
            "Epoch 15/15.. Train Loss: 2.2838.. Train Acc: 0.3842.. Validation Loss: 2.5648.. Validation Acc: 0.3359\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(15):\n",
        "    training_loss = 0\n",
        "    training_acc = 0\n",
        "    training_samples = 0\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    val_samples = 0\n",
        "    # training\n",
        "    model.train()\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "        optimizer.zero_grad()\n",
        "        logits = model.forward(imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, top_class = logits.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape).long()\n",
        "        training_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        training_loss += batch_size * loss.item()\n",
        "        training_samples += batch_size\n",
        "    # validation\n",
        "    model.eval()\n",
        "    for val_imgs, val_labels in valid_loader:\n",
        "        batch_size = val_imgs.shape[0]\n",
        "        val_logits = model.forward(val_imgs.cuda())\n",
        "        loss = criterion(val_logits, val_labels.cuda())\n",
        "        _, top_class = val_logits.topk(1, dim=1)\n",
        "        equals = top_class == val_labels.cuda().view(*top_class.shape)\n",
        "        val_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        val_loss += batch_size * loss.item()\n",
        "        val_samples += batch_size\n",
        "    assert val_samples == 10000\n",
        "    # update stats\n",
        "    stat_training_loss.append(training_loss/training_samples)\n",
        "    stat_val_loss.append(val_loss/val_samples)\n",
        "    stat_training_acc.append(training_acc/training_samples)\n",
        "    stat_val_acc.append(val_acc/val_samples)\n",
        "    # print\n",
        "    #print(f\"Epoch {(epoch+1):d}/{args.epochs:d}.. Learning rate: {scheduler.get_lr()[0]:.4f}.. Train loss: {(training_loss/training_samples):.4f}.. Train acc: {(training_acc/training_samples):.4f}.. Val loss: {(val_loss/val_samples):.4f}.. Val acc: {(val_acc/val_samples):.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{15}.. \"\n",
        "          f\"Train Loss: {training_loss / training_samples:.4f}.. \"\n",
        "          f\"Train Acc: {training_acc / training_samples:.4f}.. \"\n",
        "          f\"Validation Loss: {val_loss / val_samples:.4f}.. \"\n",
        "          f\"Validation Acc: {val_acc / val_samples:.4f}\")\n",
        "    # lr scheduler\n",
        "    ###scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8gwmkyF7xHuR"
      },
      "outputs": [],
      "source": [
        "plot_loss_acc(stat_training_loss, stat_val_loss, stat_training_acc, stat_val_acc, \"LR_one\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR = 0.05"
      ],
      "metadata": {
        "id": "XVKh3cAfe2oX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3t1DkYwuxHGt"
      },
      "outputs": [],
      "source": [
        "lr = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])\n",
        "    ])\n",
        "\n",
        "# Split data set\n",
        "dataset = torchvision.datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(0.8 * num_train))  # 80% for training, 20% for validation\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[:split], indices[split:]\n",
        "\n",
        "train_sampler = data.sampler.SubsetRandomSampler(train_indices)\n",
        "val_sampler = data.sampler.SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=val_sampler)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqCRIwTUkOly",
        "outputId": "03a27226-6f36-4e6f-b66e-8e0edd5978de"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = MobileNet(100)\n",
        "#print(model)\n",
        "model.cuda()\n",
        "\n",
        "# criterion\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9) #, weight_decay=args.wd)"
      ],
      "metadata": {
        "id": "SokyLDODfpMe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stat_training_loss = []\n",
        "stat_val_loss = []\n",
        "stat_training_acc = []\n",
        "stat_val_acc = []"
      ],
      "metadata": {
        "id": "eTNZuxlXfpGs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(15):\n",
        "    training_loss = 0\n",
        "    training_acc = 0\n",
        "    training_samples = 0\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    val_samples = 0\n",
        "    # training\n",
        "    model.train()\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "        optimizer.zero_grad()\n",
        "        logits = model.forward(imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, top_class = logits.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape).long()\n",
        "        training_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        training_loss += batch_size * loss.item()\n",
        "        training_samples += batch_size\n",
        "    # validation\n",
        "    model.eval()\n",
        "    for val_imgs, val_labels in valid_loader:\n",
        "        batch_size = val_imgs.shape[0]\n",
        "        val_logits = model.forward(val_imgs.cuda())\n",
        "        loss = criterion(val_logits, val_labels.cuda())\n",
        "        _, top_class = val_logits.topk(1, dim=1)\n",
        "        equals = top_class == val_labels.cuda().view(*top_class.shape)\n",
        "        val_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        val_loss += batch_size * loss.item()\n",
        "        val_samples += batch_size\n",
        "    assert val_samples == 10000\n",
        "    # update stats\n",
        "    stat_training_loss.append(training_loss/training_samples)\n",
        "    stat_val_loss.append(val_loss/val_samples)\n",
        "    stat_training_acc.append(training_acc/training_samples)\n",
        "    stat_val_acc.append(val_acc/val_samples)\n",
        "    # print\n",
        "    #print(f\"Epoch {(epoch+1):d}/{args.epochs:d}.. Learning rate: {scheduler.get_lr()[0]:.4f}.. Train loss: {(training_loss/training_samples):.4f}.. Train acc: {(training_acc/training_samples):.4f}.. Val loss: {(val_loss/val_samples):.4f}.. Val acc: {(val_acc/val_samples):.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{15}.. \"\n",
        "          f\"Train Loss: {training_loss / training_samples:.4f}.. \"\n",
        "          f\"Train Acc: {training_acc / training_samples:.4f}.. \"\n",
        "          f\"Validation Loss: {val_loss / val_samples:.4f}.. \"\n",
        "          f\"Validation Acc: {val_acc / val_samples:.4f}\")\n",
        "    # lr scheduler\n",
        "    ###scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izhL2E1SmfRO",
        "outputId": "39fd676d-b21d-4e9f-b11b-c6c0fa3f983d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15.. Train Loss: 4.1525.. Train Acc: 0.0664.. Validation Loss: 3.7698.. Validation Acc: 0.1101\n",
            "Epoch 2/15.. Train Loss: 3.5902.. Train Acc: 0.1405.. Validation Loss: 3.4755.. Validation Acc: 0.1536\n",
            "Epoch 3/15.. Train Loss: 3.3143.. Train Acc: 0.1855.. Validation Loss: 3.2867.. Validation Acc: 0.1998\n",
            "Epoch 4/15.. Train Loss: 3.0882.. Train Acc: 0.2297.. Validation Loss: 3.0820.. Validation Acc: 0.2382\n",
            "Epoch 5/15.. Train Loss: 2.9033.. Train Acc: 0.2644.. Validation Loss: 4.0107.. Validation Acc: 0.2283\n",
            "Epoch 6/15.. Train Loss: 2.7227.. Train Acc: 0.2968.. Validation Loss: 2.7643.. Validation Acc: 0.2963\n",
            "Epoch 7/15.. Train Loss: 2.5423.. Train Acc: 0.3344.. Validation Loss: 2.6880.. Validation Acc: 0.3066\n",
            "Epoch 8/15.. Train Loss: 2.3804.. Train Acc: 0.3682.. Validation Loss: 2.7127.. Validation Acc: 0.3087\n",
            "Epoch 9/15.. Train Loss: 2.2568.. Train Acc: 0.3928.. Validation Loss: 2.4210.. Validation Acc: 0.3681\n",
            "Epoch 10/15.. Train Loss: 2.1349.. Train Acc: 0.4200.. Validation Loss: 2.3538.. Validation Acc: 0.3894\n",
            "Epoch 11/15.. Train Loss: 2.0276.. Train Acc: 0.4459.. Validation Loss: 2.2620.. Validation Acc: 0.4019\n",
            "Epoch 12/15.. Train Loss: 1.9306.. Train Acc: 0.4669.. Validation Loss: 2.2165.. Validation Acc: 0.4161\n",
            "Epoch 13/15.. Train Loss: 1.8439.. Train Acc: 0.4895.. Validation Loss: 2.1325.. Validation Acc: 0.4334\n",
            "Epoch 14/15.. Train Loss: 1.7620.. Train Acc: 0.5063.. Validation Loss: 2.1322.. Validation Acc: 0.4329\n",
            "Epoch 15/15.. Train Loss: 1.6899.. Train Acc: 0.5244.. Validation Loss: 2.0479.. Validation Acc: 0.4597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_acc(stat_training_loss, stat_val_loss, stat_training_acc, stat_val_acc, \"LR_two\")"
      ],
      "metadata": {
        "id": "OgYETTn3k7fc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR = 0.01"
      ],
      "metadata": {
        "id": "FiCbYNRUfrgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01"
      ],
      "metadata": {
        "id": "nO7yHuetfo9h"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])\n",
        "    ])\n",
        "\n",
        "# Split data set\n",
        "dataset = torchvision.datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(0.8 * num_train))  # 80% for training, 20% for validation\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[:split], indices[split:]\n",
        "\n",
        "train_sampler = data.sampler.SubsetRandomSampler(train_indices)\n",
        "val_sampler = data.sampler.SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=val_sampler)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv7Dmsqcfn-i",
        "outputId": "d76c013a-9efa-48fd-d38e-6572e5f70449"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = MobileNet(100)\n",
        "#print(model)\n",
        "model.cuda()\n",
        "\n",
        "# criterion\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9) #, weight_decay=args.wd)"
      ],
      "metadata": {
        "id": "whXLlqhmj6Or"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stat_training_loss = []\n",
        "stat_val_loss = []\n",
        "stat_training_acc = []\n",
        "stat_val_acc = []"
      ],
      "metadata": {
        "id": "4RO30__-j6GX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(15):\n",
        "    training_loss = 0\n",
        "    training_acc = 0\n",
        "    training_samples = 0\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    val_samples = 0\n",
        "    # training\n",
        "    model.train()\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "        optimizer.zero_grad()\n",
        "        logits = model.forward(imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, top_class = logits.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape).long()\n",
        "        training_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        training_loss += batch_size * loss.item()\n",
        "        training_samples += batch_size\n",
        "    # validation\n",
        "    model.eval()\n",
        "    for val_imgs, val_labels in valid_loader:\n",
        "        batch_size = val_imgs.shape[0]\n",
        "        val_logits = model.forward(val_imgs.cuda())\n",
        "        loss = criterion(val_logits, val_labels.cuda())\n",
        "        _, top_class = val_logits.topk(1, dim=1)\n",
        "        equals = top_class == val_labels.cuda().view(*top_class.shape)\n",
        "        val_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        val_loss += batch_size * loss.item()\n",
        "        val_samples += batch_size\n",
        "    assert val_samples == 10000\n",
        "    # update stats\n",
        "    stat_training_loss.append(training_loss/training_samples)\n",
        "    stat_val_loss.append(val_loss/val_samples)\n",
        "    stat_training_acc.append(training_acc/training_samples)\n",
        "    stat_val_acc.append(val_acc/val_samples)\n",
        "    # print\n",
        "    #print(f\"Epoch {(epoch+1):d}/{args.epochs:d}.. Learning rate: {scheduler.get_lr()[0]:.4f}.. Train loss: {(training_loss/training_samples):.4f}.. Train acc: {(training_acc/training_samples):.4f}.. Val loss: {(val_loss/val_samples):.4f}.. Val acc: {(val_acc/val_samples):.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{15}.. \"\n",
        "          f\"Train Loss: {training_loss / training_samples:.4f}.. \"\n",
        "          f\"Train Acc: {training_acc / training_samples:.4f}.. \"\n",
        "          f\"Validation Loss: {val_loss / val_samples:.4f}.. \"\n",
        "          f\"Validation Acc: {val_acc / val_samples:.4f}\")\n",
        "    # lr scheduler\n",
        "    ###scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moEVKqQUqXpz",
        "outputId": "d8bc4f2f-548e-4e0b-8f9c-803226d1687f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15.. Train Loss: 4.4138.. Train Acc: 0.0367.. Validation Loss: 4.1165.. Validation Acc: 0.0679\n",
            "Epoch 2/15.. Train Loss: 3.8177.. Train Acc: 0.1046.. Validation Loss: 3.7017.. Validation Acc: 0.1211\n",
            "Epoch 3/15.. Train Loss: 3.5324.. Train Acc: 0.1509.. Validation Loss: 3.4444.. Validation Acc: 0.1672\n",
            "Epoch 4/15.. Train Loss: 3.3317.. Train Acc: 0.1862.. Validation Loss: 3.3077.. Validation Acc: 0.1922\n",
            "Epoch 5/15.. Train Loss: 3.1623.. Train Acc: 0.2167.. Validation Loss: 3.2426.. Validation Acc: 0.2023\n",
            "Epoch 6/15.. Train Loss: 3.0101.. Train Acc: 0.2456.. Validation Loss: 3.0559.. Validation Acc: 0.2402\n",
            "Epoch 7/15.. Train Loss: 2.8894.. Train Acc: 0.2683.. Validation Loss: 2.9872.. Validation Acc: 0.2614\n",
            "Epoch 8/15.. Train Loss: 2.7633.. Train Acc: 0.2929.. Validation Loss: 2.8639.. Validation Acc: 0.2780\n",
            "Epoch 9/15.. Train Loss: 2.6483.. Train Acc: 0.3164.. Validation Loss: 2.7736.. Validation Acc: 0.3052\n",
            "Epoch 10/15.. Train Loss: 2.5364.. Train Acc: 0.3378.. Validation Loss: 2.6961.. Validation Acc: 0.3131\n",
            "Epoch 11/15.. Train Loss: 2.4328.. Train Acc: 0.3577.. Validation Loss: 2.6120.. Validation Acc: 0.3324\n",
            "Epoch 12/15.. Train Loss: 2.3280.. Train Acc: 0.3826.. Validation Loss: 2.5655.. Validation Acc: 0.3369\n",
            "Epoch 13/15.. Train Loss: 2.2279.. Train Acc: 0.4042.. Validation Loss: 2.5240.. Validation Acc: 0.3565\n",
            "Epoch 14/15.. Train Loss: 2.1358.. Train Acc: 0.4244.. Validation Loss: 2.4682.. Validation Acc: 0.3643\n",
            "Epoch 15/15.. Train Loss: 2.0523.. Train Acc: 0.4436.. Validation Loss: 2.4157.. Validation Acc: 0.3747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_acc(stat_training_loss, stat_val_loss, stat_training_acc, stat_val_acc, \"LR_three\")"
      ],
      "metadata": {
        "id": "Mv08NpZLqXnL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate Schedule"
      ],
      "metadata": {
        "id": "EOBtJQUFxXU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR = 0.05, epochs = 300, all other settings & hyperparameters unchanged"
      ],
      "metadata": {
        "id": "R3EGPnryGUg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.05"
      ],
      "metadata": {
        "id": "b9b4WvAFqfcN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])\n",
        "    ])\n",
        "\n",
        "# Split data set\n",
        "dataset = torchvision.datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(0.8 * num_train))  # 80% for training, 20% for validation\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[:split], indices[split:]\n",
        "\n",
        "train_sampler = data.sampler.SubsetRandomSampler(train_indices)\n",
        "val_sampler = data.sampler.SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=val_sampler)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieWGq_D9qfZn",
        "outputId": "efd54f9d-c658-4863-baac-788451bd11b5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = MobileNet(100)\n",
        "#print(model)\n",
        "model.cuda()\n",
        "\n",
        "# criterion\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9) #, weight_decay=args.wd)"
      ],
      "metadata": {
        "id": "hVFHquMyx7wy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stat_training_loss = []\n",
        "stat_val_loss = []\n",
        "stat_training_acc = []\n",
        "stat_val_acc = []"
      ],
      "metadata": {
        "id": "gT8iQzNnx7ry"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(300):\n",
        "    training_loss = 0\n",
        "    training_acc = 0\n",
        "    training_samples = 0\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    val_samples = 0\n",
        "    # training\n",
        "    model.train()\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "        optimizer.zero_grad()\n",
        "        logits = model.forward(imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, top_class = logits.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape).long()\n",
        "        training_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        training_loss += batch_size * loss.item()\n",
        "        training_samples += batch_size\n",
        "    # validation\n",
        "    model.eval()\n",
        "    for val_imgs, val_labels in valid_loader:\n",
        "        batch_size = val_imgs.shape[0]\n",
        "        val_logits = model.forward(val_imgs.cuda())\n",
        "        loss = criterion(val_logits, val_labels.cuda())\n",
        "        _, top_class = val_logits.topk(1, dim=1)\n",
        "        equals = top_class == val_labels.cuda().view(*top_class.shape)\n",
        "        val_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        val_loss += batch_size * loss.item()\n",
        "        val_samples += batch_size\n",
        "    assert val_samples == 10000\n",
        "    # update stats\n",
        "    stat_training_loss.append(training_loss/training_samples)\n",
        "    stat_val_loss.append(val_loss/val_samples)\n",
        "    stat_training_acc.append(training_acc/training_samples)\n",
        "    stat_val_acc.append(val_acc/val_samples)\n",
        "    # print\n",
        "    #print(f\"Epoch {(epoch+1):d}/{args.epochs:d}.. Learning rate: {scheduler.get_lr()[0]:.4f}.. Train loss: {(training_loss/training_samples):.4f}.. Train acc: {(training_acc/training_samples):.4f}.. Val loss: {(val_loss/val_samples):.4f}.. Val acc: {(val_acc/val_samples):.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{300}.. \"\n",
        "          f\"Train Loss: {training_loss / training_samples:.4f}.. \"\n",
        "          f\"Train Acc: {training_acc / training_samples:.4f}.. \"\n",
        "          f\"Validation Loss: {val_loss / val_samples:.4f}.. \"\n",
        "          f\"Validation Acc: {val_acc / val_samples:.4f}\")\n",
        "    # lr scheduler\n",
        "    ###scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2_NgTw7x7jc",
        "outputId": "3ad98270-1a7a-44a7-986e-95ec30c1be6a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300.. Train Loss: 4.1241.. Train Acc: 0.0635.. Validation Loss: 3.8068.. Validation Acc: 0.1045\n",
            "Epoch 2/300.. Train Loss: 3.6115.. Train Acc: 0.1331.. Validation Loss: 3.5409.. Validation Acc: 0.1460\n",
            "Epoch 3/300.. Train Loss: 3.3086.. Train Acc: 0.1898.. Validation Loss: 3.2756.. Validation Acc: 0.1916\n",
            "Epoch 4/300.. Train Loss: 3.0913.. Train Acc: 0.2283.. Validation Loss: 3.1532.. Validation Acc: 0.2235\n",
            "Epoch 5/300.. Train Loss: 2.8616.. Train Acc: 0.2720.. Validation Loss: 3.0015.. Validation Acc: 0.2473\n",
            "Epoch 6/300.. Train Loss: 2.6733.. Train Acc: 0.3068.. Validation Loss: 2.6897.. Validation Acc: 0.3087\n",
            "Epoch 7/300.. Train Loss: 2.5020.. Train Acc: 0.3399.. Validation Loss: 2.6077.. Validation Acc: 0.3228\n",
            "Epoch 8/300.. Train Loss: 2.3676.. Train Acc: 0.3666.. Validation Loss: 2.5897.. Validation Acc: 0.3366\n",
            "Epoch 9/300.. Train Loss: 2.2554.. Train Acc: 0.3954.. Validation Loss: 2.4011.. Validation Acc: 0.3640\n",
            "Epoch 10/300.. Train Loss: 2.1351.. Train Acc: 0.4190.. Validation Loss: 2.3479.. Validation Acc: 0.3853\n",
            "Epoch 11/300.. Train Loss: 2.0421.. Train Acc: 0.4394.. Validation Loss: 2.3019.. Validation Acc: 0.3863\n",
            "Epoch 12/300.. Train Loss: 1.9611.. Train Acc: 0.4578.. Validation Loss: 2.2498.. Validation Acc: 0.4086\n",
            "Epoch 13/300.. Train Loss: 1.8739.. Train Acc: 0.4795.. Validation Loss: 2.2478.. Validation Acc: 0.4095\n",
            "Epoch 14/300.. Train Loss: 1.7946.. Train Acc: 0.4980.. Validation Loss: 2.0795.. Validation Acc: 0.4436\n",
            "Epoch 15/300.. Train Loss: 1.7179.. Train Acc: 0.5146.. Validation Loss: 2.3756.. Validation Acc: 0.4221\n",
            "Epoch 16/300.. Train Loss: 1.6701.. Train Acc: 0.5240.. Validation Loss: 2.0908.. Validation Acc: 0.4387\n",
            "Epoch 17/300.. Train Loss: 1.5806.. Train Acc: 0.5467.. Validation Loss: 2.0538.. Validation Acc: 0.4576\n",
            "Epoch 18/300.. Train Loss: 1.5193.. Train Acc: 0.5631.. Validation Loss: 2.0225.. Validation Acc: 0.4655\n",
            "Epoch 19/300.. Train Loss: 1.4567.. Train Acc: 0.5748.. Validation Loss: 2.0109.. Validation Acc: 0.4711\n",
            "Epoch 20/300.. Train Loss: 1.4022.. Train Acc: 0.5930.. Validation Loss: 1.9648.. Validation Acc: 0.4764\n",
            "Epoch 21/300.. Train Loss: 1.3439.. Train Acc: 0.6051.. Validation Loss: 1.9229.. Validation Acc: 0.4901\n",
            "Epoch 22/300.. Train Loss: 1.3006.. Train Acc: 0.6149.. Validation Loss: 1.9997.. Validation Acc: 0.4780\n",
            "Epoch 23/300.. Train Loss: 1.2427.. Train Acc: 0.6309.. Validation Loss: 1.9920.. Validation Acc: 0.4854\n",
            "Epoch 24/300.. Train Loss: 1.1957.. Train Acc: 0.6395.. Validation Loss: 1.9557.. Validation Acc: 0.4924\n",
            "Epoch 25/300.. Train Loss: 1.1375.. Train Acc: 0.6574.. Validation Loss: 1.9134.. Validation Acc: 0.4968\n",
            "Epoch 26/300.. Train Loss: 1.0998.. Train Acc: 0.6665.. Validation Loss: 1.9589.. Validation Acc: 0.4973\n",
            "Epoch 27/300.. Train Loss: 1.0515.. Train Acc: 0.6785.. Validation Loss: 1.9726.. Validation Acc: 0.4917\n",
            "Epoch 28/300.. Train Loss: 1.0080.. Train Acc: 0.6915.. Validation Loss: 1.9809.. Validation Acc: 0.5002\n",
            "Epoch 29/300.. Train Loss: 0.9567.. Train Acc: 0.7040.. Validation Loss: 2.0174.. Validation Acc: 0.5009\n",
            "Epoch 30/300.. Train Loss: 0.9107.. Train Acc: 0.7171.. Validation Loss: 2.0238.. Validation Acc: 0.5068\n",
            "Epoch 31/300.. Train Loss: 0.8738.. Train Acc: 0.7279.. Validation Loss: 2.0140.. Validation Acc: 0.5108\n",
            "Epoch 32/300.. Train Loss: 0.8355.. Train Acc: 0.7355.. Validation Loss: 2.0810.. Validation Acc: 0.5098\n",
            "Epoch 33/300.. Train Loss: 0.7885.. Train Acc: 0.7491.. Validation Loss: 2.1034.. Validation Acc: 0.5016\n",
            "Epoch 34/300.. Train Loss: 0.7422.. Train Acc: 0.7651.. Validation Loss: 2.1273.. Validation Acc: 0.5077\n",
            "Epoch 35/300.. Train Loss: 0.7069.. Train Acc: 0.7731.. Validation Loss: 2.2147.. Validation Acc: 0.5015\n",
            "Epoch 36/300.. Train Loss: 0.6589.. Train Acc: 0.7885.. Validation Loss: 2.1498.. Validation Acc: 0.5116\n",
            "Epoch 37/300.. Train Loss: 0.6141.. Train Acc: 0.8062.. Validation Loss: 2.1461.. Validation Acc: 0.5212\n",
            "Epoch 38/300.. Train Loss: 0.5869.. Train Acc: 0.8103.. Validation Loss: 2.2158.. Validation Acc: 0.5186\n",
            "Epoch 39/300.. Train Loss: 0.5602.. Train Acc: 0.8175.. Validation Loss: 2.2596.. Validation Acc: 0.5134\n",
            "Epoch 40/300.. Train Loss: 0.5179.. Train Acc: 0.8325.. Validation Loss: 2.2488.. Validation Acc: 0.5213\n",
            "Epoch 41/300.. Train Loss: 0.4890.. Train Acc: 0.8399.. Validation Loss: 2.3011.. Validation Acc: 0.5132\n",
            "Epoch 42/300.. Train Loss: 0.4683.. Train Acc: 0.8477.. Validation Loss: 2.2901.. Validation Acc: 0.5190\n",
            "Epoch 43/300.. Train Loss: 0.4421.. Train Acc: 0.8544.. Validation Loss: 2.3101.. Validation Acc: 0.5212\n",
            "Epoch 44/300.. Train Loss: 0.4153.. Train Acc: 0.8648.. Validation Loss: 2.2951.. Validation Acc: 0.5249\n",
            "Epoch 45/300.. Train Loss: 0.3829.. Train Acc: 0.8749.. Validation Loss: 2.3691.. Validation Acc: 0.5196\n",
            "Epoch 46/300.. Train Loss: 0.3632.. Train Acc: 0.8790.. Validation Loss: 2.3875.. Validation Acc: 0.5246\n",
            "Epoch 47/300.. Train Loss: 0.3346.. Train Acc: 0.8903.. Validation Loss: 2.4526.. Validation Acc: 0.5262\n",
            "Epoch 48/300.. Train Loss: 0.3257.. Train Acc: 0.8949.. Validation Loss: 2.4534.. Validation Acc: 0.5206\n",
            "Epoch 49/300.. Train Loss: 0.3098.. Train Acc: 0.8985.. Validation Loss: 2.4287.. Validation Acc: 0.5301\n",
            "Epoch 50/300.. Train Loss: 0.2885.. Train Acc: 0.9051.. Validation Loss: 2.5009.. Validation Acc: 0.5274\n",
            "Epoch 51/300.. Train Loss: 0.2652.. Train Acc: 0.9130.. Validation Loss: 2.5019.. Validation Acc: 0.5294\n",
            "Epoch 52/300.. Train Loss: 0.2485.. Train Acc: 0.9182.. Validation Loss: 2.5693.. Validation Acc: 0.5276\n",
            "Epoch 53/300.. Train Loss: 0.2321.. Train Acc: 0.9243.. Validation Loss: 2.6079.. Validation Acc: 0.5213\n",
            "Epoch 54/300.. Train Loss: 0.2385.. Train Acc: 0.9224.. Validation Loss: 2.5767.. Validation Acc: 0.5287\n",
            "Epoch 55/300.. Train Loss: 0.2266.. Train Acc: 0.9264.. Validation Loss: 2.5547.. Validation Acc: 0.5314\n",
            "Epoch 56/300.. Train Loss: 0.2160.. Train Acc: 0.9291.. Validation Loss: 2.5627.. Validation Acc: 0.5383\n",
            "Epoch 57/300.. Train Loss: 0.1988.. Train Acc: 0.9346.. Validation Loss: 2.6200.. Validation Acc: 0.5335\n",
            "Epoch 58/300.. Train Loss: 0.2005.. Train Acc: 0.9342.. Validation Loss: 2.6625.. Validation Acc: 0.5286\n",
            "Epoch 59/300.. Train Loss: 0.1816.. Train Acc: 0.9398.. Validation Loss: 2.6353.. Validation Acc: 0.5345\n",
            "Epoch 60/300.. Train Loss: 0.1752.. Train Acc: 0.9418.. Validation Loss: 2.6151.. Validation Acc: 0.5322\n",
            "Epoch 61/300.. Train Loss: 0.1669.. Train Acc: 0.9456.. Validation Loss: 2.7617.. Validation Acc: 0.5295\n",
            "Epoch 62/300.. Train Loss: 0.1596.. Train Acc: 0.9487.. Validation Loss: 2.6811.. Validation Acc: 0.5367\n",
            "Epoch 63/300.. Train Loss: 0.1528.. Train Acc: 0.9495.. Validation Loss: 2.7828.. Validation Acc: 0.5333\n",
            "Epoch 64/300.. Train Loss: 0.1424.. Train Acc: 0.9529.. Validation Loss: 2.7191.. Validation Acc: 0.5383\n",
            "Epoch 65/300.. Train Loss: 0.1414.. Train Acc: 0.9548.. Validation Loss: 2.7376.. Validation Acc: 0.5300\n",
            "Epoch 66/300.. Train Loss: 0.1251.. Train Acc: 0.9588.. Validation Loss: 2.7755.. Validation Acc: 0.5419\n",
            "Epoch 67/300.. Train Loss: 0.1280.. Train Acc: 0.9583.. Validation Loss: 2.7632.. Validation Acc: 0.5373\n",
            "Epoch 68/300.. Train Loss: 0.1240.. Train Acc: 0.9604.. Validation Loss: 2.8322.. Validation Acc: 0.5331\n",
            "Epoch 69/300.. Train Loss: 0.1212.. Train Acc: 0.9597.. Validation Loss: 2.7929.. Validation Acc: 0.5360\n",
            "Epoch 70/300.. Train Loss: 0.1105.. Train Acc: 0.9645.. Validation Loss: 2.8191.. Validation Acc: 0.5423\n",
            "Epoch 71/300.. Train Loss: 0.1038.. Train Acc: 0.9668.. Validation Loss: 2.8380.. Validation Acc: 0.5436\n",
            "Epoch 72/300.. Train Loss: 0.0979.. Train Acc: 0.9684.. Validation Loss: 2.8486.. Validation Acc: 0.5364\n",
            "Epoch 73/300.. Train Loss: 0.1128.. Train Acc: 0.9638.. Validation Loss: 2.8972.. Validation Acc: 0.5361\n",
            "Epoch 74/300.. Train Loss: 0.1042.. Train Acc: 0.9660.. Validation Loss: 2.8865.. Validation Acc: 0.5383\n",
            "Epoch 75/300.. Train Loss: 0.0993.. Train Acc: 0.9680.. Validation Loss: 2.8929.. Validation Acc: 0.5335\n",
            "Epoch 76/300.. Train Loss: 0.0951.. Train Acc: 0.9695.. Validation Loss: 2.8860.. Validation Acc: 0.5379\n",
            "Epoch 77/300.. Train Loss: 0.0953.. Train Acc: 0.9690.. Validation Loss: 2.9265.. Validation Acc: 0.5406\n",
            "Epoch 78/300.. Train Loss: 0.0891.. Train Acc: 0.9718.. Validation Loss: 2.8781.. Validation Acc: 0.5414\n",
            "Epoch 79/300.. Train Loss: 0.0881.. Train Acc: 0.9718.. Validation Loss: 2.9152.. Validation Acc: 0.5393\n",
            "Epoch 80/300.. Train Loss: 0.0790.. Train Acc: 0.9751.. Validation Loss: 2.9356.. Validation Acc: 0.5453\n",
            "Epoch 81/300.. Train Loss: 0.0801.. Train Acc: 0.9738.. Validation Loss: 2.9011.. Validation Acc: 0.5410\n",
            "Epoch 82/300.. Train Loss: 0.0687.. Train Acc: 0.9773.. Validation Loss: 2.9268.. Validation Acc: 0.5435\n",
            "Epoch 83/300.. Train Loss: 0.0727.. Train Acc: 0.9771.. Validation Loss: 2.9675.. Validation Acc: 0.5420\n",
            "Epoch 84/300.. Train Loss: 0.0749.. Train Acc: 0.9758.. Validation Loss: 2.9802.. Validation Acc: 0.5456\n",
            "Epoch 85/300.. Train Loss: 0.0730.. Train Acc: 0.9774.. Validation Loss: 2.9475.. Validation Acc: 0.5442\n",
            "Epoch 86/300.. Train Loss: 0.0684.. Train Acc: 0.9786.. Validation Loss: 3.0357.. Validation Acc: 0.5369\n",
            "Epoch 87/300.. Train Loss: 0.0718.. Train Acc: 0.9765.. Validation Loss: 2.9568.. Validation Acc: 0.5418\n",
            "Epoch 88/300.. Train Loss: 0.0644.. Train Acc: 0.9794.. Validation Loss: 2.9813.. Validation Acc: 0.5447\n",
            "Epoch 89/300.. Train Loss: 0.0604.. Train Acc: 0.9812.. Validation Loss: 2.9995.. Validation Acc: 0.5462\n",
            "Epoch 90/300.. Train Loss: 0.0627.. Train Acc: 0.9798.. Validation Loss: 2.9486.. Validation Acc: 0.5481\n",
            "Epoch 91/300.. Train Loss: 0.0549.. Train Acc: 0.9821.. Validation Loss: 3.0233.. Validation Acc: 0.5476\n",
            "Epoch 92/300.. Train Loss: 0.0565.. Train Acc: 0.9821.. Validation Loss: 3.0208.. Validation Acc: 0.5461\n",
            "Epoch 93/300.. Train Loss: 0.0569.. Train Acc: 0.9820.. Validation Loss: 3.0076.. Validation Acc: 0.5471\n",
            "Epoch 94/300.. Train Loss: 0.0560.. Train Acc: 0.9823.. Validation Loss: 3.0728.. Validation Acc: 0.5483\n",
            "Epoch 95/300.. Train Loss: 0.0565.. Train Acc: 0.9819.. Validation Loss: 3.0400.. Validation Acc: 0.5458\n",
            "Epoch 96/300.. Train Loss: 0.0529.. Train Acc: 0.9831.. Validation Loss: 3.0260.. Validation Acc: 0.5459\n",
            "Epoch 97/300.. Train Loss: 0.0516.. Train Acc: 0.9841.. Validation Loss: 3.0714.. Validation Acc: 0.5485\n",
            "Epoch 98/300.. Train Loss: 0.0533.. Train Acc: 0.9831.. Validation Loss: 3.0574.. Validation Acc: 0.5503\n",
            "Epoch 99/300.. Train Loss: 0.0492.. Train Acc: 0.9840.. Validation Loss: 3.0894.. Validation Acc: 0.5445\n",
            "Epoch 100/300.. Train Loss: 0.0496.. Train Acc: 0.9837.. Validation Loss: 3.0562.. Validation Acc: 0.5439\n",
            "Epoch 101/300.. Train Loss: 0.0462.. Train Acc: 0.9854.. Validation Loss: 3.1047.. Validation Acc: 0.5445\n",
            "Epoch 102/300.. Train Loss: 0.0458.. Train Acc: 0.9854.. Validation Loss: 3.1424.. Validation Acc: 0.5459\n",
            "Epoch 103/300.. Train Loss: 0.0483.. Train Acc: 0.9846.. Validation Loss: 3.1003.. Validation Acc: 0.5462\n",
            "Epoch 104/300.. Train Loss: 0.0422.. Train Acc: 0.9870.. Validation Loss: 3.1523.. Validation Acc: 0.5453\n",
            "Epoch 105/300.. Train Loss: 0.0420.. Train Acc: 0.9864.. Validation Loss: 3.1933.. Validation Acc: 0.5435\n",
            "Epoch 106/300.. Train Loss: 0.0444.. Train Acc: 0.9859.. Validation Loss: 3.1316.. Validation Acc: 0.5477\n",
            "Epoch 107/300.. Train Loss: 0.0384.. Train Acc: 0.9885.. Validation Loss: 3.1609.. Validation Acc: 0.5495\n",
            "Epoch 108/300.. Train Loss: 0.0355.. Train Acc: 0.9890.. Validation Loss: 3.1502.. Validation Acc: 0.5459\n",
            "Epoch 109/300.. Train Loss: 0.0358.. Train Acc: 0.9889.. Validation Loss: 3.1934.. Validation Acc: 0.5464\n",
            "Epoch 110/300.. Train Loss: 0.0412.. Train Acc: 0.9876.. Validation Loss: 3.2142.. Validation Acc: 0.5449\n",
            "Epoch 111/300.. Train Loss: 0.0403.. Train Acc: 0.9872.. Validation Loss: 3.1997.. Validation Acc: 0.5463\n",
            "Epoch 112/300.. Train Loss: 0.0383.. Train Acc: 0.9877.. Validation Loss: 3.2273.. Validation Acc: 0.5455\n",
            "Epoch 113/300.. Train Loss: 0.0407.. Train Acc: 0.9874.. Validation Loss: 3.1790.. Validation Acc: 0.5465\n",
            "Epoch 114/300.. Train Loss: 0.0341.. Train Acc: 0.9894.. Validation Loss: 3.1900.. Validation Acc: 0.5457\n",
            "Epoch 115/300.. Train Loss: 0.0330.. Train Acc: 0.9901.. Validation Loss: 3.1955.. Validation Acc: 0.5480\n",
            "Epoch 116/300.. Train Loss: 0.0336.. Train Acc: 0.9896.. Validation Loss: 3.1910.. Validation Acc: 0.5442\n",
            "Epoch 117/300.. Train Loss: 0.0330.. Train Acc: 0.9893.. Validation Loss: 3.2148.. Validation Acc: 0.5481\n",
            "Epoch 118/300.. Train Loss: 0.0283.. Train Acc: 0.9916.. Validation Loss: 3.2019.. Validation Acc: 0.5518\n",
            "Epoch 119/300.. Train Loss: 0.0279.. Train Acc: 0.9915.. Validation Loss: 3.1704.. Validation Acc: 0.5515\n",
            "Epoch 120/300.. Train Loss: 0.0304.. Train Acc: 0.9905.. Validation Loss: 3.2429.. Validation Acc: 0.5519\n",
            "Epoch 121/300.. Train Loss: 0.0327.. Train Acc: 0.9891.. Validation Loss: 3.2338.. Validation Acc: 0.5514\n",
            "Epoch 122/300.. Train Loss: 0.0296.. Train Acc: 0.9905.. Validation Loss: 3.2469.. Validation Acc: 0.5491\n",
            "Epoch 123/300.. Train Loss: 0.0307.. Train Acc: 0.9902.. Validation Loss: 3.2170.. Validation Acc: 0.5530\n",
            "Epoch 124/300.. Train Loss: 0.0293.. Train Acc: 0.9904.. Validation Loss: 3.2402.. Validation Acc: 0.5493\n",
            "Epoch 125/300.. Train Loss: 0.0291.. Train Acc: 0.9912.. Validation Loss: 3.2591.. Validation Acc: 0.5483\n",
            "Epoch 126/300.. Train Loss: 0.0278.. Train Acc: 0.9919.. Validation Loss: 3.2358.. Validation Acc: 0.5458\n",
            "Epoch 127/300.. Train Loss: 0.0277.. Train Acc: 0.9915.. Validation Loss: 3.2258.. Validation Acc: 0.5588\n",
            "Epoch 128/300.. Train Loss: 0.0287.. Train Acc: 0.9905.. Validation Loss: 3.2683.. Validation Acc: 0.5511\n",
            "Epoch 129/300.. Train Loss: 0.0256.. Train Acc: 0.9924.. Validation Loss: 3.2757.. Validation Acc: 0.5494\n",
            "Epoch 130/300.. Train Loss: 0.0255.. Train Acc: 0.9921.. Validation Loss: 3.2114.. Validation Acc: 0.5513\n",
            "Epoch 131/300.. Train Loss: 0.0312.. Train Acc: 0.9895.. Validation Loss: 3.2855.. Validation Acc: 0.5508\n",
            "Epoch 132/300.. Train Loss: 0.0327.. Train Acc: 0.9895.. Validation Loss: 3.2898.. Validation Acc: 0.5499\n",
            "Epoch 133/300.. Train Loss: 0.0333.. Train Acc: 0.9892.. Validation Loss: 3.2964.. Validation Acc: 0.5419\n",
            "Epoch 134/300.. Train Loss: 0.0323.. Train Acc: 0.9900.. Validation Loss: 3.2644.. Validation Acc: 0.5482\n",
            "Epoch 135/300.. Train Loss: 0.0291.. Train Acc: 0.9906.. Validation Loss: 3.2585.. Validation Acc: 0.5513\n",
            "Epoch 136/300.. Train Loss: 0.0282.. Train Acc: 0.9912.. Validation Loss: 3.2720.. Validation Acc: 0.5492\n",
            "Epoch 137/300.. Train Loss: 0.0258.. Train Acc: 0.9921.. Validation Loss: 3.2726.. Validation Acc: 0.5503\n",
            "Epoch 138/300.. Train Loss: 0.0260.. Train Acc: 0.9920.. Validation Loss: 3.2453.. Validation Acc: 0.5510\n",
            "Epoch 139/300.. Train Loss: 0.0235.. Train Acc: 0.9929.. Validation Loss: 3.2803.. Validation Acc: 0.5560\n",
            "Epoch 140/300.. Train Loss: 0.0238.. Train Acc: 0.9923.. Validation Loss: 3.2792.. Validation Acc: 0.5492\n",
            "Epoch 141/300.. Train Loss: 0.0240.. Train Acc: 0.9922.. Validation Loss: 3.3163.. Validation Acc: 0.5515\n",
            "Epoch 142/300.. Train Loss: 0.0220.. Train Acc: 0.9932.. Validation Loss: 3.2987.. Validation Acc: 0.5579\n",
            "Epoch 143/300.. Train Loss: 0.0260.. Train Acc: 0.9920.. Validation Loss: 3.2617.. Validation Acc: 0.5544\n",
            "Epoch 144/300.. Train Loss: 0.0228.. Train Acc: 0.9928.. Validation Loss: 3.3002.. Validation Acc: 0.5546\n",
            "Epoch 145/300.. Train Loss: 0.0215.. Train Acc: 0.9932.. Validation Loss: 3.3714.. Validation Acc: 0.5523\n",
            "Epoch 146/300.. Train Loss: 0.0238.. Train Acc: 0.9927.. Validation Loss: 3.3802.. Validation Acc: 0.5500\n",
            "Epoch 147/300.. Train Loss: 0.0220.. Train Acc: 0.9935.. Validation Loss: 3.3266.. Validation Acc: 0.5515\n",
            "Epoch 148/300.. Train Loss: 0.0215.. Train Acc: 0.9933.. Validation Loss: 3.3642.. Validation Acc: 0.5510\n",
            "Epoch 149/300.. Train Loss: 0.0244.. Train Acc: 0.9924.. Validation Loss: 3.3335.. Validation Acc: 0.5492\n",
            "Epoch 150/300.. Train Loss: 0.0216.. Train Acc: 0.9934.. Validation Loss: 3.3883.. Validation Acc: 0.5474\n",
            "Epoch 151/300.. Train Loss: 0.0219.. Train Acc: 0.9933.. Validation Loss: 3.4017.. Validation Acc: 0.5512\n",
            "Epoch 152/300.. Train Loss: 0.0223.. Train Acc: 0.9929.. Validation Loss: 3.3762.. Validation Acc: 0.5509\n",
            "Epoch 153/300.. Train Loss: 0.0215.. Train Acc: 0.9932.. Validation Loss: 3.3649.. Validation Acc: 0.5496\n",
            "Epoch 154/300.. Train Loss: 0.0223.. Train Acc: 0.9931.. Validation Loss: 3.3298.. Validation Acc: 0.5501\n",
            "Epoch 155/300.. Train Loss: 0.0246.. Train Acc: 0.9929.. Validation Loss: 3.3825.. Validation Acc: 0.5480\n",
            "Epoch 156/300.. Train Loss: 0.0218.. Train Acc: 0.9931.. Validation Loss: 3.3342.. Validation Acc: 0.5506\n",
            "Epoch 157/300.. Train Loss: 0.0190.. Train Acc: 0.9941.. Validation Loss: 3.3288.. Validation Acc: 0.5554\n",
            "Epoch 158/300.. Train Loss: 0.0215.. Train Acc: 0.9934.. Validation Loss: 3.3254.. Validation Acc: 0.5528\n",
            "Epoch 159/300.. Train Loss: 0.0198.. Train Acc: 0.9935.. Validation Loss: 3.3654.. Validation Acc: 0.5517\n",
            "Epoch 160/300.. Train Loss: 0.0214.. Train Acc: 0.9933.. Validation Loss: 3.4079.. Validation Acc: 0.5473\n",
            "Epoch 161/300.. Train Loss: 0.0210.. Train Acc: 0.9933.. Validation Loss: 3.4287.. Validation Acc: 0.5473\n",
            "Epoch 162/300.. Train Loss: 0.0224.. Train Acc: 0.9929.. Validation Loss: 3.4138.. Validation Acc: 0.5509\n",
            "Epoch 163/300.. Train Loss: 0.0215.. Train Acc: 0.9930.. Validation Loss: 3.3825.. Validation Acc: 0.5552\n",
            "Epoch 164/300.. Train Loss: 0.0216.. Train Acc: 0.9931.. Validation Loss: 3.3741.. Validation Acc: 0.5518\n",
            "Epoch 165/300.. Train Loss: 0.0206.. Train Acc: 0.9936.. Validation Loss: 3.3828.. Validation Acc: 0.5552\n",
            "Epoch 166/300.. Train Loss: 0.0193.. Train Acc: 0.9944.. Validation Loss: 3.3430.. Validation Acc: 0.5518\n",
            "Epoch 167/300.. Train Loss: 0.0221.. Train Acc: 0.9930.. Validation Loss: 3.3616.. Validation Acc: 0.5508\n",
            "Epoch 168/300.. Train Loss: 0.0201.. Train Acc: 0.9939.. Validation Loss: 3.3562.. Validation Acc: 0.5562\n",
            "Epoch 169/300.. Train Loss: 0.0185.. Train Acc: 0.9942.. Validation Loss: 3.3901.. Validation Acc: 0.5579\n",
            "Epoch 170/300.. Train Loss: 0.0192.. Train Acc: 0.9939.. Validation Loss: 3.4202.. Validation Acc: 0.5538\n",
            "Epoch 171/300.. Train Loss: 0.0163.. Train Acc: 0.9950.. Validation Loss: 3.4025.. Validation Acc: 0.5557\n",
            "Epoch 172/300.. Train Loss: 0.0180.. Train Acc: 0.9943.. Validation Loss: 3.3908.. Validation Acc: 0.5538\n",
            "Epoch 173/300.. Train Loss: 0.0168.. Train Acc: 0.9950.. Validation Loss: 3.3646.. Validation Acc: 0.5538\n",
            "Epoch 174/300.. Train Loss: 0.0161.. Train Acc: 0.9950.. Validation Loss: 3.3750.. Validation Acc: 0.5529\n",
            "Epoch 175/300.. Train Loss: 0.0163.. Train Acc: 0.9950.. Validation Loss: 3.3975.. Validation Acc: 0.5529\n",
            "Epoch 176/300.. Train Loss: 0.0174.. Train Acc: 0.9946.. Validation Loss: 3.4359.. Validation Acc: 0.5507\n",
            "Epoch 177/300.. Train Loss: 0.0184.. Train Acc: 0.9941.. Validation Loss: 3.4627.. Validation Acc: 0.5467\n",
            "Epoch 178/300.. Train Loss: 0.0196.. Train Acc: 0.9938.. Validation Loss: 3.3879.. Validation Acc: 0.5557\n",
            "Epoch 179/300.. Train Loss: 0.0177.. Train Acc: 0.9942.. Validation Loss: 3.3845.. Validation Acc: 0.5543\n",
            "Epoch 180/300.. Train Loss: 0.0159.. Train Acc: 0.9949.. Validation Loss: 3.3691.. Validation Acc: 0.5566\n",
            "Epoch 181/300.. Train Loss: 0.0157.. Train Acc: 0.9950.. Validation Loss: 3.3596.. Validation Acc: 0.5583\n",
            "Epoch 182/300.. Train Loss: 0.0159.. Train Acc: 0.9952.. Validation Loss: 3.4240.. Validation Acc: 0.5545\n",
            "Epoch 183/300.. Train Loss: 0.0147.. Train Acc: 0.9954.. Validation Loss: 3.4140.. Validation Acc: 0.5525\n",
            "Epoch 184/300.. Train Loss: 0.0146.. Train Acc: 0.9956.. Validation Loss: 3.4265.. Validation Acc: 0.5542\n",
            "Epoch 185/300.. Train Loss: 0.0143.. Train Acc: 0.9956.. Validation Loss: 3.3358.. Validation Acc: 0.5624\n",
            "Epoch 186/300.. Train Loss: 0.0140.. Train Acc: 0.9956.. Validation Loss: 3.4401.. Validation Acc: 0.5563\n",
            "Epoch 187/300.. Train Loss: 0.0161.. Train Acc: 0.9950.. Validation Loss: 3.4312.. Validation Acc: 0.5571\n",
            "Epoch 188/300.. Train Loss: 0.0168.. Train Acc: 0.9944.. Validation Loss: 3.4158.. Validation Acc: 0.5519\n",
            "Epoch 189/300.. Train Loss: 0.0152.. Train Acc: 0.9949.. Validation Loss: 3.3825.. Validation Acc: 0.5536\n",
            "Epoch 190/300.. Train Loss: 0.0133.. Train Acc: 0.9958.. Validation Loss: 3.4191.. Validation Acc: 0.5586\n",
            "Epoch 191/300.. Train Loss: 0.0138.. Train Acc: 0.9958.. Validation Loss: 3.3908.. Validation Acc: 0.5584\n",
            "Epoch 192/300.. Train Loss: 0.0149.. Train Acc: 0.9951.. Validation Loss: 3.4378.. Validation Acc: 0.5565\n",
            "Epoch 193/300.. Train Loss: 0.0115.. Train Acc: 0.9964.. Validation Loss: 3.4379.. Validation Acc: 0.5583\n",
            "Epoch 194/300.. Train Loss: 0.0112.. Train Acc: 0.9966.. Validation Loss: 3.4306.. Validation Acc: 0.5608\n",
            "Epoch 195/300.. Train Loss: 0.0138.. Train Acc: 0.9957.. Validation Loss: 3.4064.. Validation Acc: 0.5568\n",
            "Epoch 196/300.. Train Loss: 0.0156.. Train Acc: 0.9953.. Validation Loss: 3.4609.. Validation Acc: 0.5528\n",
            "Epoch 197/300.. Train Loss: 0.0127.. Train Acc: 0.9959.. Validation Loss: 3.4431.. Validation Acc: 0.5559\n",
            "Epoch 198/300.. Train Loss: 0.0130.. Train Acc: 0.9959.. Validation Loss: 3.4498.. Validation Acc: 0.5548\n",
            "Epoch 199/300.. Train Loss: 0.0124.. Train Acc: 0.9960.. Validation Loss: 3.4557.. Validation Acc: 0.5549\n",
            "Epoch 200/300.. Train Loss: 0.0118.. Train Acc: 0.9964.. Validation Loss: 3.4165.. Validation Acc: 0.5575\n",
            "Epoch 201/300.. Train Loss: 0.0113.. Train Acc: 0.9965.. Validation Loss: 3.4721.. Validation Acc: 0.5562\n",
            "Epoch 202/300.. Train Loss: 0.0109.. Train Acc: 0.9968.. Validation Loss: 3.4510.. Validation Acc: 0.5508\n",
            "Epoch 203/300.. Train Loss: 0.0113.. Train Acc: 0.9967.. Validation Loss: 3.4521.. Validation Acc: 0.5559\n",
            "Epoch 204/300.. Train Loss: 0.0108.. Train Acc: 0.9967.. Validation Loss: 3.4381.. Validation Acc: 0.5599\n",
            "Epoch 205/300.. Train Loss: 0.0092.. Train Acc: 0.9973.. Validation Loss: 3.4135.. Validation Acc: 0.5589\n",
            "Epoch 206/300.. Train Loss: 0.0098.. Train Acc: 0.9972.. Validation Loss: 3.4822.. Validation Acc: 0.5569\n",
            "Epoch 207/300.. Train Loss: 0.0101.. Train Acc: 0.9970.. Validation Loss: 3.4693.. Validation Acc: 0.5540\n",
            "Epoch 208/300.. Train Loss: 0.0099.. Train Acc: 0.9972.. Validation Loss: 3.4455.. Validation Acc: 0.5608\n",
            "Epoch 209/300.. Train Loss: 0.0106.. Train Acc: 0.9968.. Validation Loss: 3.5302.. Validation Acc: 0.5528\n",
            "Epoch 210/300.. Train Loss: 0.0131.. Train Acc: 0.9960.. Validation Loss: 3.4985.. Validation Acc: 0.5538\n",
            "Epoch 211/300.. Train Loss: 0.0122.. Train Acc: 0.9963.. Validation Loss: 3.4510.. Validation Acc: 0.5549\n",
            "Epoch 212/300.. Train Loss: 0.0115.. Train Acc: 0.9965.. Validation Loss: 3.4784.. Validation Acc: 0.5564\n",
            "Epoch 213/300.. Train Loss: 0.0101.. Train Acc: 0.9969.. Validation Loss: 3.5384.. Validation Acc: 0.5595\n",
            "Epoch 214/300.. Train Loss: 0.0112.. Train Acc: 0.9965.. Validation Loss: 3.5150.. Validation Acc: 0.5498\n",
            "Epoch 215/300.. Train Loss: 0.0117.. Train Acc: 0.9960.. Validation Loss: 3.5016.. Validation Acc: 0.5545\n",
            "Epoch 216/300.. Train Loss: 0.0123.. Train Acc: 0.9958.. Validation Loss: 3.4894.. Validation Acc: 0.5583\n",
            "Epoch 217/300.. Train Loss: 0.0123.. Train Acc: 0.9961.. Validation Loss: 3.4809.. Validation Acc: 0.5573\n",
            "Epoch 218/300.. Train Loss: 0.0135.. Train Acc: 0.9958.. Validation Loss: 3.4796.. Validation Acc: 0.5551\n",
            "Epoch 219/300.. Train Loss: 0.0108.. Train Acc: 0.9963.. Validation Loss: 3.4951.. Validation Acc: 0.5568\n",
            "Epoch 220/300.. Train Loss: 0.0102.. Train Acc: 0.9967.. Validation Loss: 3.5339.. Validation Acc: 0.5500\n",
            "Epoch 221/300.. Train Loss: 0.0098.. Train Acc: 0.9970.. Validation Loss: 3.5037.. Validation Acc: 0.5565\n",
            "Epoch 222/300.. Train Loss: 0.0091.. Train Acc: 0.9970.. Validation Loss: 3.5047.. Validation Acc: 0.5599\n",
            "Epoch 223/300.. Train Loss: 0.0098.. Train Acc: 0.9966.. Validation Loss: 3.5045.. Validation Acc: 0.5531\n",
            "Epoch 224/300.. Train Loss: 0.0119.. Train Acc: 0.9964.. Validation Loss: 3.5370.. Validation Acc: 0.5543\n",
            "Epoch 225/300.. Train Loss: 0.0124.. Train Acc: 0.9960.. Validation Loss: 3.5072.. Validation Acc: 0.5595\n",
            "Epoch 226/300.. Train Loss: 0.0122.. Train Acc: 0.9960.. Validation Loss: 3.5457.. Validation Acc: 0.5490\n",
            "Epoch 227/300.. Train Loss: 0.0112.. Train Acc: 0.9965.. Validation Loss: 3.5135.. Validation Acc: 0.5582\n",
            "Epoch 228/300.. Train Loss: 0.0103.. Train Acc: 0.9967.. Validation Loss: 3.5264.. Validation Acc: 0.5560\n",
            "Epoch 229/300.. Train Loss: 0.0091.. Train Acc: 0.9977.. Validation Loss: 3.5065.. Validation Acc: 0.5601\n",
            "Epoch 230/300.. Train Loss: 0.0101.. Train Acc: 0.9965.. Validation Loss: 3.5455.. Validation Acc: 0.5578\n",
            "Epoch 231/300.. Train Loss: 0.0121.. Train Acc: 0.9963.. Validation Loss: 3.5285.. Validation Acc: 0.5597\n",
            "Epoch 232/300.. Train Loss: 0.0103.. Train Acc: 0.9967.. Validation Loss: 3.5254.. Validation Acc: 0.5602\n",
            "Epoch 233/300.. Train Loss: 0.0093.. Train Acc: 0.9969.. Validation Loss: 3.5271.. Validation Acc: 0.5545\n",
            "Epoch 234/300.. Train Loss: 0.0094.. Train Acc: 0.9970.. Validation Loss: 3.5545.. Validation Acc: 0.5570\n",
            "Epoch 235/300.. Train Loss: 0.0092.. Train Acc: 0.9970.. Validation Loss: 3.5280.. Validation Acc: 0.5576\n",
            "Epoch 236/300.. Train Loss: 0.0096.. Train Acc: 0.9971.. Validation Loss: 3.5339.. Validation Acc: 0.5563\n",
            "Epoch 237/300.. Train Loss: 0.0105.. Train Acc: 0.9970.. Validation Loss: 3.5166.. Validation Acc: 0.5544\n",
            "Epoch 238/300.. Train Loss: 0.0089.. Train Acc: 0.9971.. Validation Loss: 3.5260.. Validation Acc: 0.5532\n",
            "Epoch 239/300.. Train Loss: 0.0088.. Train Acc: 0.9973.. Validation Loss: 3.5147.. Validation Acc: 0.5534\n",
            "Epoch 240/300.. Train Loss: 0.0094.. Train Acc: 0.9975.. Validation Loss: 3.5387.. Validation Acc: 0.5555\n",
            "Epoch 241/300.. Train Loss: 0.0087.. Train Acc: 0.9971.. Validation Loss: 3.5154.. Validation Acc: 0.5581\n",
            "Epoch 242/300.. Train Loss: 0.0081.. Train Acc: 0.9975.. Validation Loss: 3.4922.. Validation Acc: 0.5580\n",
            "Epoch 243/300.. Train Loss: 0.0077.. Train Acc: 0.9976.. Validation Loss: 3.5328.. Validation Acc: 0.5635\n",
            "Epoch 244/300.. Train Loss: 0.0083.. Train Acc: 0.9973.. Validation Loss: 3.5617.. Validation Acc: 0.5592\n",
            "Epoch 245/300.. Train Loss: 0.0089.. Train Acc: 0.9972.. Validation Loss: 3.5247.. Validation Acc: 0.5543\n",
            "Epoch 246/300.. Train Loss: 0.0074.. Train Acc: 0.9976.. Validation Loss: 3.5031.. Validation Acc: 0.5631\n",
            "Epoch 247/300.. Train Loss: 0.0080.. Train Acc: 0.9973.. Validation Loss: 3.5253.. Validation Acc: 0.5584\n",
            "Epoch 248/300.. Train Loss: 0.0081.. Train Acc: 0.9972.. Validation Loss: 3.5857.. Validation Acc: 0.5606\n",
            "Epoch 249/300.. Train Loss: 0.0074.. Train Acc: 0.9976.. Validation Loss: 3.5737.. Validation Acc: 0.5603\n",
            "Epoch 250/300.. Train Loss: 0.0080.. Train Acc: 0.9976.. Validation Loss: 3.5608.. Validation Acc: 0.5576\n",
            "Epoch 251/300.. Train Loss: 0.0072.. Train Acc: 0.9979.. Validation Loss: 3.5275.. Validation Acc: 0.5620\n",
            "Epoch 252/300.. Train Loss: 0.0082.. Train Acc: 0.9976.. Validation Loss: 3.5748.. Validation Acc: 0.5578\n",
            "Epoch 253/300.. Train Loss: 0.0089.. Train Acc: 0.9973.. Validation Loss: 3.5664.. Validation Acc: 0.5584\n",
            "Epoch 254/300.. Train Loss: 0.0100.. Train Acc: 0.9968.. Validation Loss: 3.5629.. Validation Acc: 0.5561\n",
            "Epoch 255/300.. Train Loss: 0.0088.. Train Acc: 0.9975.. Validation Loss: 3.5235.. Validation Acc: 0.5616\n",
            "Epoch 256/300.. Train Loss: 0.0086.. Train Acc: 0.9970.. Validation Loss: 3.6092.. Validation Acc: 0.5629\n",
            "Epoch 257/300.. Train Loss: 0.0078.. Train Acc: 0.9979.. Validation Loss: 3.5828.. Validation Acc: 0.5587\n",
            "Epoch 258/300.. Train Loss: 0.0069.. Train Acc: 0.9979.. Validation Loss: 3.6149.. Validation Acc: 0.5611\n",
            "Epoch 259/300.. Train Loss: 0.0077.. Train Acc: 0.9975.. Validation Loss: 3.6042.. Validation Acc: 0.5609\n",
            "Epoch 260/300.. Train Loss: 0.0073.. Train Acc: 0.9978.. Validation Loss: 3.6117.. Validation Acc: 0.5560\n",
            "Epoch 261/300.. Train Loss: 0.0076.. Train Acc: 0.9975.. Validation Loss: 3.6052.. Validation Acc: 0.5576\n",
            "Epoch 262/300.. Train Loss: 0.0084.. Train Acc: 0.9975.. Validation Loss: 3.6903.. Validation Acc: 0.5588\n",
            "Epoch 263/300.. Train Loss: 0.0085.. Train Acc: 0.9977.. Validation Loss: 3.6157.. Validation Acc: 0.5593\n",
            "Epoch 264/300.. Train Loss: 0.0083.. Train Acc: 0.9977.. Validation Loss: 3.5886.. Validation Acc: 0.5576\n",
            "Epoch 265/300.. Train Loss: 0.0095.. Train Acc: 0.9970.. Validation Loss: 3.6141.. Validation Acc: 0.5599\n",
            "Epoch 266/300.. Train Loss: 0.0100.. Train Acc: 0.9970.. Validation Loss: 3.5958.. Validation Acc: 0.5584\n",
            "Epoch 267/300.. Train Loss: 0.0085.. Train Acc: 0.9972.. Validation Loss: 3.6163.. Validation Acc: 0.5569\n",
            "Epoch 268/300.. Train Loss: 0.0074.. Train Acc: 0.9976.. Validation Loss: 3.5807.. Validation Acc: 0.5643\n",
            "Epoch 269/300.. Train Loss: 0.0094.. Train Acc: 0.9970.. Validation Loss: 3.6105.. Validation Acc: 0.5546\n",
            "Epoch 270/300.. Train Loss: 0.0070.. Train Acc: 0.9978.. Validation Loss: 3.5819.. Validation Acc: 0.5597\n",
            "Epoch 271/300.. Train Loss: 0.0077.. Train Acc: 0.9973.. Validation Loss: 3.6396.. Validation Acc: 0.5600\n",
            "Epoch 272/300.. Train Loss: 0.0081.. Train Acc: 0.9973.. Validation Loss: 3.6187.. Validation Acc: 0.5592\n",
            "Epoch 273/300.. Train Loss: 0.0068.. Train Acc: 0.9980.. Validation Loss: 3.6443.. Validation Acc: 0.5575\n",
            "Epoch 274/300.. Train Loss: 0.0075.. Train Acc: 0.9977.. Validation Loss: 3.6068.. Validation Acc: 0.5551\n",
            "Epoch 275/300.. Train Loss: 0.0086.. Train Acc: 0.9971.. Validation Loss: 3.6908.. Validation Acc: 0.5566\n",
            "Epoch 276/300.. Train Loss: 0.0071.. Train Acc: 0.9977.. Validation Loss: 3.6437.. Validation Acc: 0.5589\n",
            "Epoch 277/300.. Train Loss: 0.0073.. Train Acc: 0.9977.. Validation Loss: 3.6616.. Validation Acc: 0.5548\n",
            "Epoch 278/300.. Train Loss: 0.0081.. Train Acc: 0.9974.. Validation Loss: 3.6937.. Validation Acc: 0.5568\n",
            "Epoch 279/300.. Train Loss: 0.0065.. Train Acc: 0.9980.. Validation Loss: 3.5894.. Validation Acc: 0.5554\n",
            "Epoch 280/300.. Train Loss: 0.0077.. Train Acc: 0.9974.. Validation Loss: 3.5461.. Validation Acc: 0.5619\n",
            "Epoch 281/300.. Train Loss: 0.0072.. Train Acc: 0.9978.. Validation Loss: 3.6119.. Validation Acc: 0.5612\n",
            "Epoch 282/300.. Train Loss: 0.0073.. Train Acc: 0.9978.. Validation Loss: 3.6135.. Validation Acc: 0.5587\n",
            "Epoch 283/300.. Train Loss: 0.0078.. Train Acc: 0.9974.. Validation Loss: 3.6473.. Validation Acc: 0.5557\n",
            "Epoch 284/300.. Train Loss: 0.0070.. Train Acc: 0.9979.. Validation Loss: 3.6071.. Validation Acc: 0.5582\n",
            "Epoch 285/300.. Train Loss: 0.0062.. Train Acc: 0.9980.. Validation Loss: 3.6491.. Validation Acc: 0.5511\n",
            "Epoch 286/300.. Train Loss: 0.0077.. Train Acc: 0.9976.. Validation Loss: 3.6737.. Validation Acc: 0.5548\n",
            "Epoch 287/300.. Train Loss: 0.0071.. Train Acc: 0.9977.. Validation Loss: 3.7065.. Validation Acc: 0.5543\n",
            "Epoch 288/300.. Train Loss: 0.0080.. Train Acc: 0.9972.. Validation Loss: 3.6661.. Validation Acc: 0.5586\n",
            "Epoch 289/300.. Train Loss: 0.0064.. Train Acc: 0.9980.. Validation Loss: 3.6657.. Validation Acc: 0.5574\n",
            "Epoch 290/300.. Train Loss: 0.0071.. Train Acc: 0.9978.. Validation Loss: 3.6458.. Validation Acc: 0.5565\n",
            "Epoch 291/300.. Train Loss: 0.0075.. Train Acc: 0.9978.. Validation Loss: 3.6518.. Validation Acc: 0.5571\n",
            "Epoch 292/300.. Train Loss: 0.0068.. Train Acc: 0.9978.. Validation Loss: 3.6357.. Validation Acc: 0.5604\n",
            "Epoch 293/300.. Train Loss: 0.0091.. Train Acc: 0.9970.. Validation Loss: 3.6857.. Validation Acc: 0.5538\n",
            "Epoch 294/300.. Train Loss: 0.0063.. Train Acc: 0.9982.. Validation Loss: 3.6205.. Validation Acc: 0.5562\n",
            "Epoch 295/300.. Train Loss: 0.0057.. Train Acc: 0.9982.. Validation Loss: 3.6429.. Validation Acc: 0.5624\n",
            "Epoch 296/300.. Train Loss: 0.0071.. Train Acc: 0.9978.. Validation Loss: 3.5696.. Validation Acc: 0.5651\n",
            "Epoch 297/300.. Train Loss: 0.0073.. Train Acc: 0.9977.. Validation Loss: 3.6303.. Validation Acc: 0.5551\n",
            "Epoch 298/300.. Train Loss: 0.0068.. Train Acc: 0.9977.. Validation Loss: 3.6196.. Validation Acc: 0.5596\n",
            "Epoch 299/300.. Train Loss: 0.0066.. Train Acc: 0.9978.. Validation Loss: 3.6869.. Validation Acc: 0.5551\n",
            "Epoch 300/300.. Train Loss: 0.0079.. Train Acc: 0.9976.. Validation Loss: 3.6587.. Validation Acc: 0.5603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_acc(stat_training_loss, stat_val_loss, stat_training_acc, stat_val_acc, \"LRS_constant\")"
      ],
      "metadata": {
        "id": "LS4gV4mfyGgd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR = 0.05, LRS = cosine annealing, epochs = 300\n"
      ],
      "metadata": {
        "id": "tamhJH1fGejh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR"
      ],
      "metadata": {
        "id": "brNkNiKAHroH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.05"
      ],
      "metadata": {
        "id": "jI5Z-yVkyGSJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])\n",
        "    ])\n",
        "\n",
        "# Split data set\n",
        "dataset = torchvision.datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(0.8 * num_train))  # 80% for training, 20% for validation\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[:split], indices[split:]\n",
        "\n",
        "train_sampler = data.sampler.SubsetRandomSampler(train_indices)\n",
        "val_sampler = data.sampler.SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=val_sampler)\n",
        ""
      ],
      "metadata": {
        "id": "Q_cC9WLKHUHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = MobileNet(100)\n",
        "#print(model)\n",
        "model.cuda()\n",
        "\n",
        "# criterion\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9) #, weight_decay=args.wd)\n",
        "\n",
        "# scheduler\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=300, eta_min=0)\n"
      ],
      "metadata": {
        "id": "KFRg_4Z7HUC7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stat_training_loss = []\n",
        "stat_val_loss = []\n",
        "stat_training_acc = []\n",
        "stat_val_acc = []"
      ],
      "metadata": {
        "id": "lvjforyOHT_L"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(300):\n",
        "    training_loss = 0\n",
        "    training_acc = 0\n",
        "    training_samples = 0\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    val_samples = 0\n",
        "    # training\n",
        "    model.train()\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "        optimizer.zero_grad()\n",
        "        logits = model.forward(imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, top_class = logits.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape).long()\n",
        "        training_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        training_loss += batch_size * loss.item()\n",
        "        training_samples += batch_size\n",
        "    # validation\n",
        "    model.eval()\n",
        "    for val_imgs, val_labels in valid_loader:\n",
        "        batch_size = val_imgs.shape[0]\n",
        "        val_logits = model.forward(val_imgs.cuda())\n",
        "        loss = criterion(val_logits, val_labels.cuda())\n",
        "        _, top_class = val_logits.topk(1, dim=1)\n",
        "        equals = top_class == val_labels.cuda().view(*top_class.shape)\n",
        "        val_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        val_loss += batch_size * loss.item()\n",
        "        val_samples += batch_size\n",
        "    assert val_samples == 10000\n",
        "    # update stats\n",
        "    stat_training_loss.append(training_loss/training_samples)\n",
        "    stat_val_loss.append(val_loss/val_samples)\n",
        "    stat_training_acc.append(training_acc/training_samples)\n",
        "    stat_val_acc.append(val_acc/val_samples)\n",
        "    # print\n",
        "    #print(f\"Epoch {(epoch+1):d}/{args.epochs:d}.. Learning rate: {scheduler.get_lr()[0]:.4f}.. Train loss: {(training_loss/training_samples):.4f}.. Train acc: {(training_acc/training_samples):.4f}.. Val loss: {(val_loss/val_samples):.4f}.. Val acc: {(val_acc/val_samples):.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{300}.. \"\n",
        "          f\"Learning rate: {scheduler.get_lr()[0]:.4f}.. \"\n",
        "          f\"Train Loss: {training_loss / training_samples:.4f}.. \"\n",
        "          f\"Train Acc: {training_acc / training_samples:.4f}.. \"\n",
        "          f\"Validation Loss: {val_loss / val_samples:.4f}.. \"\n",
        "          f\"Validation Acc: {val_acc / val_samples:.4f}\")\n",
        "    # lr scheduler\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsYpV6odHT7r",
        "outputId": "cd8cf585-e887-4b6b-b100-ac67571a642b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300.. Learning rate: 0.0500.. Train Loss: 4.1851.. Train Acc: 0.0596.. Validation Loss: 3.8559.. Validation Acc: 0.0937\n",
            "Epoch 2/300.. Learning rate: 0.0500.. Train Loss: 3.6212.. Train Acc: 0.1318.. Validation Loss: 3.8221.. Validation Acc: 0.1386\n",
            "Epoch 3/300.. Learning rate: 0.0500.. Train Loss: 3.3223.. Train Acc: 0.1846.. Validation Loss: 3.3195.. Validation Acc: 0.1843\n",
            "Epoch 4/300.. Learning rate: 0.0500.. Train Loss: 3.0858.. Train Acc: 0.2291.. Validation Loss: 3.0747.. Validation Acc: 0.2401\n",
            "Epoch 5/300.. Learning rate: 0.0500.. Train Loss: 2.9189.. Train Acc: 0.2603.. Validation Loss: 2.9188.. Validation Acc: 0.2662\n",
            "Epoch 6/300.. Learning rate: 0.0500.. Train Loss: 2.7178.. Train Acc: 0.2988.. Validation Loss: 2.7258.. Validation Acc: 0.2981\n",
            "Epoch 7/300.. Learning rate: 0.0499.. Train Loss: 2.5356.. Train Acc: 0.3335.. Validation Loss: 2.6893.. Validation Acc: 0.3151\n",
            "Epoch 8/300.. Learning rate: 0.0499.. Train Loss: 2.3886.. Train Acc: 0.3649.. Validation Loss: 2.5226.. Validation Acc: 0.3418\n",
            "Epoch 9/300.. Learning rate: 0.0499.. Train Loss: 2.2690.. Train Acc: 0.3951.. Validation Loss: 2.4193.. Validation Acc: 0.3652\n",
            "Epoch 10/300.. Learning rate: 0.0499.. Train Loss: 2.1438.. Train Acc: 0.4198.. Validation Loss: 2.4471.. Validation Acc: 0.3630\n",
            "Epoch 11/300.. Learning rate: 0.0498.. Train Loss: 2.0448.. Train Acc: 0.4421.. Validation Loss: 2.2763.. Validation Acc: 0.3962\n",
            "Epoch 12/300.. Learning rate: 0.0498.. Train Loss: 1.9526.. Train Acc: 0.4624.. Validation Loss: 2.2089.. Validation Acc: 0.4150\n",
            "Epoch 13/300.. Learning rate: 0.0498.. Train Loss: 1.8612.. Train Acc: 0.4839.. Validation Loss: 2.1523.. Validation Acc: 0.4372\n",
            "Epoch 14/300.. Learning rate: 0.0497.. Train Loss: 1.7928.. Train Acc: 0.4992.. Validation Loss: 2.1346.. Validation Acc: 0.4311\n",
            "Epoch 15/300.. Learning rate: 0.0497.. Train Loss: 1.7176.. Train Acc: 0.5142.. Validation Loss: 2.0984.. Validation Acc: 0.4487\n",
            "Epoch 16/300.. Learning rate: 0.0497.. Train Loss: 1.6425.. Train Acc: 0.5337.. Validation Loss: 2.0938.. Validation Acc: 0.4461\n",
            "Epoch 17/300.. Learning rate: 0.0496.. Train Loss: 1.5798.. Train Acc: 0.5463.. Validation Loss: 2.0072.. Validation Acc: 0.4635\n",
            "Epoch 18/300.. Learning rate: 0.0496.. Train Loss: 1.5127.. Train Acc: 0.5624.. Validation Loss: 1.9771.. Validation Acc: 0.4762\n",
            "Epoch 19/300.. Learning rate: 0.0495.. Train Loss: 1.4529.. Train Acc: 0.5790.. Validation Loss: 1.9690.. Validation Acc: 0.4760\n",
            "Epoch 20/300.. Learning rate: 0.0495.. Train Loss: 1.3956.. Train Acc: 0.5928.. Validation Loss: 2.0278.. Validation Acc: 0.4712\n",
            "Epoch 21/300.. Learning rate: 0.0494.. Train Loss: 1.3358.. Train Acc: 0.6077.. Validation Loss: 1.9912.. Validation Acc: 0.4858\n",
            "Epoch 22/300.. Learning rate: 0.0493.. Train Loss: 1.2936.. Train Acc: 0.6210.. Validation Loss: 2.0241.. Validation Acc: 0.4824\n",
            "Epoch 23/300.. Learning rate: 0.0493.. Train Loss: 1.2356.. Train Acc: 0.6310.. Validation Loss: 1.9474.. Validation Acc: 0.5030\n",
            "Epoch 24/300.. Learning rate: 0.0492.. Train Loss: 1.1837.. Train Acc: 0.6482.. Validation Loss: 1.9314.. Validation Acc: 0.4952\n",
            "Epoch 25/300.. Learning rate: 0.0492.. Train Loss: 1.1350.. Train Acc: 0.6584.. Validation Loss: 1.9991.. Validation Acc: 0.4949\n",
            "Epoch 26/300.. Learning rate: 0.0491.. Train Loss: 1.0782.. Train Acc: 0.6710.. Validation Loss: 1.9403.. Validation Acc: 0.5055\n",
            "Epoch 27/300.. Learning rate: 0.0490.. Train Loss: 1.0340.. Train Acc: 0.6834.. Validation Loss: 2.0111.. Validation Acc: 0.4995\n",
            "Epoch 28/300.. Learning rate: 0.0489.. Train Loss: 0.9857.. Train Acc: 0.6985.. Validation Loss: 2.0466.. Validation Acc: 0.4930\n",
            "Epoch 29/300.. Learning rate: 0.0489.. Train Loss: 0.9417.. Train Acc: 0.7088.. Validation Loss: 2.0386.. Validation Acc: 0.5015\n",
            "Epoch 30/300.. Learning rate: 0.0488.. Train Loss: 0.8951.. Train Acc: 0.7238.. Validation Loss: 2.0451.. Validation Acc: 0.5080\n",
            "Epoch 31/300.. Learning rate: 0.0487.. Train Loss: 0.8497.. Train Acc: 0.7342.. Validation Loss: 2.0742.. Validation Acc: 0.5035\n",
            "Epoch 32/300.. Learning rate: 0.0486.. Train Loss: 0.8042.. Train Acc: 0.7492.. Validation Loss: 2.0938.. Validation Acc: 0.5042\n",
            "Epoch 33/300.. Learning rate: 0.0485.. Train Loss: 0.7662.. Train Acc: 0.7578.. Validation Loss: 2.1245.. Validation Acc: 0.5129\n",
            "Epoch 34/300.. Learning rate: 0.0484.. Train Loss: 0.7158.. Train Acc: 0.7731.. Validation Loss: 2.1351.. Validation Acc: 0.5128\n",
            "Epoch 35/300.. Learning rate: 0.0483.. Train Loss: 0.6873.. Train Acc: 0.7806.. Validation Loss: 2.1685.. Validation Acc: 0.5046\n",
            "Epoch 36/300.. Learning rate: 0.0482.. Train Loss: 0.6501.. Train Acc: 0.7944.. Validation Loss: 2.1968.. Validation Acc: 0.5118\n",
            "Epoch 37/300.. Learning rate: 0.0481.. Train Loss: 0.6097.. Train Acc: 0.8051.. Validation Loss: 2.2061.. Validation Acc: 0.5132\n",
            "Epoch 38/300.. Learning rate: 0.0480.. Train Loss: 0.5752.. Train Acc: 0.8138.. Validation Loss: 2.2114.. Validation Acc: 0.5173\n",
            "Epoch 39/300.. Learning rate: 0.0479.. Train Loss: 0.5303.. Train Acc: 0.8280.. Validation Loss: 2.2636.. Validation Acc: 0.5171\n",
            "Epoch 40/300.. Learning rate: 0.0478.. Train Loss: 0.4866.. Train Acc: 0.8434.. Validation Loss: 2.2458.. Validation Acc: 0.5248\n",
            "Epoch 41/300.. Learning rate: 0.0477.. Train Loss: 0.4783.. Train Acc: 0.8466.. Validation Loss: 2.2889.. Validation Acc: 0.5181\n",
            "Epoch 42/300.. Learning rate: 0.0476.. Train Loss: 0.4466.. Train Acc: 0.8524.. Validation Loss: 2.3214.. Validation Acc: 0.5213\n",
            "Epoch 43/300.. Learning rate: 0.0475.. Train Loss: 0.4099.. Train Acc: 0.8667.. Validation Loss: 2.3822.. Validation Acc: 0.5205\n",
            "Epoch 44/300.. Learning rate: 0.0474.. Train Loss: 0.3986.. Train Acc: 0.8692.. Validation Loss: 2.3465.. Validation Acc: 0.5269\n",
            "Epoch 45/300.. Learning rate: 0.0473.. Train Loss: 0.3620.. Train Acc: 0.8810.. Validation Loss: 2.4101.. Validation Acc: 0.5243\n",
            "Epoch 46/300.. Learning rate: 0.0472.. Train Loss: 0.3307.. Train Acc: 0.8918.. Validation Loss: 2.4281.. Validation Acc: 0.5276\n",
            "Epoch 47/300.. Learning rate: 0.0470.. Train Loss: 0.3208.. Train Acc: 0.8949.. Validation Loss: 2.4732.. Validation Acc: 0.5256\n",
            "Epoch 48/300.. Learning rate: 0.0469.. Train Loss: 0.3115.. Train Acc: 0.8980.. Validation Loss: 2.4519.. Validation Acc: 0.5249\n",
            "Epoch 49/300.. Learning rate: 0.0468.. Train Loss: 0.3056.. Train Acc: 0.9002.. Validation Loss: 2.5292.. Validation Acc: 0.5260\n",
            "Epoch 50/300.. Learning rate: 0.0467.. Train Loss: 0.2726.. Train Acc: 0.9104.. Validation Loss: 2.5597.. Validation Acc: 0.5197\n",
            "Epoch 51/300.. Learning rate: 0.0465.. Train Loss: 0.2551.. Train Acc: 0.9173.. Validation Loss: 2.5305.. Validation Acc: 0.5224\n",
            "Epoch 52/300.. Learning rate: 0.0464.. Train Loss: 0.2478.. Train Acc: 0.9194.. Validation Loss: 2.5604.. Validation Acc: 0.5303\n",
            "Epoch 53/300.. Learning rate: 0.0463.. Train Loss: 0.2167.. Train Acc: 0.9288.. Validation Loss: 2.6098.. Validation Acc: 0.5303\n",
            "Epoch 54/300.. Learning rate: 0.0461.. Train Loss: 0.2083.. Train Acc: 0.9324.. Validation Loss: 2.6065.. Validation Acc: 0.5310\n",
            "Epoch 55/300.. Learning rate: 0.0460.. Train Loss: 0.2061.. Train Acc: 0.9324.. Validation Loss: 2.6270.. Validation Acc: 0.5259\n",
            "Epoch 56/300.. Learning rate: 0.0458.. Train Loss: 0.1929.. Train Acc: 0.9366.. Validation Loss: 2.6957.. Validation Acc: 0.5237\n",
            "Epoch 57/300.. Learning rate: 0.0457.. Train Loss: 0.1884.. Train Acc: 0.9384.. Validation Loss: 2.6990.. Validation Acc: 0.5305\n",
            "Epoch 58/300.. Learning rate: 0.0455.. Train Loss: 0.1730.. Train Acc: 0.9434.. Validation Loss: 2.7141.. Validation Acc: 0.5309\n",
            "Epoch 59/300.. Learning rate: 0.0454.. Train Loss: 0.1556.. Train Acc: 0.9490.. Validation Loss: 2.7780.. Validation Acc: 0.5253\n",
            "Epoch 60/300.. Learning rate: 0.0452.. Train Loss: 0.1485.. Train Acc: 0.9511.. Validation Loss: 2.7224.. Validation Acc: 0.5358\n",
            "Epoch 61/300.. Learning rate: 0.0451.. Train Loss: 0.1462.. Train Acc: 0.9526.. Validation Loss: 2.7270.. Validation Acc: 0.5332\n",
            "Epoch 62/300.. Learning rate: 0.0449.. Train Loss: 0.1477.. Train Acc: 0.9526.. Validation Loss: 2.7497.. Validation Acc: 0.5329\n",
            "Epoch 63/300.. Learning rate: 0.0448.. Train Loss: 0.1394.. Train Acc: 0.9550.. Validation Loss: 2.7566.. Validation Acc: 0.5364\n",
            "Epoch 64/300.. Learning rate: 0.0446.. Train Loss: 0.1302.. Train Acc: 0.9577.. Validation Loss: 2.8219.. Validation Acc: 0.5342\n",
            "Epoch 65/300.. Learning rate: 0.0444.. Train Loss: 0.1251.. Train Acc: 0.9592.. Validation Loss: 2.8062.. Validation Acc: 0.5341\n",
            "Epoch 66/300.. Learning rate: 0.0443.. Train Loss: 0.1092.. Train Acc: 0.9652.. Validation Loss: 2.8502.. Validation Acc: 0.5318\n",
            "Epoch 67/300.. Learning rate: 0.0441.. Train Loss: 0.1120.. Train Acc: 0.9642.. Validation Loss: 2.8393.. Validation Acc: 0.5334\n",
            "Epoch 68/300.. Learning rate: 0.0439.. Train Loss: 0.1068.. Train Acc: 0.9657.. Validation Loss: 2.8397.. Validation Acc: 0.5351\n",
            "Epoch 69/300.. Learning rate: 0.0438.. Train Loss: 0.0987.. Train Acc: 0.9681.. Validation Loss: 2.8819.. Validation Acc: 0.5305\n",
            "Epoch 70/300.. Learning rate: 0.0436.. Train Loss: 0.0945.. Train Acc: 0.9697.. Validation Loss: 2.8727.. Validation Acc: 0.5391\n",
            "Epoch 71/300.. Learning rate: 0.0434.. Train Loss: 0.0904.. Train Acc: 0.9703.. Validation Loss: 2.8961.. Validation Acc: 0.5359\n",
            "Epoch 72/300.. Learning rate: 0.0432.. Train Loss: 0.0876.. Train Acc: 0.9720.. Validation Loss: 2.8555.. Validation Acc: 0.5428\n",
            "Epoch 73/300.. Learning rate: 0.0430.. Train Loss: 0.0809.. Train Acc: 0.9750.. Validation Loss: 2.8992.. Validation Acc: 0.5392\n",
            "Epoch 74/300.. Learning rate: 0.0429.. Train Loss: 0.0777.. Train Acc: 0.9755.. Validation Loss: 2.8701.. Validation Acc: 0.5396\n",
            "Epoch 75/300.. Learning rate: 0.0427.. Train Loss: 0.0690.. Train Acc: 0.9780.. Validation Loss: 2.8770.. Validation Acc: 0.5428\n",
            "Epoch 76/300.. Learning rate: 0.0425.. Train Loss: 0.0763.. Train Acc: 0.9757.. Validation Loss: 2.9622.. Validation Acc: 0.5379\n",
            "Epoch 77/300.. Learning rate: 0.0423.. Train Loss: 0.0676.. Train Acc: 0.9792.. Validation Loss: 2.8768.. Validation Acc: 0.5504\n",
            "Epoch 78/300.. Learning rate: 0.0421.. Train Loss: 0.0640.. Train Acc: 0.9798.. Validation Loss: 2.9026.. Validation Acc: 0.5451\n",
            "Epoch 79/300.. Learning rate: 0.0419.. Train Loss: 0.0659.. Train Acc: 0.9798.. Validation Loss: 2.9347.. Validation Acc: 0.5448\n",
            "Epoch 80/300.. Learning rate: 0.0417.. Train Loss: 0.0631.. Train Acc: 0.9804.. Validation Loss: 2.9344.. Validation Acc: 0.5410\n",
            "Epoch 81/300.. Learning rate: 0.0415.. Train Loss: 0.0608.. Train Acc: 0.9809.. Validation Loss: 2.9644.. Validation Acc: 0.5456\n",
            "Epoch 82/300.. Learning rate: 0.0413.. Train Loss: 0.0584.. Train Acc: 0.9811.. Validation Loss: 2.9748.. Validation Acc: 0.5420\n",
            "Epoch 83/300.. Learning rate: 0.0411.. Train Loss: 0.0534.. Train Acc: 0.9833.. Validation Loss: 2.9681.. Validation Acc: 0.5427\n",
            "Epoch 84/300.. Learning rate: 0.0409.. Train Loss: 0.0525.. Train Acc: 0.9833.. Validation Loss: 2.9916.. Validation Acc: 0.5468\n",
            "Epoch 85/300.. Learning rate: 0.0407.. Train Loss: 0.0481.. Train Acc: 0.9850.. Validation Loss: 2.9897.. Validation Acc: 0.5517\n",
            "Epoch 86/300.. Learning rate: 0.0405.. Train Loss: 0.0435.. Train Acc: 0.9862.. Validation Loss: 3.0177.. Validation Acc: 0.5436\n",
            "Epoch 87/300.. Learning rate: 0.0403.. Train Loss: 0.0495.. Train Acc: 0.9844.. Validation Loss: 3.0001.. Validation Acc: 0.5445\n",
            "Epoch 88/300.. Learning rate: 0.0401.. Train Loss: 0.0436.. Train Acc: 0.9874.. Validation Loss: 3.0726.. Validation Acc: 0.5482\n",
            "Epoch 89/300.. Learning rate: 0.0399.. Train Loss: 0.0386.. Train Acc: 0.9882.. Validation Loss: 3.0963.. Validation Acc: 0.5424\n",
            "Epoch 90/300.. Learning rate: 0.0397.. Train Loss: 0.0409.. Train Acc: 0.9877.. Validation Loss: 3.0510.. Validation Acc: 0.5500\n",
            "Epoch 91/300.. Learning rate: 0.0395.. Train Loss: 0.0359.. Train Acc: 0.9894.. Validation Loss: 3.0622.. Validation Acc: 0.5442\n",
            "Epoch 92/300.. Learning rate: 0.0393.. Train Loss: 0.0399.. Train Acc: 0.9876.. Validation Loss: 3.0385.. Validation Acc: 0.5450\n",
            "Epoch 93/300.. Learning rate: 0.0391.. Train Loss: 0.0375.. Train Acc: 0.9886.. Validation Loss: 3.0755.. Validation Acc: 0.5517\n",
            "Epoch 94/300.. Learning rate: 0.0388.. Train Loss: 0.0365.. Train Acc: 0.9884.. Validation Loss: 3.0308.. Validation Acc: 0.5519\n",
            "Epoch 95/300.. Learning rate: 0.0386.. Train Loss: 0.0351.. Train Acc: 0.9893.. Validation Loss: 3.0503.. Validation Acc: 0.5501\n",
            "Epoch 96/300.. Learning rate: 0.0384.. Train Loss: 0.0343.. Train Acc: 0.9890.. Validation Loss: 3.0473.. Validation Acc: 0.5584\n",
            "Epoch 97/300.. Learning rate: 0.0382.. Train Loss: 0.0311.. Train Acc: 0.9907.. Validation Loss: 3.1003.. Validation Acc: 0.5450\n",
            "Epoch 98/300.. Learning rate: 0.0380.. Train Loss: 0.0287.. Train Acc: 0.9910.. Validation Loss: 3.0532.. Validation Acc: 0.5586\n",
            "Epoch 99/300.. Learning rate: 0.0377.. Train Loss: 0.0294.. Train Acc: 0.9911.. Validation Loss: 3.1102.. Validation Acc: 0.5508\n",
            "Epoch 100/300.. Learning rate: 0.0375.. Train Loss: 0.0302.. Train Acc: 0.9907.. Validation Loss: 3.1170.. Validation Acc: 0.5510\n",
            "Epoch 101/300.. Learning rate: 0.0373.. Train Loss: 0.0265.. Train Acc: 0.9919.. Validation Loss: 3.0681.. Validation Acc: 0.5587\n",
            "Epoch 102/300.. Learning rate: 0.0370.. Train Loss: 0.0221.. Train Acc: 0.9935.. Validation Loss: 3.0961.. Validation Acc: 0.5519\n",
            "Epoch 103/300.. Learning rate: 0.0368.. Train Loss: 0.0239.. Train Acc: 0.9928.. Validation Loss: 3.1294.. Validation Acc: 0.5548\n",
            "Epoch 104/300.. Learning rate: 0.0366.. Train Loss: 0.0246.. Train Acc: 0.9928.. Validation Loss: 3.1312.. Validation Acc: 0.5545\n",
            "Epoch 105/300.. Learning rate: 0.0364.. Train Loss: 0.0226.. Train Acc: 0.9933.. Validation Loss: 3.1109.. Validation Acc: 0.5530\n",
            "Epoch 106/300.. Learning rate: 0.0361.. Train Loss: 0.0232.. Train Acc: 0.9931.. Validation Loss: 3.0997.. Validation Acc: 0.5534\n",
            "Epoch 107/300.. Learning rate: 0.0359.. Train Loss: 0.0217.. Train Acc: 0.9939.. Validation Loss: 3.1822.. Validation Acc: 0.5505\n",
            "Epoch 108/300.. Learning rate: 0.0356.. Train Loss: 0.0193.. Train Acc: 0.9945.. Validation Loss: 3.1561.. Validation Acc: 0.5538\n",
            "Epoch 109/300.. Learning rate: 0.0354.. Train Loss: 0.0201.. Train Acc: 0.9941.. Validation Loss: 3.1623.. Validation Acc: 0.5530\n",
            "Epoch 110/300.. Learning rate: 0.0352.. Train Loss: 0.0193.. Train Acc: 0.9942.. Validation Loss: 3.1510.. Validation Acc: 0.5534\n",
            "Epoch 111/300.. Learning rate: 0.0349.. Train Loss: 0.0196.. Train Acc: 0.9945.. Validation Loss: 3.2138.. Validation Acc: 0.5526\n",
            "Epoch 112/300.. Learning rate: 0.0347.. Train Loss: 0.0196.. Train Acc: 0.9942.. Validation Loss: 3.1650.. Validation Acc: 0.5575\n",
            "Epoch 113/300.. Learning rate: 0.0344.. Train Loss: 0.0179.. Train Acc: 0.9950.. Validation Loss: 3.1908.. Validation Acc: 0.5535\n",
            "Epoch 114/300.. Learning rate: 0.0342.. Train Loss: 0.0186.. Train Acc: 0.9944.. Validation Loss: 3.1308.. Validation Acc: 0.5570\n",
            "Epoch 115/300.. Learning rate: 0.0340.. Train Loss: 0.0178.. Train Acc: 0.9946.. Validation Loss: 3.1573.. Validation Acc: 0.5588\n",
            "Epoch 116/300.. Learning rate: 0.0337.. Train Loss: 0.0151.. Train Acc: 0.9956.. Validation Loss: 3.1444.. Validation Acc: 0.5595\n",
            "Epoch 117/300.. Learning rate: 0.0335.. Train Loss: 0.0155.. Train Acc: 0.9956.. Validation Loss: 3.1548.. Validation Acc: 0.5561\n",
            "Epoch 118/300.. Learning rate: 0.0332.. Train Loss: 0.0131.. Train Acc: 0.9967.. Validation Loss: 3.1685.. Validation Acc: 0.5547\n",
            "Epoch 119/300.. Learning rate: 0.0330.. Train Loss: 0.0142.. Train Acc: 0.9957.. Validation Loss: 3.1869.. Validation Acc: 0.5604\n",
            "Epoch 120/300.. Learning rate: 0.0327.. Train Loss: 0.0133.. Train Acc: 0.9963.. Validation Loss: 3.2234.. Validation Acc: 0.5576\n",
            "Epoch 121/300.. Learning rate: 0.0325.. Train Loss: 0.0120.. Train Acc: 0.9969.. Validation Loss: 3.2330.. Validation Acc: 0.5563\n",
            "Epoch 122/300.. Learning rate: 0.0322.. Train Loss: 0.0114.. Train Acc: 0.9971.. Validation Loss: 3.2477.. Validation Acc: 0.5553\n",
            "Epoch 123/300.. Learning rate: 0.0320.. Train Loss: 0.0116.. Train Acc: 0.9968.. Validation Loss: 3.2009.. Validation Acc: 0.5563\n",
            "Epoch 124/300.. Learning rate: 0.0317.. Train Loss: 0.0095.. Train Acc: 0.9976.. Validation Loss: 3.2320.. Validation Acc: 0.5576\n",
            "Epoch 125/300.. Learning rate: 0.0315.. Train Loss: 0.0101.. Train Acc: 0.9972.. Validation Loss: 3.1999.. Validation Acc: 0.5600\n",
            "Epoch 126/300.. Learning rate: 0.0312.. Train Loss: 0.0107.. Train Acc: 0.9970.. Validation Loss: 3.1649.. Validation Acc: 0.5575\n",
            "Epoch 127/300.. Learning rate: 0.0310.. Train Loss: 0.0097.. Train Acc: 0.9977.. Validation Loss: 3.2246.. Validation Acc: 0.5578\n",
            "Epoch 128/300.. Learning rate: 0.0307.. Train Loss: 0.0096.. Train Acc: 0.9977.. Validation Loss: 3.2213.. Validation Acc: 0.5636\n",
            "Epoch 129/300.. Learning rate: 0.0305.. Train Loss: 0.0090.. Train Acc: 0.9972.. Validation Loss: 3.2164.. Validation Acc: 0.5582\n",
            "Epoch 130/300.. Learning rate: 0.0302.. Train Loss: 0.0100.. Train Acc: 0.9974.. Validation Loss: 3.2295.. Validation Acc: 0.5611\n",
            "Epoch 131/300.. Learning rate: 0.0299.. Train Loss: 0.0101.. Train Acc: 0.9971.. Validation Loss: 3.2406.. Validation Acc: 0.5607\n",
            "Epoch 132/300.. Learning rate: 0.0297.. Train Loss: 0.0090.. Train Acc: 0.9977.. Validation Loss: 3.2475.. Validation Acc: 0.5589\n",
            "Epoch 133/300.. Learning rate: 0.0294.. Train Loss: 0.0085.. Train Acc: 0.9979.. Validation Loss: 3.2310.. Validation Acc: 0.5614\n",
            "Epoch 134/300.. Learning rate: 0.0292.. Train Loss: 0.0084.. Train Acc: 0.9978.. Validation Loss: 3.2465.. Validation Acc: 0.5575\n",
            "Epoch 135/300.. Learning rate: 0.0289.. Train Loss: 0.0060.. Train Acc: 0.9987.. Validation Loss: 3.2356.. Validation Acc: 0.5578\n",
            "Epoch 136/300.. Learning rate: 0.0287.. Train Loss: 0.0091.. Train Acc: 0.9974.. Validation Loss: 3.2338.. Validation Acc: 0.5596\n",
            "Epoch 137/300.. Learning rate: 0.0284.. Train Loss: 0.0080.. Train Acc: 0.9976.. Validation Loss: 3.2301.. Validation Acc: 0.5644\n",
            "Epoch 138/300.. Learning rate: 0.0281.. Train Loss: 0.0078.. Train Acc: 0.9980.. Validation Loss: 3.2537.. Validation Acc: 0.5576\n",
            "Epoch 139/300.. Learning rate: 0.0279.. Train Loss: 0.0076.. Train Acc: 0.9979.. Validation Loss: 3.2224.. Validation Acc: 0.5620\n",
            "Epoch 140/300.. Learning rate: 0.0276.. Train Loss: 0.0069.. Train Acc: 0.9982.. Validation Loss: 3.2164.. Validation Acc: 0.5632\n",
            "Epoch 141/300.. Learning rate: 0.0274.. Train Loss: 0.0066.. Train Acc: 0.9982.. Validation Loss: 3.2677.. Validation Acc: 0.5541\n",
            "Epoch 142/300.. Learning rate: 0.0271.. Train Loss: 0.0068.. Train Acc: 0.9981.. Validation Loss: 3.2293.. Validation Acc: 0.5637\n",
            "Epoch 143/300.. Learning rate: 0.0268.. Train Loss: 0.0068.. Train Acc: 0.9984.. Validation Loss: 3.1981.. Validation Acc: 0.5638\n",
            "Epoch 144/300.. Learning rate: 0.0266.. Train Loss: 0.0069.. Train Acc: 0.9980.. Validation Loss: 3.2545.. Validation Acc: 0.5593\n",
            "Epoch 145/300.. Learning rate: 0.0263.. Train Loss: 0.0057.. Train Acc: 0.9986.. Validation Loss: 3.2531.. Validation Acc: 0.5605\n",
            "Epoch 146/300.. Learning rate: 0.0260.. Train Loss: 0.0057.. Train Acc: 0.9984.. Validation Loss: 3.2361.. Validation Acc: 0.5606\n",
            "Epoch 147/300.. Learning rate: 0.0258.. Train Loss: 0.0048.. Train Acc: 0.9989.. Validation Loss: 3.2584.. Validation Acc: 0.5542\n",
            "Epoch 148/300.. Learning rate: 0.0255.. Train Loss: 0.0056.. Train Acc: 0.9987.. Validation Loss: 3.2271.. Validation Acc: 0.5613\n",
            "Epoch 149/300.. Learning rate: 0.0253.. Train Loss: 0.0058.. Train Acc: 0.9983.. Validation Loss: 3.2349.. Validation Acc: 0.5608\n",
            "Epoch 150/300.. Learning rate: 0.0250.. Train Loss: 0.0049.. Train Acc: 0.9986.. Validation Loss: 3.2394.. Validation Acc: 0.5632\n",
            "Epoch 151/300.. Learning rate: 0.0247.. Train Loss: 0.0055.. Train Acc: 0.9986.. Validation Loss: 3.2565.. Validation Acc: 0.5630\n",
            "Epoch 152/300.. Learning rate: 0.0245.. Train Loss: 0.0063.. Train Acc: 0.9983.. Validation Loss: 3.2810.. Validation Acc: 0.5596\n",
            "Epoch 153/300.. Learning rate: 0.0242.. Train Loss: 0.0051.. Train Acc: 0.9986.. Validation Loss: 3.2479.. Validation Acc: 0.5585\n",
            "Epoch 154/300.. Learning rate: 0.0240.. Train Loss: 0.0045.. Train Acc: 0.9989.. Validation Loss: 3.2561.. Validation Acc: 0.5607\n",
            "Epoch 155/300.. Learning rate: 0.0237.. Train Loss: 0.0047.. Train Acc: 0.9988.. Validation Loss: 3.2331.. Validation Acc: 0.5616\n",
            "Epoch 156/300.. Learning rate: 0.0234.. Train Loss: 0.0042.. Train Acc: 0.9989.. Validation Loss: 3.2622.. Validation Acc: 0.5569\n",
            "Epoch 157/300.. Learning rate: 0.0232.. Train Loss: 0.0038.. Train Acc: 0.9990.. Validation Loss: 3.2371.. Validation Acc: 0.5627\n",
            "Epoch 158/300.. Learning rate: 0.0229.. Train Loss: 0.0042.. Train Acc: 0.9990.. Validation Loss: 3.1939.. Validation Acc: 0.5711\n",
            "Epoch 159/300.. Learning rate: 0.0227.. Train Loss: 0.0037.. Train Acc: 0.9992.. Validation Loss: 3.2414.. Validation Acc: 0.5642\n",
            "Epoch 160/300.. Learning rate: 0.0224.. Train Loss: 0.0040.. Train Acc: 0.9988.. Validation Loss: 3.2294.. Validation Acc: 0.5691\n",
            "Epoch 161/300.. Learning rate: 0.0221.. Train Loss: 0.0044.. Train Acc: 0.9988.. Validation Loss: 3.2426.. Validation Acc: 0.5658\n",
            "Epoch 162/300.. Learning rate: 0.0219.. Train Loss: 0.0039.. Train Acc: 0.9990.. Validation Loss: 3.2896.. Validation Acc: 0.5645\n",
            "Epoch 163/300.. Learning rate: 0.0216.. Train Loss: 0.0040.. Train Acc: 0.9989.. Validation Loss: 3.2293.. Validation Acc: 0.5673\n",
            "Epoch 164/300.. Learning rate: 0.0214.. Train Loss: 0.0042.. Train Acc: 0.9989.. Validation Loss: 3.2708.. Validation Acc: 0.5633\n",
            "Epoch 165/300.. Learning rate: 0.0211.. Train Loss: 0.0035.. Train Acc: 0.9992.. Validation Loss: 3.2703.. Validation Acc: 0.5674\n",
            "Epoch 166/300.. Learning rate: 0.0208.. Train Loss: 0.0035.. Train Acc: 0.9990.. Validation Loss: 3.2414.. Validation Acc: 0.5669\n",
            "Epoch 167/300.. Learning rate: 0.0206.. Train Loss: 0.0034.. Train Acc: 0.9990.. Validation Loss: 3.2771.. Validation Acc: 0.5630\n",
            "Epoch 168/300.. Learning rate: 0.0203.. Train Loss: 0.0036.. Train Acc: 0.9990.. Validation Loss: 3.2530.. Validation Acc: 0.5651\n",
            "Epoch 169/300.. Learning rate: 0.0201.. Train Loss: 0.0035.. Train Acc: 0.9990.. Validation Loss: 3.2859.. Validation Acc: 0.5694\n",
            "Epoch 170/300.. Learning rate: 0.0198.. Train Loss: 0.0033.. Train Acc: 0.9992.. Validation Loss: 3.2591.. Validation Acc: 0.5671\n",
            "Epoch 171/300.. Learning rate: 0.0195.. Train Loss: 0.0033.. Train Acc: 0.9992.. Validation Loss: 3.2557.. Validation Acc: 0.5652\n",
            "Epoch 172/300.. Learning rate: 0.0193.. Train Loss: 0.0028.. Train Acc: 0.9992.. Validation Loss: 3.2753.. Validation Acc: 0.5647\n",
            "Epoch 173/300.. Learning rate: 0.0190.. Train Loss: 0.0032.. Train Acc: 0.9990.. Validation Loss: 3.2553.. Validation Acc: 0.5652\n",
            "Epoch 174/300.. Learning rate: 0.0188.. Train Loss: 0.0029.. Train Acc: 0.9993.. Validation Loss: 3.2618.. Validation Acc: 0.5694\n",
            "Epoch 175/300.. Learning rate: 0.0185.. Train Loss: 0.0032.. Train Acc: 0.9991.. Validation Loss: 3.2671.. Validation Acc: 0.5641\n",
            "Epoch 176/300.. Learning rate: 0.0183.. Train Loss: 0.0028.. Train Acc: 0.9993.. Validation Loss: 3.2872.. Validation Acc: 0.5654\n",
            "Epoch 177/300.. Learning rate: 0.0180.. Train Loss: 0.0025.. Train Acc: 0.9993.. Validation Loss: 3.2884.. Validation Acc: 0.5672\n",
            "Epoch 178/300.. Learning rate: 0.0178.. Train Loss: 0.0025.. Train Acc: 0.9993.. Validation Loss: 3.2684.. Validation Acc: 0.5674\n",
            "Epoch 179/300.. Learning rate: 0.0175.. Train Loss: 0.0025.. Train Acc: 0.9993.. Validation Loss: 3.2694.. Validation Acc: 0.5658\n",
            "Epoch 180/300.. Learning rate: 0.0173.. Train Loss: 0.0025.. Train Acc: 0.9993.. Validation Loss: 3.2595.. Validation Acc: 0.5633\n",
            "Epoch 181/300.. Learning rate: 0.0170.. Train Loss: 0.0025.. Train Acc: 0.9992.. Validation Loss: 3.2500.. Validation Acc: 0.5643\n",
            "Epoch 182/300.. Learning rate: 0.0168.. Train Loss: 0.0024.. Train Acc: 0.9993.. Validation Loss: 3.2969.. Validation Acc: 0.5646\n",
            "Epoch 183/300.. Learning rate: 0.0165.. Train Loss: 0.0024.. Train Acc: 0.9993.. Validation Loss: 3.2585.. Validation Acc: 0.5702\n",
            "Epoch 184/300.. Learning rate: 0.0163.. Train Loss: 0.0024.. Train Acc: 0.9994.. Validation Loss: 3.2874.. Validation Acc: 0.5694\n",
            "Epoch 185/300.. Learning rate: 0.0160.. Train Loss: 0.0022.. Train Acc: 0.9995.. Validation Loss: 3.2776.. Validation Acc: 0.5660\n",
            "Epoch 186/300.. Learning rate: 0.0158.. Train Loss: 0.0029.. Train Acc: 0.9991.. Validation Loss: 3.2991.. Validation Acc: 0.5662\n",
            "Epoch 187/300.. Learning rate: 0.0156.. Train Loss: 0.0022.. Train Acc: 0.9995.. Validation Loss: 3.2885.. Validation Acc: 0.5624\n",
            "Epoch 188/300.. Learning rate: 0.0153.. Train Loss: 0.0021.. Train Acc: 0.9995.. Validation Loss: 3.2485.. Validation Acc: 0.5670\n",
            "Epoch 189/300.. Learning rate: 0.0151.. Train Loss: 0.0022.. Train Acc: 0.9995.. Validation Loss: 3.2460.. Validation Acc: 0.5716\n",
            "Epoch 190/300.. Learning rate: 0.0148.. Train Loss: 0.0024.. Train Acc: 0.9994.. Validation Loss: 3.2763.. Validation Acc: 0.5701\n",
            "Epoch 191/300.. Learning rate: 0.0146.. Train Loss: 0.0026.. Train Acc: 0.9994.. Validation Loss: 3.2741.. Validation Acc: 0.5677\n",
            "Epoch 192/300.. Learning rate: 0.0144.. Train Loss: 0.0022.. Train Acc: 0.9994.. Validation Loss: 3.2666.. Validation Acc: 0.5666\n",
            "Epoch 193/300.. Learning rate: 0.0141.. Train Loss: 0.0021.. Train Acc: 0.9995.. Validation Loss: 3.2737.. Validation Acc: 0.5684\n",
            "Epoch 194/300.. Learning rate: 0.0139.. Train Loss: 0.0024.. Train Acc: 0.9991.. Validation Loss: 3.2851.. Validation Acc: 0.5649\n",
            "Epoch 195/300.. Learning rate: 0.0137.. Train Loss: 0.0025.. Train Acc: 0.9992.. Validation Loss: 3.3001.. Validation Acc: 0.5650\n",
            "Epoch 196/300.. Learning rate: 0.0134.. Train Loss: 0.0021.. Train Acc: 0.9994.. Validation Loss: 3.2805.. Validation Acc: 0.5651\n",
            "Epoch 197/300.. Learning rate: 0.0132.. Train Loss: 0.0022.. Train Acc: 0.9994.. Validation Loss: 3.2564.. Validation Acc: 0.5681\n",
            "Epoch 198/300.. Learning rate: 0.0130.. Train Loss: 0.0020.. Train Acc: 0.9995.. Validation Loss: 3.2969.. Validation Acc: 0.5658\n",
            "Epoch 199/300.. Learning rate: 0.0127.. Train Loss: 0.0023.. Train Acc: 0.9993.. Validation Loss: 3.2853.. Validation Acc: 0.5643\n",
            "Epoch 200/300.. Learning rate: 0.0125.. Train Loss: 0.0022.. Train Acc: 0.9993.. Validation Loss: 3.2615.. Validation Acc: 0.5689\n",
            "Epoch 201/300.. Learning rate: 0.0123.. Train Loss: 0.0021.. Train Acc: 0.9995.. Validation Loss: 3.2783.. Validation Acc: 0.5646\n",
            "Epoch 202/300.. Learning rate: 0.0121.. Train Loss: 0.0020.. Train Acc: 0.9995.. Validation Loss: 3.2743.. Validation Acc: 0.5678\n",
            "Epoch 203/300.. Learning rate: 0.0118.. Train Loss: 0.0021.. Train Acc: 0.9994.. Validation Loss: 3.2594.. Validation Acc: 0.5732\n",
            "Epoch 204/300.. Learning rate: 0.0116.. Train Loss: 0.0022.. Train Acc: 0.9993.. Validation Loss: 3.2860.. Validation Acc: 0.5681\n",
            "Epoch 205/300.. Learning rate: 0.0114.. Train Loss: 0.0022.. Train Acc: 0.9993.. Validation Loss: 3.2589.. Validation Acc: 0.5677\n",
            "Epoch 206/300.. Learning rate: 0.0112.. Train Loss: 0.0023.. Train Acc: 0.9994.. Validation Loss: 3.2585.. Validation Acc: 0.5709\n",
            "Epoch 207/300.. Learning rate: 0.0110.. Train Loss: 0.0018.. Train Acc: 0.9995.. Validation Loss: 3.2958.. Validation Acc: 0.5638\n",
            "Epoch 208/300.. Learning rate: 0.0107.. Train Loss: 0.0019.. Train Acc: 0.9995.. Validation Loss: 3.3017.. Validation Acc: 0.5636\n",
            "Epoch 209/300.. Learning rate: 0.0105.. Train Loss: 0.0020.. Train Acc: 0.9995.. Validation Loss: 3.2843.. Validation Acc: 0.5688\n",
            "Epoch 210/300.. Learning rate: 0.0103.. Train Loss: 0.0020.. Train Acc: 0.9995.. Validation Loss: 3.2759.. Validation Acc: 0.5677\n",
            "Epoch 211/300.. Learning rate: 0.0101.. Train Loss: 0.0018.. Train Acc: 0.9996.. Validation Loss: 3.3006.. Validation Acc: 0.5661\n",
            "Epoch 212/300.. Learning rate: 0.0099.. Train Loss: 0.0020.. Train Acc: 0.9993.. Validation Loss: 3.2421.. Validation Acc: 0.5724\n",
            "Epoch 213/300.. Learning rate: 0.0097.. Train Loss: 0.0018.. Train Acc: 0.9996.. Validation Loss: 3.2779.. Validation Acc: 0.5699\n",
            "Epoch 214/300.. Learning rate: 0.0095.. Train Loss: 0.0019.. Train Acc: 0.9994.. Validation Loss: 3.2823.. Validation Acc: 0.5708\n",
            "Epoch 215/300.. Learning rate: 0.0093.. Train Loss: 0.0019.. Train Acc: 0.9993.. Validation Loss: 3.2866.. Validation Acc: 0.5661\n",
            "Epoch 216/300.. Learning rate: 0.0091.. Train Loss: 0.0017.. Train Acc: 0.9994.. Validation Loss: 3.2605.. Validation Acc: 0.5723\n",
            "Epoch 217/300.. Learning rate: 0.0089.. Train Loss: 0.0019.. Train Acc: 0.9994.. Validation Loss: 3.2858.. Validation Acc: 0.5707\n",
            "Epoch 218/300.. Learning rate: 0.0087.. Train Loss: 0.0019.. Train Acc: 0.9993.. Validation Loss: 3.2820.. Validation Acc: 0.5726\n",
            "Epoch 219/300.. Learning rate: 0.0085.. Train Loss: 0.0020.. Train Acc: 0.9993.. Validation Loss: 3.2746.. Validation Acc: 0.5668\n",
            "Epoch 220/300.. Learning rate: 0.0083.. Train Loss: 0.0016.. Train Acc: 0.9995.. Validation Loss: 3.2751.. Validation Acc: 0.5704\n",
            "Epoch 221/300.. Learning rate: 0.0081.. Train Loss: 0.0016.. Train Acc: 0.9996.. Validation Loss: 3.2822.. Validation Acc: 0.5661\n",
            "Epoch 222/300.. Learning rate: 0.0079.. Train Loss: 0.0015.. Train Acc: 0.9996.. Validation Loss: 3.2932.. Validation Acc: 0.5695\n",
            "Epoch 223/300.. Learning rate: 0.0077.. Train Loss: 0.0017.. Train Acc: 0.9996.. Validation Loss: 3.3128.. Validation Acc: 0.5700\n",
            "Epoch 224/300.. Learning rate: 0.0075.. Train Loss: 0.0016.. Train Acc: 0.9996.. Validation Loss: 3.2651.. Validation Acc: 0.5712\n",
            "Epoch 225/300.. Learning rate: 0.0073.. Train Loss: 0.0014.. Train Acc: 0.9997.. Validation Loss: 3.2936.. Validation Acc: 0.5701\n",
            "Epoch 226/300.. Learning rate: 0.0071.. Train Loss: 0.0020.. Train Acc: 0.9994.. Validation Loss: 3.3048.. Validation Acc: 0.5680\n",
            "Epoch 227/300.. Learning rate: 0.0070.. Train Loss: 0.0014.. Train Acc: 0.9997.. Validation Loss: 3.2977.. Validation Acc: 0.5690\n",
            "Epoch 228/300.. Learning rate: 0.0068.. Train Loss: 0.0017.. Train Acc: 0.9996.. Validation Loss: 3.2386.. Validation Acc: 0.5707\n",
            "Epoch 229/300.. Learning rate: 0.0066.. Train Loss: 0.0014.. Train Acc: 0.9997.. Validation Loss: 3.2962.. Validation Acc: 0.5693\n",
            "Epoch 230/300.. Learning rate: 0.0064.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.3044.. Validation Acc: 0.5663\n",
            "Epoch 231/300.. Learning rate: 0.0062.. Train Loss: 0.0017.. Train Acc: 0.9995.. Validation Loss: 3.3301.. Validation Acc: 0.5714\n",
            "Epoch 232/300.. Learning rate: 0.0061.. Train Loss: 0.0015.. Train Acc: 0.9996.. Validation Loss: 3.2866.. Validation Acc: 0.5729\n",
            "Epoch 233/300.. Learning rate: 0.0059.. Train Loss: 0.0017.. Train Acc: 0.9995.. Validation Loss: 3.2515.. Validation Acc: 0.5739\n",
            "Epoch 234/300.. Learning rate: 0.0057.. Train Loss: 0.0015.. Train Acc: 0.9996.. Validation Loss: 3.2645.. Validation Acc: 0.5698\n",
            "Epoch 235/300.. Learning rate: 0.0056.. Train Loss: 0.0014.. Train Acc: 0.9996.. Validation Loss: 3.2702.. Validation Acc: 0.5753\n",
            "Epoch 236/300.. Learning rate: 0.0054.. Train Loss: 0.0015.. Train Acc: 0.9997.. Validation Loss: 3.2934.. Validation Acc: 0.5729\n",
            "Epoch 237/300.. Learning rate: 0.0052.. Train Loss: 0.0019.. Train Acc: 0.9994.. Validation Loss: 3.2796.. Validation Acc: 0.5720\n",
            "Epoch 238/300.. Learning rate: 0.0051.. Train Loss: 0.0014.. Train Acc: 0.9996.. Validation Loss: 3.2942.. Validation Acc: 0.5719\n",
            "Epoch 239/300.. Learning rate: 0.0049.. Train Loss: 0.0016.. Train Acc: 0.9996.. Validation Loss: 3.2345.. Validation Acc: 0.5757\n",
            "Epoch 240/300.. Learning rate: 0.0048.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.3016.. Validation Acc: 0.5698\n",
            "Epoch 241/300.. Learning rate: 0.0046.. Train Loss: 0.0014.. Train Acc: 0.9996.. Validation Loss: 3.2883.. Validation Acc: 0.5693\n",
            "Epoch 242/300.. Learning rate: 0.0045.. Train Loss: 0.0015.. Train Acc: 0.9996.. Validation Loss: 3.2893.. Validation Acc: 0.5678\n",
            "Epoch 243/300.. Learning rate: 0.0043.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.2939.. Validation Acc: 0.5671\n",
            "Epoch 244/300.. Learning rate: 0.0042.. Train Loss: 0.0013.. Train Acc: 0.9996.. Validation Loss: 3.3112.. Validation Acc: 0.5709\n",
            "Epoch 245/300.. Learning rate: 0.0040.. Train Loss: 0.0015.. Train Acc: 0.9996.. Validation Loss: 3.2978.. Validation Acc: 0.5719\n",
            "Epoch 246/300.. Learning rate: 0.0039.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.2631.. Validation Acc: 0.5720\n",
            "Epoch 247/300.. Learning rate: 0.0038.. Train Loss: 0.0015.. Train Acc: 0.9995.. Validation Loss: 3.3288.. Validation Acc: 0.5718\n",
            "Epoch 248/300.. Learning rate: 0.0036.. Train Loss: 0.0012.. Train Acc: 0.9997.. Validation Loss: 3.2818.. Validation Acc: 0.5679\n",
            "Epoch 249/300.. Learning rate: 0.0035.. Train Loss: 0.0015.. Train Acc: 0.9996.. Validation Loss: 3.2952.. Validation Acc: 0.5660\n",
            "Epoch 250/300.. Learning rate: 0.0034.. Train Loss: 0.0012.. Train Acc: 0.9998.. Validation Loss: 3.3006.. Validation Acc: 0.5671\n",
            "Epoch 251/300.. Learning rate: 0.0032.. Train Loss: 0.0016.. Train Acc: 0.9996.. Validation Loss: 3.2864.. Validation Acc: 0.5737\n",
            "Epoch 252/300.. Learning rate: 0.0031.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.2792.. Validation Acc: 0.5655\n",
            "Epoch 253/300.. Learning rate: 0.0030.. Train Loss: 0.0014.. Train Acc: 0.9995.. Validation Loss: 3.2931.. Validation Acc: 0.5721\n",
            "Epoch 254/300.. Learning rate: 0.0028.. Train Loss: 0.0019.. Train Acc: 0.9993.. Validation Loss: 3.3170.. Validation Acc: 0.5644\n",
            "Epoch 255/300.. Learning rate: 0.0027.. Train Loss: 0.0013.. Train Acc: 0.9996.. Validation Loss: 3.2860.. Validation Acc: 0.5714\n",
            "Epoch 256/300.. Learning rate: 0.0026.. Train Loss: 0.0016.. Train Acc: 0.9996.. Validation Loss: 3.2752.. Validation Acc: 0.5698\n",
            "Epoch 257/300.. Learning rate: 0.0025.. Train Loss: 0.0014.. Train Acc: 0.9996.. Validation Loss: 3.3078.. Validation Acc: 0.5703\n",
            "Epoch 258/300.. Learning rate: 0.0024.. Train Loss: 0.0012.. Train Acc: 0.9998.. Validation Loss: 3.3020.. Validation Acc: 0.5651\n",
            "Epoch 259/300.. Learning rate: 0.0023.. Train Loss: 0.0015.. Train Acc: 0.9997.. Validation Loss: 3.2715.. Validation Acc: 0.5703\n",
            "Epoch 260/300.. Learning rate: 0.0022.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.2434.. Validation Acc: 0.5738\n",
            "Epoch 261/300.. Learning rate: 0.0021.. Train Loss: 0.0015.. Train Acc: 0.9996.. Validation Loss: 3.2821.. Validation Acc: 0.5697\n",
            "Epoch 262/300.. Learning rate: 0.0020.. Train Loss: 0.0012.. Train Acc: 0.9998.. Validation Loss: 3.2480.. Validation Acc: 0.5688\n",
            "Epoch 263/300.. Learning rate: 0.0019.. Train Loss: 0.0015.. Train Acc: 0.9996.. Validation Loss: 3.2923.. Validation Acc: 0.5647\n",
            "Epoch 264/300.. Learning rate: 0.0018.. Train Loss: 0.0015.. Train Acc: 0.9996.. Validation Loss: 3.2912.. Validation Acc: 0.5697\n",
            "Epoch 265/300.. Learning rate: 0.0017.. Train Loss: 0.0015.. Train Acc: 0.9995.. Validation Loss: 3.2925.. Validation Acc: 0.5709\n",
            "Epoch 266/300.. Learning rate: 0.0016.. Train Loss: 0.0013.. Train Acc: 0.9996.. Validation Loss: 3.2532.. Validation Acc: 0.5679\n",
            "Epoch 267/300.. Learning rate: 0.0015.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.2676.. Validation Acc: 0.5685\n",
            "Epoch 268/300.. Learning rate: 0.0014.. Train Loss: 0.0015.. Train Acc: 0.9997.. Validation Loss: 3.2857.. Validation Acc: 0.5678\n",
            "Epoch 269/300.. Learning rate: 0.0013.. Train Loss: 0.0013.. Train Acc: 0.9996.. Validation Loss: 3.2531.. Validation Acc: 0.5712\n",
            "Epoch 270/300.. Learning rate: 0.0012.. Train Loss: 0.0013.. Train Acc: 0.9996.. Validation Loss: 3.2802.. Validation Acc: 0.5706\n",
            "Epoch 271/300.. Learning rate: 0.0011.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.2948.. Validation Acc: 0.5667\n",
            "Epoch 272/300.. Learning rate: 0.0011.. Train Loss: 0.0011.. Train Acc: 0.9998.. Validation Loss: 3.2493.. Validation Acc: 0.5717\n",
            "Epoch 273/300.. Learning rate: 0.0010.. Train Loss: 0.0017.. Train Acc: 0.9994.. Validation Loss: 3.2709.. Validation Acc: 0.5679\n",
            "Epoch 274/300.. Learning rate: 0.0009.. Train Loss: 0.0012.. Train Acc: 0.9997.. Validation Loss: 3.2823.. Validation Acc: 0.5692\n",
            "Epoch 275/300.. Learning rate: 0.0009.. Train Loss: 0.0015.. Train Acc: 0.9996.. Validation Loss: 3.2958.. Validation Acc: 0.5710\n",
            "Epoch 276/300.. Learning rate: 0.0008.. Train Loss: 0.0014.. Train Acc: 0.9995.. Validation Loss: 3.3049.. Validation Acc: 0.5683\n",
            "Epoch 277/300.. Learning rate: 0.0007.. Train Loss: 0.0015.. Train Acc: 0.9996.. Validation Loss: 3.2789.. Validation Acc: 0.5673\n",
            "Epoch 278/300.. Learning rate: 0.0007.. Train Loss: 0.0013.. Train Acc: 0.9996.. Validation Loss: 3.2383.. Validation Acc: 0.5728\n",
            "Epoch 279/300.. Learning rate: 0.0006.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.3096.. Validation Acc: 0.5695\n",
            "Epoch 280/300.. Learning rate: 0.0005.. Train Loss: 0.0014.. Train Acc: 0.9996.. Validation Loss: 3.2634.. Validation Acc: 0.5777\n",
            "Epoch 281/300.. Learning rate: 0.0005.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.2997.. Validation Acc: 0.5720\n",
            "Epoch 282/300.. Learning rate: 0.0004.. Train Loss: 0.0014.. Train Acc: 0.9997.. Validation Loss: 3.2796.. Validation Acc: 0.5677\n",
            "Epoch 283/300.. Learning rate: 0.0004.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.2823.. Validation Acc: 0.5732\n",
            "Epoch 284/300.. Learning rate: 0.0004.. Train Loss: 0.0012.. Train Acc: 0.9997.. Validation Loss: 3.2836.. Validation Acc: 0.5709\n",
            "Epoch 285/300.. Learning rate: 0.0003.. Train Loss: 0.0012.. Train Acc: 0.9998.. Validation Loss: 3.2456.. Validation Acc: 0.5719\n",
            "Epoch 286/300.. Learning rate: 0.0003.. Train Loss: 0.0011.. Train Acc: 0.9998.. Validation Loss: 3.2853.. Validation Acc: 0.5677\n",
            "Epoch 287/300.. Learning rate: 0.0002.. Train Loss: 0.0011.. Train Acc: 0.9998.. Validation Loss: 3.2962.. Validation Acc: 0.5693\n",
            "Epoch 288/300.. Learning rate: 0.0002.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.2776.. Validation Acc: 0.5711\n",
            "Epoch 289/300.. Learning rate: 0.0002.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.3138.. Validation Acc: 0.5659\n",
            "Epoch 290/300.. Learning rate: 0.0001.. Train Loss: 0.0011.. Train Acc: 0.9999.. Validation Loss: 3.2773.. Validation Acc: 0.5733\n",
            "Epoch 291/300.. Learning rate: 0.0001.. Train Loss: 0.0013.. Train Acc: 0.9996.. Validation Loss: 3.2909.. Validation Acc: 0.5692\n",
            "Epoch 292/300.. Learning rate: 0.0001.. Train Loss: 0.0015.. Train Acc: 0.9995.. Validation Loss: 3.3055.. Validation Acc: 0.5669\n",
            "Epoch 293/300.. Learning rate: 0.0001.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.2802.. Validation Acc: 0.5695\n",
            "Epoch 294/300.. Learning rate: 0.0001.. Train Loss: 0.0014.. Train Acc: 0.9997.. Validation Loss: 3.2352.. Validation Acc: 0.5700\n",
            "Epoch 295/300.. Learning rate: 0.0000.. Train Loss: 0.0012.. Train Acc: 0.9997.. Validation Loss: 3.2787.. Validation Acc: 0.5731\n",
            "Epoch 296/300.. Learning rate: 0.0000.. Train Loss: 0.0015.. Train Acc: 0.9996.. Validation Loss: 3.3104.. Validation Acc: 0.5698\n",
            "Epoch 297/300.. Learning rate: 0.0000.. Train Loss: 0.0014.. Train Acc: 0.9996.. Validation Loss: 3.2984.. Validation Acc: 0.5715\n",
            "Epoch 298/300.. Learning rate: 0.0000.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.2844.. Validation Acc: 0.5714\n",
            "Epoch 299/300.. Learning rate: 0.0000.. Train Loss: 0.0013.. Train Acc: 0.9997.. Validation Loss: 3.2880.. Validation Acc: 0.5700\n",
            "Epoch 300/300.. Learning rate: 0.0000.. Train Loss: 0.0011.. Train Acc: 0.9998.. Validation Loss: 3.2638.. Validation Acc: 0.5720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_acc(stat_training_loss, stat_val_loss, stat_training_acc, stat_val_acc, \"LRS_cosine\")"
      ],
      "metadata": {
        "id": "2BUyLdSGJIdv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight Decay"
      ],
      "metadata": {
        "id": "zrz43BjbahDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR = 0.05, LRS = cosine annealing, weight decay coefficient = λ = 5 × 10−4\n"
      ],
      "metadata": {
        "id": "D1les-eNbGD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.05"
      ],
      "metadata": {
        "id": "1UCek3OyZJ2o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])\n",
        "    ])\n",
        "\n",
        "# Split data set\n",
        "dataset = torchvision.datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(0.8 * num_train))  # 80% for training, 20% for validation\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[:split], indices[split:]\n",
        "\n",
        "train_sampler = data.sampler.SubsetRandomSampler(train_indices)\n",
        "val_sampler = data.sampler.SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=val_sampler)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqXNaBBEZJ0A",
        "outputId": "1f4f9fc0-54a0-434f-d206-e5c7a2fe5eb6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:06<00:00, 27957533.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = MobileNet(100)\n",
        "#print(model)\n",
        "model.cuda()\n",
        "\n",
        "# criterion\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# scheduler\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=300, eta_min=0)\n"
      ],
      "metadata": {
        "id": "4JA-4jRgYveQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stat_training_loss = []\n",
        "stat_val_loss = []\n",
        "stat_training_acc = []\n",
        "stat_val_acc = []"
      ],
      "metadata": {
        "id": "zZft3rnTYvaF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(300):\n",
        "    training_loss = 0\n",
        "    training_acc = 0\n",
        "    training_samples = 0\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    val_samples = 0\n",
        "    # training\n",
        "    model.train()\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "        optimizer.zero_grad()\n",
        "        logits = model.forward(imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, top_class = logits.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape).long()\n",
        "        training_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        training_loss += batch_size * loss.item()\n",
        "        training_samples += batch_size\n",
        "    # validation\n",
        "    model.eval()\n",
        "    for val_imgs, val_labels in valid_loader:\n",
        "        batch_size = val_imgs.shape[0]\n",
        "        val_logits = model.forward(val_imgs.cuda())\n",
        "        loss = criterion(val_logits, val_labels.cuda())\n",
        "        _, top_class = val_logits.topk(1, dim=1)\n",
        "        equals = top_class == val_labels.cuda().view(*top_class.shape)\n",
        "        val_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        val_loss += batch_size * loss.item()\n",
        "        val_samples += batch_size\n",
        "    assert val_samples == 10000\n",
        "    # update stats\n",
        "    stat_training_loss.append(training_loss/training_samples)\n",
        "    stat_val_loss.append(val_loss/val_samples)\n",
        "    stat_training_acc.append(training_acc/training_samples)\n",
        "    stat_val_acc.append(val_acc/val_samples)\n",
        "    # print\n",
        "    #print(f\"Epoch {(epoch+1):d}/{args.epochs:d}.. Learning rate: {scheduler.get_lr()[0]:.4f}.. Train loss: {(training_loss/training_samples):.4f}.. Train acc: {(training_acc/training_samples):.4f}.. Val loss: {(val_loss/val_samples):.4f}.. Val acc: {(val_acc/val_samples):.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{300}.. \"\n",
        "          f\"Learning rate: {scheduler.get_lr()[0]:.4f}.. \"\n",
        "          f\"Train Loss: {training_loss / training_samples:.4f}.. \"\n",
        "          f\"Train Acc: {training_acc / training_samples:.4f}.. \"\n",
        "          f\"Validation Loss: {val_loss / val_samples:.4f}.. \"\n",
        "          f\"Validation Acc: {val_acc / val_samples:.4f}\")\n",
        "    # lr scheduler\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_tKEuVBZj8h",
        "outputId": "671655f4-f863-4a1a-f60d-be50922a32a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300.. Learning rate: 0.0500.. Train Loss: 4.1519.. Train Acc: 0.0637.. Validation Loss: 3.8179.. Validation Acc: 0.0994\n",
            "Epoch 2/300.. Learning rate: 0.0500.. Train Loss: 3.6183.. Train Acc: 0.1333.. Validation Loss: 3.5540.. Validation Acc: 0.1491\n",
            "Epoch 3/300.. Learning rate: 0.0500.. Train Loss: 3.3399.. Train Acc: 0.1815.. Validation Loss: 3.3994.. Validation Acc: 0.1777\n",
            "Epoch 4/300.. Learning rate: 0.0500.. Train Loss: 3.0918.. Train Acc: 0.2265.. Validation Loss: 3.1344.. Validation Acc: 0.2158\n",
            "Epoch 5/300.. Learning rate: 0.0500.. Train Loss: 2.8662.. Train Acc: 0.2684.. Validation Loss: 2.9989.. Validation Acc: 0.2481\n",
            "Epoch 6/300.. Learning rate: 0.0500.. Train Loss: 2.6619.. Train Acc: 0.3086.. Validation Loss: 2.7307.. Validation Acc: 0.2939\n",
            "Epoch 7/300.. Learning rate: 0.0499.. Train Loss: 2.5021.. Train Acc: 0.3403.. Validation Loss: 2.6032.. Validation Acc: 0.3154\n",
            "Epoch 8/300.. Learning rate: 0.0499.. Train Loss: 2.3643.. Train Acc: 0.3683.. Validation Loss: 2.5540.. Validation Acc: 0.3331\n",
            "Epoch 9/300.. Learning rate: 0.0499.. Train Loss: 2.2471.. Train Acc: 0.3922.. Validation Loss: 2.4149.. Validation Acc: 0.3707\n",
            "Epoch 10/300.. Learning rate: 0.0499.. Train Loss: 2.1406.. Train Acc: 0.4180.. Validation Loss: 2.4304.. Validation Acc: 0.3623\n",
            "Epoch 11/300.. Learning rate: 0.0498.. Train Loss: 2.0519.. Train Acc: 0.4387.. Validation Loss: 2.2830.. Validation Acc: 0.3906\n",
            "Epoch 12/300.. Learning rate: 0.0498.. Train Loss: 1.9924.. Train Acc: 0.4524.. Validation Loss: 2.5021.. Validation Acc: 0.3567\n",
            "Epoch 13/300.. Learning rate: 0.0498.. Train Loss: 1.9261.. Train Acc: 0.4685.. Validation Loss: 2.1602.. Validation Acc: 0.4247\n",
            "Epoch 14/300.. Learning rate: 0.0497.. Train Loss: 1.8686.. Train Acc: 0.4805.. Validation Loss: 2.1810.. Validation Acc: 0.4183\n",
            "Epoch 15/300.. Learning rate: 0.0497.. Train Loss: 1.8163.. Train Acc: 0.4966.. Validation Loss: 2.0952.. Validation Acc: 0.4274\n",
            "Epoch 16/300.. Learning rate: 0.0497.. Train Loss: 1.7783.. Train Acc: 0.5015.. Validation Loss: 2.0576.. Validation Acc: 0.4397\n",
            "Epoch 17/300.. Learning rate: 0.0496.. Train Loss: 1.7352.. Train Acc: 0.5122.. Validation Loss: 2.0178.. Validation Acc: 0.4455\n",
            "Epoch 18/300.. Learning rate: 0.0496.. Train Loss: 1.7075.. Train Acc: 0.5217.. Validation Loss: 2.0417.. Validation Acc: 0.4510\n",
            "Epoch 19/300.. Learning rate: 0.0495.. Train Loss: 1.6681.. Train Acc: 0.5310.. Validation Loss: 2.0306.. Validation Acc: 0.4535\n",
            "Epoch 20/300.. Learning rate: 0.0495.. Train Loss: 1.6471.. Train Acc: 0.5354.. Validation Loss: 2.1161.. Validation Acc: 0.4342\n",
            "Epoch 21/300.. Learning rate: 0.0494.. Train Loss: 1.6143.. Train Acc: 0.5406.. Validation Loss: 1.9723.. Validation Acc: 0.4673\n",
            "Epoch 22/300.. Learning rate: 0.0493.. Train Loss: 1.6048.. Train Acc: 0.5442.. Validation Loss: 1.9551.. Validation Acc: 0.4721\n",
            "Epoch 23/300.. Learning rate: 0.0493.. Train Loss: 1.5741.. Train Acc: 0.5528.. Validation Loss: 2.0184.. Validation Acc: 0.4619\n",
            "Epoch 24/300.. Learning rate: 0.0492.. Train Loss: 1.5516.. Train Acc: 0.5567.. Validation Loss: 1.9415.. Validation Acc: 0.4796\n",
            "Epoch 25/300.. Learning rate: 0.0492.. Train Loss: 1.5362.. Train Acc: 0.5618.. Validation Loss: 2.0025.. Validation Acc: 0.4530\n",
            "Epoch 26/300.. Learning rate: 0.0491.. Train Loss: 1.5189.. Train Acc: 0.5660.. Validation Loss: 2.0602.. Validation Acc: 0.4542\n",
            "Epoch 27/300.. Learning rate: 0.0490.. Train Loss: 1.5042.. Train Acc: 0.5695.. Validation Loss: 2.0149.. Validation Acc: 0.4612\n",
            "Epoch 28/300.. Learning rate: 0.0489.. Train Loss: 1.4781.. Train Acc: 0.5766.. Validation Loss: 1.9649.. Validation Acc: 0.4735\n",
            "Epoch 29/300.. Learning rate: 0.0489.. Train Loss: 1.4693.. Train Acc: 0.5799.. Validation Loss: 2.0064.. Validation Acc: 0.4643\n",
            "Epoch 30/300.. Learning rate: 0.0488.. Train Loss: 1.4611.. Train Acc: 0.5799.. Validation Loss: 1.9737.. Validation Acc: 0.4780\n",
            "Epoch 31/300.. Learning rate: 0.0487.. Train Loss: 1.4476.. Train Acc: 0.5848.. Validation Loss: 1.9726.. Validation Acc: 0.4718\n",
            "Epoch 32/300.. Learning rate: 0.0486.. Train Loss: 1.4297.. Train Acc: 0.5879.. Validation Loss: 1.8823.. Validation Acc: 0.4950\n",
            "Epoch 33/300.. Learning rate: 0.0485.. Train Loss: 1.4134.. Train Acc: 0.5922.. Validation Loss: 1.9307.. Validation Acc: 0.4881\n",
            "Epoch 34/300.. Learning rate: 0.0484.. Train Loss: 1.4111.. Train Acc: 0.5956.. Validation Loss: 1.9015.. Validation Acc: 0.4903\n",
            "Epoch 35/300.. Learning rate: 0.0483.. Train Loss: 1.3919.. Train Acc: 0.5971.. Validation Loss: 2.0017.. Validation Acc: 0.4723\n",
            "Epoch 36/300.. Learning rate: 0.0482.. Train Loss: 1.3832.. Train Acc: 0.6027.. Validation Loss: 1.8593.. Validation Acc: 0.5025\n",
            "Epoch 37/300.. Learning rate: 0.0481.. Train Loss: 1.3633.. Train Acc: 0.6016.. Validation Loss: 2.0143.. Validation Acc: 0.4654\n",
            "Epoch 38/300.. Learning rate: 0.0480.. Train Loss: 1.3792.. Train Acc: 0.5989.. Validation Loss: 1.8116.. Validation Acc: 0.5089\n",
            "Epoch 39/300.. Learning rate: 0.0479.. Train Loss: 1.3482.. Train Acc: 0.6107.. Validation Loss: 2.0115.. Validation Acc: 0.4686\n",
            "Epoch 40/300.. Learning rate: 0.0478.. Train Loss: 1.3567.. Train Acc: 0.6091.. Validation Loss: 1.9069.. Validation Acc: 0.4905\n",
            "Epoch 41/300.. Learning rate: 0.0477.. Train Loss: 1.3287.. Train Acc: 0.6144.. Validation Loss: 2.0164.. Validation Acc: 0.4708\n",
            "Epoch 42/300.. Learning rate: 0.0476.. Train Loss: 1.3289.. Train Acc: 0.6138.. Validation Loss: 1.8227.. Validation Acc: 0.5089\n",
            "Epoch 43/300.. Learning rate: 0.0475.. Train Loss: 1.3193.. Train Acc: 0.6183.. Validation Loss: 1.8582.. Validation Acc: 0.5053\n",
            "Epoch 44/300.. Learning rate: 0.0474.. Train Loss: 1.3089.. Train Acc: 0.6198.. Validation Loss: 1.8851.. Validation Acc: 0.4985\n",
            "Epoch 45/300.. Learning rate: 0.0473.. Train Loss: 1.2951.. Train Acc: 0.6218.. Validation Loss: 1.8463.. Validation Acc: 0.5066\n",
            "Epoch 46/300.. Learning rate: 0.0472.. Train Loss: 1.2945.. Train Acc: 0.6234.. Validation Loss: 1.9541.. Validation Acc: 0.4850\n",
            "Epoch 47/300.. Learning rate: 0.0470.. Train Loss: 1.2854.. Train Acc: 0.6258.. Validation Loss: 1.8688.. Validation Acc: 0.5029\n",
            "Epoch 48/300.. Learning rate: 0.0469.. Train Loss: 1.2891.. Train Acc: 0.6216.. Validation Loss: 1.8144.. Validation Acc: 0.5125\n",
            "Epoch 49/300.. Learning rate: 0.0468.. Train Loss: 1.2743.. Train Acc: 0.6267.. Validation Loss: 1.9380.. Validation Acc: 0.4827\n",
            "Epoch 50/300.. Learning rate: 0.0467.. Train Loss: 1.2727.. Train Acc: 0.6278.. Validation Loss: 1.8538.. Validation Acc: 0.5074\n",
            "Epoch 51/300.. Learning rate: 0.0465.. Train Loss: 1.2570.. Train Acc: 0.6327.. Validation Loss: 1.8872.. Validation Acc: 0.4956\n",
            "Epoch 52/300.. Learning rate: 0.0464.. Train Loss: 1.2501.. Train Acc: 0.6339.. Validation Loss: 2.0186.. Validation Acc: 0.4745\n",
            "Epoch 53/300.. Learning rate: 0.0463.. Train Loss: 1.2502.. Train Acc: 0.6320.. Validation Loss: 1.9018.. Validation Acc: 0.5004\n",
            "Epoch 54/300.. Learning rate: 0.0461.. Train Loss: 1.2378.. Train Acc: 0.6364.. Validation Loss: 1.8210.. Validation Acc: 0.5158\n",
            "Epoch 55/300.. Learning rate: 0.0460.. Train Loss: 1.2220.. Train Acc: 0.6418.. Validation Loss: 1.8942.. Validation Acc: 0.5009\n",
            "Epoch 56/300.. Learning rate: 0.0458.. Train Loss: 1.2208.. Train Acc: 0.6435.. Validation Loss: 1.7585.. Validation Acc: 0.5309\n",
            "Epoch 57/300.. Learning rate: 0.0457.. Train Loss: 1.2136.. Train Acc: 0.6449.. Validation Loss: 1.7355.. Validation Acc: 0.5405\n",
            "Epoch 58/300.. Learning rate: 0.0455.. Train Loss: 1.2024.. Train Acc: 0.6469.. Validation Loss: 1.8274.. Validation Acc: 0.5160\n",
            "Epoch 59/300.. Learning rate: 0.0454.. Train Loss: 1.1934.. Train Acc: 0.6485.. Validation Loss: 1.8150.. Validation Acc: 0.5161\n",
            "Epoch 60/300.. Learning rate: 0.0452.. Train Loss: 1.1840.. Train Acc: 0.6522.. Validation Loss: 1.7941.. Validation Acc: 0.5210\n",
            "Epoch 61/300.. Learning rate: 0.0451.. Train Loss: 1.1904.. Train Acc: 0.6505.. Validation Loss: 1.9177.. Validation Acc: 0.4986\n",
            "Epoch 62/300.. Learning rate: 0.0449.. Train Loss: 1.1774.. Train Acc: 0.6513.. Validation Loss: 1.8732.. Validation Acc: 0.5067\n",
            "Epoch 63/300.. Learning rate: 0.0448.. Train Loss: 1.1724.. Train Acc: 0.6538.. Validation Loss: 1.8852.. Validation Acc: 0.4994\n",
            "Epoch 64/300.. Learning rate: 0.0446.. Train Loss: 1.1725.. Train Acc: 0.6582.. Validation Loss: 1.8182.. Validation Acc: 0.5158\n",
            "Epoch 65/300.. Learning rate: 0.0444.. Train Loss: 1.1679.. Train Acc: 0.6549.. Validation Loss: 1.7528.. Validation Acc: 0.5323\n",
            "Epoch 66/300.. Learning rate: 0.0443.. Train Loss: 1.1585.. Train Acc: 0.6583.. Validation Loss: 1.8842.. Validation Acc: 0.5080\n",
            "Epoch 67/300.. Learning rate: 0.0441.. Train Loss: 1.1531.. Train Acc: 0.6593.. Validation Loss: 1.7913.. Validation Acc: 0.5275\n",
            "Epoch 68/300.. Learning rate: 0.0439.. Train Loss: 1.1624.. Train Acc: 0.6577.. Validation Loss: 1.7768.. Validation Acc: 0.5260\n",
            "Epoch 69/300.. Learning rate: 0.0438.. Train Loss: 1.1362.. Train Acc: 0.6646.. Validation Loss: 1.7934.. Validation Acc: 0.5215\n",
            "Epoch 70/300.. Learning rate: 0.0436.. Train Loss: 1.1524.. Train Acc: 0.6594.. Validation Loss: 1.7809.. Validation Acc: 0.5256\n",
            "Epoch 71/300.. Learning rate: 0.0434.. Train Loss: 1.1317.. Train Acc: 0.6645.. Validation Loss: 1.7975.. Validation Acc: 0.5234\n",
            "Epoch 72/300.. Learning rate: 0.0432.. Train Loss: 1.1167.. Train Acc: 0.6663.. Validation Loss: 1.9266.. Validation Acc: 0.4961\n",
            "Epoch 73/300.. Learning rate: 0.0430.. Train Loss: 1.1231.. Train Acc: 0.6672.. Validation Loss: 1.8533.. Validation Acc: 0.5073\n",
            "Epoch 74/300.. Learning rate: 0.0429.. Train Loss: 1.1093.. Train Acc: 0.6711.. Validation Loss: 1.7439.. Validation Acc: 0.5415\n",
            "Epoch 75/300.. Learning rate: 0.0427.. Train Loss: 1.1173.. Train Acc: 0.6680.. Validation Loss: 1.8459.. Validation Acc: 0.5148\n",
            "Epoch 76/300.. Learning rate: 0.0425.. Train Loss: 1.1080.. Train Acc: 0.6727.. Validation Loss: 1.7724.. Validation Acc: 0.5276\n",
            "Epoch 77/300.. Learning rate: 0.0423.. Train Loss: 1.1057.. Train Acc: 0.6724.. Validation Loss: 1.7523.. Validation Acc: 0.5355\n",
            "Epoch 78/300.. Learning rate: 0.0421.. Train Loss: 1.0912.. Train Acc: 0.6752.. Validation Loss: 1.7554.. Validation Acc: 0.5356\n",
            "Epoch 79/300.. Learning rate: 0.0419.. Train Loss: 1.0908.. Train Acc: 0.6763.. Validation Loss: 1.8689.. Validation Acc: 0.5136\n",
            "Epoch 80/300.. Learning rate: 0.0417.. Train Loss: 1.0773.. Train Acc: 0.6797.. Validation Loss: 1.6977.. Validation Acc: 0.5502\n",
            "Epoch 81/300.. Learning rate: 0.0415.. Train Loss: 1.0796.. Train Acc: 0.6786.. Validation Loss: 1.8348.. Validation Acc: 0.5139\n",
            "Epoch 82/300.. Learning rate: 0.0413.. Train Loss: 1.0740.. Train Acc: 0.6789.. Validation Loss: 1.9139.. Validation Acc: 0.5031\n",
            "Epoch 83/300.. Learning rate: 0.0411.. Train Loss: 1.0684.. Train Acc: 0.6826.. Validation Loss: 1.8710.. Validation Acc: 0.5038\n",
            "Epoch 84/300.. Learning rate: 0.0409.. Train Loss: 1.0631.. Train Acc: 0.6836.. Validation Loss: 1.7416.. Validation Acc: 0.5319\n",
            "Epoch 85/300.. Learning rate: 0.0407.. Train Loss: 1.0665.. Train Acc: 0.6803.. Validation Loss: 1.6848.. Validation Acc: 0.5562\n",
            "Epoch 86/300.. Learning rate: 0.0405.. Train Loss: 1.0351.. Train Acc: 0.6902.. Validation Loss: 1.7139.. Validation Acc: 0.5458\n",
            "Epoch 87/300.. Learning rate: 0.0403.. Train Loss: 1.0533.. Train Acc: 0.6850.. Validation Loss: 1.8338.. Validation Acc: 0.5252\n",
            "Epoch 88/300.. Learning rate: 0.0401.. Train Loss: 1.0285.. Train Acc: 0.6911.. Validation Loss: 1.8622.. Validation Acc: 0.5231\n",
            "Epoch 89/300.. Learning rate: 0.0399.. Train Loss: 1.0289.. Train Acc: 0.6926.. Validation Loss: 1.8685.. Validation Acc: 0.5123\n",
            "Epoch 90/300.. Learning rate: 0.0397.. Train Loss: 1.0464.. Train Acc: 0.6842.. Validation Loss: 1.8079.. Validation Acc: 0.5223\n",
            "Epoch 91/300.. Learning rate: 0.0395.. Train Loss: 1.0265.. Train Acc: 0.6929.. Validation Loss: 1.8741.. Validation Acc: 0.5092\n",
            "Epoch 92/300.. Learning rate: 0.0393.. Train Loss: 1.0149.. Train Acc: 0.6950.. Validation Loss: 1.6426.. Validation Acc: 0.5609\n",
            "Epoch 93/300.. Learning rate: 0.0391.. Train Loss: 1.0192.. Train Acc: 0.6931.. Validation Loss: 1.7652.. Validation Acc: 0.5350\n",
            "Epoch 94/300.. Learning rate: 0.0388.. Train Loss: 1.0178.. Train Acc: 0.6935.. Validation Loss: 1.7994.. Validation Acc: 0.5254\n",
            "Epoch 95/300.. Learning rate: 0.0386.. Train Loss: 1.0100.. Train Acc: 0.6981.. Validation Loss: 1.7378.. Validation Acc: 0.5407\n",
            "Epoch 96/300.. Learning rate: 0.0384.. Train Loss: 0.9860.. Train Acc: 0.7051.. Validation Loss: 1.7228.. Validation Acc: 0.5440\n",
            "Epoch 97/300.. Learning rate: 0.0382.. Train Loss: 0.9905.. Train Acc: 0.7015.. Validation Loss: 1.7357.. Validation Acc: 0.5440\n",
            "Epoch 98/300.. Learning rate: 0.0380.. Train Loss: 0.9847.. Train Acc: 0.7044.. Validation Loss: 1.7178.. Validation Acc: 0.5445\n",
            "Epoch 99/300.. Learning rate: 0.0377.. Train Loss: 0.9726.. Train Acc: 0.7066.. Validation Loss: 1.6810.. Validation Acc: 0.5546\n",
            "Epoch 100/300.. Learning rate: 0.0375.. Train Loss: 0.9771.. Train Acc: 0.7053.. Validation Loss: 1.7619.. Validation Acc: 0.5384\n",
            "Epoch 101/300.. Learning rate: 0.0373.. Train Loss: 0.9604.. Train Acc: 0.7085.. Validation Loss: 1.6800.. Validation Acc: 0.5561\n",
            "Epoch 102/300.. Learning rate: 0.0370.. Train Loss: 0.9506.. Train Acc: 0.7139.. Validation Loss: 1.8491.. Validation Acc: 0.5262\n",
            "Epoch 103/300.. Learning rate: 0.0368.. Train Loss: 0.9656.. Train Acc: 0.7108.. Validation Loss: 1.7004.. Validation Acc: 0.5520\n",
            "Epoch 104/300.. Learning rate: 0.0366.. Train Loss: 0.9446.. Train Acc: 0.7140.. Validation Loss: 1.6920.. Validation Acc: 0.5552\n",
            "Epoch 105/300.. Learning rate: 0.0364.. Train Loss: 0.9350.. Train Acc: 0.7173.. Validation Loss: 1.8023.. Validation Acc: 0.5296\n",
            "Epoch 106/300.. Learning rate: 0.0361.. Train Loss: 0.9360.. Train Acc: 0.7190.. Validation Loss: 1.6940.. Validation Acc: 0.5505\n",
            "Epoch 107/300.. Learning rate: 0.0359.. Train Loss: 0.9366.. Train Acc: 0.7169.. Validation Loss: 1.7180.. Validation Acc: 0.5497\n",
            "Epoch 108/300.. Learning rate: 0.0356.. Train Loss: 0.9278.. Train Acc: 0.7179.. Validation Loss: 1.7585.. Validation Acc: 0.5399\n",
            "Epoch 109/300.. Learning rate: 0.0354.. Train Loss: 0.9123.. Train Acc: 0.7202.. Validation Loss: 1.7715.. Validation Acc: 0.5390\n",
            "Epoch 110/300.. Learning rate: 0.0352.. Train Loss: 0.9225.. Train Acc: 0.7197.. Validation Loss: 1.7565.. Validation Acc: 0.5497\n",
            "Epoch 111/300.. Learning rate: 0.0349.. Train Loss: 0.9143.. Train Acc: 0.7210.. Validation Loss: 1.7869.. Validation Acc: 0.5379\n",
            "Epoch 112/300.. Learning rate: 0.0347.. Train Loss: 0.9002.. Train Acc: 0.7255.. Validation Loss: 1.7286.. Validation Acc: 0.5510\n",
            "Epoch 113/300.. Learning rate: 0.0344.. Train Loss: 0.8948.. Train Acc: 0.7276.. Validation Loss: 1.7133.. Validation Acc: 0.5540\n",
            "Epoch 114/300.. Learning rate: 0.0342.. Train Loss: 0.8979.. Train Acc: 0.7251.. Validation Loss: 1.8223.. Validation Acc: 0.5293\n",
            "Epoch 115/300.. Learning rate: 0.0340.. Train Loss: 0.8870.. Train Acc: 0.7319.. Validation Loss: 1.7216.. Validation Acc: 0.5498\n",
            "Epoch 116/300.. Learning rate: 0.0337.. Train Loss: 0.8718.. Train Acc: 0.7327.. Validation Loss: 1.7567.. Validation Acc: 0.5498\n",
            "Epoch 117/300.. Learning rate: 0.0335.. Train Loss: 0.8735.. Train Acc: 0.7352.. Validation Loss: 1.8746.. Validation Acc: 0.5268\n",
            "Epoch 118/300.. Learning rate: 0.0332.. Train Loss: 0.8658.. Train Acc: 0.7365.. Validation Loss: 1.7129.. Validation Acc: 0.5539\n",
            "Epoch 119/300.. Learning rate: 0.0330.. Train Loss: 0.8604.. Train Acc: 0.7361.. Validation Loss: 1.7613.. Validation Acc: 0.5481\n",
            "Epoch 120/300.. Learning rate: 0.0327.. Train Loss: 0.8705.. Train Acc: 0.7356.. Validation Loss: 1.7036.. Validation Acc: 0.5626\n",
            "Epoch 121/300.. Learning rate: 0.0325.. Train Loss: 0.8489.. Train Acc: 0.7417.. Validation Loss: 1.7660.. Validation Acc: 0.5443\n",
            "Epoch 122/300.. Learning rate: 0.0322.. Train Loss: 0.8439.. Train Acc: 0.7416.. Validation Loss: 1.7516.. Validation Acc: 0.5526\n",
            "Epoch 123/300.. Learning rate: 0.0320.. Train Loss: 0.8368.. Train Acc: 0.7427.. Validation Loss: 1.7217.. Validation Acc: 0.5570\n",
            "Epoch 124/300.. Learning rate: 0.0317.. Train Loss: 0.8266.. Train Acc: 0.7471.. Validation Loss: 1.7436.. Validation Acc: 0.5522\n",
            "Epoch 125/300.. Learning rate: 0.0315.. Train Loss: 0.8253.. Train Acc: 0.7482.. Validation Loss: 1.7141.. Validation Acc: 0.5574\n",
            "Epoch 126/300.. Learning rate: 0.0312.. Train Loss: 0.8097.. Train Acc: 0.7511.. Validation Loss: 1.6547.. Validation Acc: 0.5639\n",
            "Epoch 127/300.. Learning rate: 0.0310.. Train Loss: 0.7975.. Train Acc: 0.7531.. Validation Loss: 1.8442.. Validation Acc: 0.5360\n",
            "Epoch 128/300.. Learning rate: 0.0307.. Train Loss: 0.8106.. Train Acc: 0.7500.. Validation Loss: 1.6501.. Validation Acc: 0.5676\n",
            "Epoch 129/300.. Learning rate: 0.0305.. Train Loss: 0.8012.. Train Acc: 0.7533.. Validation Loss: 1.7244.. Validation Acc: 0.5590\n",
            "Epoch 130/300.. Learning rate: 0.0302.. Train Loss: 0.7868.. Train Acc: 0.7592.. Validation Loss: 1.6670.. Validation Acc: 0.5677\n",
            "Epoch 131/300.. Learning rate: 0.0299.. Train Loss: 0.7826.. Train Acc: 0.7596.. Validation Loss: 1.7326.. Validation Acc: 0.5519\n",
            "Epoch 132/300.. Learning rate: 0.0297.. Train Loss: 0.7599.. Train Acc: 0.7655.. Validation Loss: 1.8158.. Validation Acc: 0.5479\n",
            "Epoch 133/300.. Learning rate: 0.0294.. Train Loss: 0.7668.. Train Acc: 0.7656.. Validation Loss: 1.7593.. Validation Acc: 0.5541\n",
            "Epoch 134/300.. Learning rate: 0.0292.. Train Loss: 0.7731.. Train Acc: 0.7616.. Validation Loss: 1.7587.. Validation Acc: 0.5513\n",
            "Epoch 135/300.. Learning rate: 0.0289.. Train Loss: 0.7531.. Train Acc: 0.7682.. Validation Loss: 1.6707.. Validation Acc: 0.5719\n",
            "Epoch 136/300.. Learning rate: 0.0287.. Train Loss: 0.7426.. Train Acc: 0.7689.. Validation Loss: 1.7323.. Validation Acc: 0.5617\n",
            "Epoch 137/300.. Learning rate: 0.0284.. Train Loss: 0.7272.. Train Acc: 0.7754.. Validation Loss: 1.7308.. Validation Acc: 0.5566\n",
            "Epoch 138/300.. Learning rate: 0.0281.. Train Loss: 0.7388.. Train Acc: 0.7732.. Validation Loss: 1.8226.. Validation Acc: 0.5478\n",
            "Epoch 139/300.. Learning rate: 0.0279.. Train Loss: 0.7063.. Train Acc: 0.7813.. Validation Loss: 1.7128.. Validation Acc: 0.5670\n",
            "Epoch 140/300.. Learning rate: 0.0276.. Train Loss: 0.7206.. Train Acc: 0.7770.. Validation Loss: 1.7154.. Validation Acc: 0.5643\n",
            "Epoch 141/300.. Learning rate: 0.0274.. Train Loss: 0.7101.. Train Acc: 0.7799.. Validation Loss: 1.7164.. Validation Acc: 0.5688\n",
            "Epoch 142/300.. Learning rate: 0.0271.. Train Loss: 0.7029.. Train Acc: 0.7819.. Validation Loss: 1.6518.. Validation Acc: 0.5738\n",
            "Epoch 143/300.. Learning rate: 0.0268.. Train Loss: 0.6802.. Train Acc: 0.7881.. Validation Loss: 1.6790.. Validation Acc: 0.5698\n",
            "Epoch 144/300.. Learning rate: 0.0266.. Train Loss: 0.6960.. Train Acc: 0.7858.. Validation Loss: 1.6435.. Validation Acc: 0.5815\n",
            "Epoch 145/300.. Learning rate: 0.0263.. Train Loss: 0.6818.. Train Acc: 0.7897.. Validation Loss: 1.8028.. Validation Acc: 0.5494\n",
            "Epoch 146/300.. Learning rate: 0.0260.. Train Loss: 0.6886.. Train Acc: 0.7846.. Validation Loss: 1.6361.. Validation Acc: 0.5816\n",
            "Epoch 147/300.. Learning rate: 0.0258.. Train Loss: 0.6593.. Train Acc: 0.7942.. Validation Loss: 1.6972.. Validation Acc: 0.5709\n",
            "Epoch 148/300.. Learning rate: 0.0255.. Train Loss: 0.6456.. Train Acc: 0.7984.. Validation Loss: 1.6643.. Validation Acc: 0.5746\n",
            "Epoch 149/300.. Learning rate: 0.0253.. Train Loss: 0.6543.. Train Acc: 0.7973.. Validation Loss: 1.6400.. Validation Acc: 0.5804\n",
            "Epoch 150/300.. Learning rate: 0.0250.. Train Loss: 0.6452.. Train Acc: 0.7966.. Validation Loss: 1.7097.. Validation Acc: 0.5725\n",
            "Epoch 151/300.. Learning rate: 0.0247.. Train Loss: 0.6267.. Train Acc: 0.8047.. Validation Loss: 1.6959.. Validation Acc: 0.5725\n",
            "Epoch 152/300.. Learning rate: 0.0245.. Train Loss: 0.6101.. Train Acc: 0.8090.. Validation Loss: 1.8010.. Validation Acc: 0.5512\n",
            "Epoch 153/300.. Learning rate: 0.0242.. Train Loss: 0.6150.. Train Acc: 0.8072.. Validation Loss: 1.6503.. Validation Acc: 0.5796\n",
            "Epoch 154/300.. Learning rate: 0.0240.. Train Loss: 0.6079.. Train Acc: 0.8102.. Validation Loss: 1.7587.. Validation Acc: 0.5671\n",
            "Epoch 155/300.. Learning rate: 0.0237.. Train Loss: 0.5947.. Train Acc: 0.8141.. Validation Loss: 1.7026.. Validation Acc: 0.5780\n",
            "Epoch 156/300.. Learning rate: 0.0234.. Train Loss: 0.5865.. Train Acc: 0.8140.. Validation Loss: 1.7771.. Validation Acc: 0.5610\n",
            "Epoch 157/300.. Learning rate: 0.0232.. Train Loss: 0.5942.. Train Acc: 0.8128.. Validation Loss: 1.7045.. Validation Acc: 0.5767\n",
            "Epoch 158/300.. Learning rate: 0.0229.. Train Loss: 0.5811.. Train Acc: 0.8198.. Validation Loss: 1.7378.. Validation Acc: 0.5717\n",
            "Epoch 159/300.. Learning rate: 0.0227.. Train Loss: 0.5734.. Train Acc: 0.8205.. Validation Loss: 1.7227.. Validation Acc: 0.5703\n",
            "Epoch 160/300.. Learning rate: 0.0224.. Train Loss: 0.5694.. Train Acc: 0.8208.. Validation Loss: 1.6995.. Validation Acc: 0.5802\n",
            "Epoch 161/300.. Learning rate: 0.0221.. Train Loss: 0.5513.. Train Acc: 0.8287.. Validation Loss: 1.7249.. Validation Acc: 0.5800\n",
            "Epoch 162/300.. Learning rate: 0.0219.. Train Loss: 0.5466.. Train Acc: 0.8280.. Validation Loss: 1.6813.. Validation Acc: 0.5808\n",
            "Epoch 163/300.. Learning rate: 0.0216.. Train Loss: 0.5446.. Train Acc: 0.8279.. Validation Loss: 1.7352.. Validation Acc: 0.5754\n",
            "Epoch 164/300.. Learning rate: 0.0214.. Train Loss: 0.5329.. Train Acc: 0.8319.. Validation Loss: 1.7449.. Validation Acc: 0.5783\n",
            "Epoch 165/300.. Learning rate: 0.0211.. Train Loss: 0.5104.. Train Acc: 0.8394.. Validation Loss: 1.6907.. Validation Acc: 0.5875\n",
            "Epoch 166/300.. Learning rate: 0.0208.. Train Loss: 0.5165.. Train Acc: 0.8370.. Validation Loss: 1.6675.. Validation Acc: 0.5898\n",
            "Epoch 167/300.. Learning rate: 0.0206.. Train Loss: 0.5104.. Train Acc: 0.8415.. Validation Loss: 1.7253.. Validation Acc: 0.5728\n",
            "Epoch 168/300.. Learning rate: 0.0203.. Train Loss: 0.4968.. Train Acc: 0.8433.. Validation Loss: 1.7114.. Validation Acc: 0.5834\n",
            "Epoch 169/300.. Learning rate: 0.0201.. Train Loss: 0.4967.. Train Acc: 0.8431.. Validation Loss: 1.7334.. Validation Acc: 0.5827\n",
            "Epoch 170/300.. Learning rate: 0.0198.. Train Loss: 0.4772.. Train Acc: 0.8486.. Validation Loss: 1.6643.. Validation Acc: 0.5910\n",
            "Epoch 171/300.. Learning rate: 0.0195.. Train Loss: 0.4706.. Train Acc: 0.8513.. Validation Loss: 1.7125.. Validation Acc: 0.5822\n",
            "Epoch 172/300.. Learning rate: 0.0193.. Train Loss: 0.4706.. Train Acc: 0.8501.. Validation Loss: 1.7505.. Validation Acc: 0.5740\n",
            "Epoch 173/300.. Learning rate: 0.0190.. Train Loss: 0.4500.. Train Acc: 0.8573.. Validation Loss: 1.6663.. Validation Acc: 0.5914\n",
            "Epoch 174/300.. Learning rate: 0.0188.. Train Loss: 0.4543.. Train Acc: 0.8577.. Validation Loss: 1.7662.. Validation Acc: 0.5740\n",
            "Epoch 175/300.. Learning rate: 0.0185.. Train Loss: 0.4417.. Train Acc: 0.8588.. Validation Loss: 1.7356.. Validation Acc: 0.5845\n",
            "Epoch 176/300.. Learning rate: 0.0183.. Train Loss: 0.4301.. Train Acc: 0.8649.. Validation Loss: 1.6612.. Validation Acc: 0.5953\n",
            "Epoch 177/300.. Learning rate: 0.0180.. Train Loss: 0.4039.. Train Acc: 0.8744.. Validation Loss: 1.6909.. Validation Acc: 0.6014\n",
            "Epoch 178/300.. Learning rate: 0.0178.. Train Loss: 0.4155.. Train Acc: 0.8687.. Validation Loss: 1.6915.. Validation Acc: 0.5972\n",
            "Epoch 179/300.. Learning rate: 0.0175.. Train Loss: 0.4005.. Train Acc: 0.8728.. Validation Loss: 1.6770.. Validation Acc: 0.6008\n",
            "Epoch 180/300.. Learning rate: 0.0173.. Train Loss: 0.4040.. Train Acc: 0.8733.. Validation Loss: 1.6489.. Validation Acc: 0.6049\n",
            "Epoch 181/300.. Learning rate: 0.0170.. Train Loss: 0.3795.. Train Acc: 0.8825.. Validation Loss: 1.5980.. Validation Acc: 0.6113\n",
            "Epoch 182/300.. Learning rate: 0.0168.. Train Loss: 0.3713.. Train Acc: 0.8839.. Validation Loss: 1.7712.. Validation Acc: 0.5851\n",
            "Epoch 183/300.. Learning rate: 0.0165.. Train Loss: 0.3720.. Train Acc: 0.8832.. Validation Loss: 1.7781.. Validation Acc: 0.5834\n",
            "Epoch 184/300.. Learning rate: 0.0163.. Train Loss: 0.3624.. Train Acc: 0.8867.. Validation Loss: 1.7209.. Validation Acc: 0.5917\n",
            "Epoch 185/300.. Learning rate: 0.0160.. Train Loss: 0.3606.. Train Acc: 0.8851.. Validation Loss: 1.6839.. Validation Acc: 0.5999\n",
            "Epoch 186/300.. Learning rate: 0.0158.. Train Loss: 0.3511.. Train Acc: 0.8892.. Validation Loss: 1.7297.. Validation Acc: 0.5955\n",
            "Epoch 187/300.. Learning rate: 0.0156.. Train Loss: 0.3496.. Train Acc: 0.8892.. Validation Loss: 1.6868.. Validation Acc: 0.6006\n",
            "Epoch 188/300.. Learning rate: 0.0153.. Train Loss: 0.3370.. Train Acc: 0.8951.. Validation Loss: 1.7157.. Validation Acc: 0.5906\n",
            "Epoch 189/300.. Learning rate: 0.0151.. Train Loss: 0.3257.. Train Acc: 0.8977.. Validation Loss: 1.7148.. Validation Acc: 0.5952\n",
            "Epoch 190/300.. Learning rate: 0.0148.. Train Loss: 0.3098.. Train Acc: 0.9035.. Validation Loss: 1.7032.. Validation Acc: 0.5977\n",
            "Epoch 191/300.. Learning rate: 0.0146.. Train Loss: 0.3068.. Train Acc: 0.9048.. Validation Loss: 1.7222.. Validation Acc: 0.5901\n",
            "Epoch 192/300.. Learning rate: 0.0144.. Train Loss: 0.2975.. Train Acc: 0.9085.. Validation Loss: 1.7832.. Validation Acc: 0.5930\n",
            "Epoch 193/300.. Learning rate: 0.0141.. Train Loss: 0.2961.. Train Acc: 0.9094.. Validation Loss: 1.6797.. Validation Acc: 0.6046\n",
            "Epoch 194/300.. Learning rate: 0.0139.. Train Loss: 0.2983.. Train Acc: 0.9069.. Validation Loss: 1.7161.. Validation Acc: 0.6025\n",
            "Epoch 195/300.. Learning rate: 0.0137.. Train Loss: 0.2820.. Train Acc: 0.9131.. Validation Loss: 1.6961.. Validation Acc: 0.6090\n",
            "Epoch 196/300.. Learning rate: 0.0134.. Train Loss: 0.2689.. Train Acc: 0.9185.. Validation Loss: 1.6760.. Validation Acc: 0.6072\n",
            "Epoch 197/300.. Learning rate: 0.0132.. Train Loss: 0.2630.. Train Acc: 0.9199.. Validation Loss: 1.6969.. Validation Acc: 0.6065\n",
            "Epoch 198/300.. Learning rate: 0.0130.. Train Loss: 0.2537.. Train Acc: 0.9234.. Validation Loss: 1.6365.. Validation Acc: 0.6163\n",
            "Epoch 199/300.. Learning rate: 0.0127.. Train Loss: 0.2450.. Train Acc: 0.9268.. Validation Loss: 1.7308.. Validation Acc: 0.6043\n",
            "Epoch 200/300.. Learning rate: 0.0125.. Train Loss: 0.2322.. Train Acc: 0.9319.. Validation Loss: 1.6831.. Validation Acc: 0.6159\n",
            "Epoch 201/300.. Learning rate: 0.0123.. Train Loss: 0.2371.. Train Acc: 0.9281.. Validation Loss: 1.6725.. Validation Acc: 0.6176\n",
            "Epoch 202/300.. Learning rate: 0.0121.. Train Loss: 0.2230.. Train Acc: 0.9329.. Validation Loss: 1.6990.. Validation Acc: 0.6119\n",
            "Epoch 203/300.. Learning rate: 0.0118.. Train Loss: 0.2252.. Train Acc: 0.9317.. Validation Loss: 1.7803.. Validation Acc: 0.6011\n",
            "Epoch 204/300.. Learning rate: 0.0116.. Train Loss: 0.2111.. Train Acc: 0.9388.. Validation Loss: 1.7566.. Validation Acc: 0.5998\n",
            "Epoch 205/300.. Learning rate: 0.0114.. Train Loss: 0.1963.. Train Acc: 0.9425.. Validation Loss: 1.6685.. Validation Acc: 0.6157\n",
            "Epoch 206/300.. Learning rate: 0.0112.. Train Loss: 0.1884.. Train Acc: 0.9456.. Validation Loss: 1.6203.. Validation Acc: 0.6274\n",
            "Epoch 207/300.. Learning rate: 0.0110.. Train Loss: 0.1897.. Train Acc: 0.9454.. Validation Loss: 1.6353.. Validation Acc: 0.6323\n",
            "Epoch 208/300.. Learning rate: 0.0107.. Train Loss: 0.1750.. Train Acc: 0.9496.. Validation Loss: 1.7171.. Validation Acc: 0.6120\n",
            "Epoch 209/300.. Learning rate: 0.0105.. Train Loss: 0.1716.. Train Acc: 0.9497.. Validation Loss: 1.6869.. Validation Acc: 0.6167\n",
            "Epoch 210/300.. Learning rate: 0.0103.. Train Loss: 0.1662.. Train Acc: 0.9528.. Validation Loss: 1.6703.. Validation Acc: 0.6208\n",
            "Epoch 211/300.. Learning rate: 0.0101.. Train Loss: 0.1575.. Train Acc: 0.9549.. Validation Loss: 1.6901.. Validation Acc: 0.6224\n",
            "Epoch 212/300.. Learning rate: 0.0099.. Train Loss: 0.1506.. Train Acc: 0.9575.. Validation Loss: 1.6657.. Validation Acc: 0.6264\n",
            "Epoch 213/300.. Learning rate: 0.0097.. Train Loss: 0.1401.. Train Acc: 0.9610.. Validation Loss: 1.6905.. Validation Acc: 0.6155\n",
            "Epoch 214/300.. Learning rate: 0.0095.. Train Loss: 0.1393.. Train Acc: 0.9620.. Validation Loss: 1.6164.. Validation Acc: 0.6279\n",
            "Epoch 215/300.. Learning rate: 0.0093.. Train Loss: 0.1343.. Train Acc: 0.9628.. Validation Loss: 1.6245.. Validation Acc: 0.6315\n",
            "Epoch 216/300.. Learning rate: 0.0091.. Train Loss: 0.1298.. Train Acc: 0.9643.. Validation Loss: 1.6134.. Validation Acc: 0.6282\n",
            "Epoch 217/300.. Learning rate: 0.0089.. Train Loss: 0.1242.. Train Acc: 0.9661.. Validation Loss: 1.6033.. Validation Acc: 0.6319\n",
            "Epoch 218/300.. Learning rate: 0.0087.. Train Loss: 0.1154.. Train Acc: 0.9707.. Validation Loss: 1.6674.. Validation Acc: 0.6282\n",
            "Epoch 219/300.. Learning rate: 0.0085.. Train Loss: 0.1102.. Train Acc: 0.9714.. Validation Loss: 1.6189.. Validation Acc: 0.6361\n",
            "Epoch 220/300.. Learning rate: 0.0083.. Train Loss: 0.1019.. Train Acc: 0.9746.. Validation Loss: 1.6449.. Validation Acc: 0.6257\n",
            "Epoch 221/300.. Learning rate: 0.0081.. Train Loss: 0.0970.. Train Acc: 0.9751.. Validation Loss: 1.6277.. Validation Acc: 0.6297\n",
            "Epoch 222/300.. Learning rate: 0.0079.. Train Loss: 0.0909.. Train Acc: 0.9775.. Validation Loss: 1.5934.. Validation Acc: 0.6424\n",
            "Epoch 223/300.. Learning rate: 0.0077.. Train Loss: 0.0785.. Train Acc: 0.9815.. Validation Loss: 1.5791.. Validation Acc: 0.6451\n",
            "Epoch 224/300.. Learning rate: 0.0075.. Train Loss: 0.0764.. Train Acc: 0.9822.. Validation Loss: 1.6044.. Validation Acc: 0.6352\n",
            "Epoch 225/300.. Learning rate: 0.0073.. Train Loss: 0.0768.. Train Acc: 0.9815.. Validation Loss: 1.5924.. Validation Acc: 0.6417\n",
            "Epoch 226/300.. Learning rate: 0.0071.. Train Loss: 0.0690.. Train Acc: 0.9849.. Validation Loss: 1.5557.. Validation Acc: 0.6553\n",
            "Epoch 227/300.. Learning rate: 0.0070.. Train Loss: 0.0646.. Train Acc: 0.9860.. Validation Loss: 1.5757.. Validation Acc: 0.6445\n",
            "Epoch 228/300.. Learning rate: 0.0068.. Train Loss: 0.0590.. Train Acc: 0.9877.. Validation Loss: 1.5632.. Validation Acc: 0.6504\n",
            "Epoch 229/300.. Learning rate: 0.0066.. Train Loss: 0.0527.. Train Acc: 0.9892.. Validation Loss: 1.5588.. Validation Acc: 0.6506\n",
            "Epoch 230/300.. Learning rate: 0.0064.. Train Loss: 0.0493.. Train Acc: 0.9906.. Validation Loss: 1.5729.. Validation Acc: 0.6496\n",
            "Epoch 231/300.. Learning rate: 0.0062.. Train Loss: 0.0466.. Train Acc: 0.9913.. Validation Loss: 1.5484.. Validation Acc: 0.6503\n",
            "Epoch 232/300.. Learning rate: 0.0061.. Train Loss: 0.0442.. Train Acc: 0.9921.. Validation Loss: 1.5326.. Validation Acc: 0.6531\n",
            "Epoch 233/300.. Learning rate: 0.0059.. Train Loss: 0.0407.. Train Acc: 0.9933.. Validation Loss: 1.5370.. Validation Acc: 0.6564\n",
            "Epoch 234/300.. Learning rate: 0.0057.. Train Loss: 0.0363.. Train Acc: 0.9943.. Validation Loss: 1.5316.. Validation Acc: 0.6563\n",
            "Epoch 235/300.. Learning rate: 0.0056.. Train Loss: 0.0366.. Train Acc: 0.9944.. Validation Loss: 1.5266.. Validation Acc: 0.6626\n",
            "Epoch 236/300.. Learning rate: 0.0054.. Train Loss: 0.0309.. Train Acc: 0.9960.. Validation Loss: 1.5344.. Validation Acc: 0.6569\n",
            "Epoch 237/300.. Learning rate: 0.0052.. Train Loss: 0.0301.. Train Acc: 0.9960.. Validation Loss: 1.5053.. Validation Acc: 0.6599\n",
            "Epoch 238/300.. Learning rate: 0.0051.. Train Loss: 0.0278.. Train Acc: 0.9968.. Validation Loss: 1.4886.. Validation Acc: 0.6652\n",
            "Epoch 239/300.. Learning rate: 0.0049.. Train Loss: 0.0282.. Train Acc: 0.9966.. Validation Loss: 1.4989.. Validation Acc: 0.6656\n",
            "Epoch 240/300.. Learning rate: 0.0048.. Train Loss: 0.0272.. Train Acc: 0.9966.. Validation Loss: 1.4857.. Validation Acc: 0.6644\n",
            "Epoch 241/300.. Learning rate: 0.0046.. Train Loss: 0.0253.. Train Acc: 0.9973.. Validation Loss: 1.4735.. Validation Acc: 0.6658\n",
            "Epoch 242/300.. Learning rate: 0.0045.. Train Loss: 0.0234.. Train Acc: 0.9972.. Validation Loss: 1.4739.. Validation Acc: 0.6667\n",
            "Epoch 243/300.. Learning rate: 0.0043.. Train Loss: 0.0241.. Train Acc: 0.9971.. Validation Loss: 1.4657.. Validation Acc: 0.6638\n",
            "Epoch 244/300.. Learning rate: 0.0042.. Train Loss: 0.0226.. Train Acc: 0.9979.. Validation Loss: 1.4604.. Validation Acc: 0.6666\n",
            "Epoch 245/300.. Learning rate: 0.0040.. Train Loss: 0.0215.. Train Acc: 0.9979.. Validation Loss: 1.4558.. Validation Acc: 0.6701\n",
            "Epoch 246/300.. Learning rate: 0.0039.. Train Loss: 0.0197.. Train Acc: 0.9983.. Validation Loss: 1.4590.. Validation Acc: 0.6720\n",
            "Epoch 247/300.. Learning rate: 0.0038.. Train Loss: 0.0192.. Train Acc: 0.9985.. Validation Loss: 1.4535.. Validation Acc: 0.6672\n",
            "Epoch 248/300.. Learning rate: 0.0036.. Train Loss: 0.0183.. Train Acc: 0.9984.. Validation Loss: 1.4666.. Validation Acc: 0.6660\n",
            "Epoch 249/300.. Learning rate: 0.0035.. Train Loss: 0.0178.. Train Acc: 0.9987.. Validation Loss: 1.4449.. Validation Acc: 0.6704\n",
            "Epoch 250/300.. Learning rate: 0.0034.. Train Loss: 0.0169.. Train Acc: 0.9987.. Validation Loss: 1.4438.. Validation Acc: 0.6689\n",
            "Epoch 251/300.. Learning rate: 0.0032.. Train Loss: 0.0175.. Train Acc: 0.9986.. Validation Loss: 1.4359.. Validation Acc: 0.6754\n",
            "Epoch 252/300.. Learning rate: 0.0031.. Train Loss: 0.0166.. Train Acc: 0.9988.. Validation Loss: 1.4418.. Validation Acc: 0.6710\n",
            "Epoch 253/300.. Learning rate: 0.0030.. Train Loss: 0.0164.. Train Acc: 0.9986.. Validation Loss: 1.4404.. Validation Acc: 0.6712\n",
            "Epoch 254/300.. Learning rate: 0.0028.. Train Loss: 0.0162.. Train Acc: 0.9990.. Validation Loss: 1.4387.. Validation Acc: 0.6725\n",
            "Epoch 255/300.. Learning rate: 0.0027.. Train Loss: 0.0164.. Train Acc: 0.9988.. Validation Loss: 1.4299.. Validation Acc: 0.6701\n",
            "Epoch 256/300.. Learning rate: 0.0026.. Train Loss: 0.0155.. Train Acc: 0.9990.. Validation Loss: 1.4150.. Validation Acc: 0.6747\n",
            "Epoch 257/300.. Learning rate: 0.0025.. Train Loss: 0.0163.. Train Acc: 0.9988.. Validation Loss: 1.4278.. Validation Acc: 0.6664\n",
            "Epoch 258/300.. Learning rate: 0.0024.. Train Loss: 0.0149.. Train Acc: 0.9990.. Validation Loss: 1.4140.. Validation Acc: 0.6774\n",
            "Epoch 259/300.. Learning rate: 0.0023.. Train Loss: 0.0149.. Train Acc: 0.9989.. Validation Loss: 1.4198.. Validation Acc: 0.6741\n",
            "Epoch 260/300.. Learning rate: 0.0022.. Train Loss: 0.0144.. Train Acc: 0.9993.. Validation Loss: 1.4080.. Validation Acc: 0.6737\n",
            "Epoch 261/300.. Learning rate: 0.0021.. Train Loss: 0.0145.. Train Acc: 0.9994.. Validation Loss: 1.4232.. Validation Acc: 0.6742\n",
            "Epoch 262/300.. Learning rate: 0.0020.. Train Loss: 0.0147.. Train Acc: 0.9993.. Validation Loss: 1.4074.. Validation Acc: 0.6725\n",
            "Epoch 263/300.. Learning rate: 0.0019.. Train Loss: 0.0144.. Train Acc: 0.9991.. Validation Loss: 1.4041.. Validation Acc: 0.6761\n",
            "Epoch 264/300.. Learning rate: 0.0018.. Train Loss: 0.0143.. Train Acc: 0.9992.. Validation Loss: 1.4192.. Validation Acc: 0.6732\n",
            "Epoch 265/300.. Learning rate: 0.0017.. Train Loss: 0.0138.. Train Acc: 0.9991.. Validation Loss: 1.4045.. Validation Acc: 0.6756\n",
            "Epoch 266/300.. Learning rate: 0.0016.. Train Loss: 0.0136.. Train Acc: 0.9993.. Validation Loss: 1.4008.. Validation Acc: 0.6727\n",
            "Epoch 267/300.. Learning rate: 0.0015.. Train Loss: 0.0134.. Train Acc: 0.9994.. Validation Loss: 1.4014.. Validation Acc: 0.6752\n",
            "Epoch 268/300.. Learning rate: 0.0014.. Train Loss: 0.0133.. Train Acc: 0.9995.. Validation Loss: 1.3942.. Validation Acc: 0.6791\n",
            "Epoch 269/300.. Learning rate: 0.0013.. Train Loss: 0.0131.. Train Acc: 0.9993.. Validation Loss: 1.4001.. Validation Acc: 0.6807\n",
            "Epoch 270/300.. Learning rate: 0.0012.. Train Loss: 0.0132.. Train Acc: 0.9993.. Validation Loss: 1.4129.. Validation Acc: 0.6751\n",
            "Epoch 271/300.. Learning rate: 0.0011.. Train Loss: 0.0132.. Train Acc: 0.9994.. Validation Loss: 1.3948.. Validation Acc: 0.6762\n",
            "Epoch 272/300.. Learning rate: 0.0011.. Train Loss: 0.0129.. Train Acc: 0.9993.. Validation Loss: 1.3913.. Validation Acc: 0.6759\n",
            "Epoch 273/300.. Learning rate: 0.0010.. Train Loss: 0.0129.. Train Acc: 0.9994.. Validation Loss: 1.4034.. Validation Acc: 0.6741\n",
            "Epoch 274/300.. Learning rate: 0.0009.. Train Loss: 0.0126.. Train Acc: 0.9994.. Validation Loss: 1.3970.. Validation Acc: 0.6751\n",
            "Epoch 275/300.. Learning rate: 0.0009.. Train Loss: 0.0129.. Train Acc: 0.9993.. Validation Loss: 1.3977.. Validation Acc: 0.6782\n",
            "Epoch 276/300.. Learning rate: 0.0008.. Train Loss: 0.0125.. Train Acc: 0.9995.. Validation Loss: 1.3928.. Validation Acc: 0.6749\n",
            "Epoch 277/300.. Learning rate: 0.0007.. Train Loss: 0.0123.. Train Acc: 0.9995.. Validation Loss: 1.4017.. Validation Acc: 0.6755\n",
            "Epoch 278/300.. Learning rate: 0.0007.. Train Loss: 0.0122.. Train Acc: 0.9995.. Validation Loss: 1.3952.. Validation Acc: 0.6777\n",
            "Epoch 279/300.. Learning rate: 0.0006.. Train Loss: 0.0119.. Train Acc: 0.9995.. Validation Loss: 1.3974.. Validation Acc: 0.6756\n",
            "Epoch 280/300.. Learning rate: 0.0005.. Train Loss: 0.0126.. Train Acc: 0.9996.. Validation Loss: 1.3906.. Validation Acc: 0.6747\n",
            "Epoch 281/300.. Learning rate: 0.0005.. Train Loss: 0.0124.. Train Acc: 0.9996.. Validation Loss: 1.3850.. Validation Acc: 0.6763\n",
            "Epoch 282/300.. Learning rate: 0.0004.. Train Loss: 0.0119.. Train Acc: 0.9996.. Validation Loss: 1.3762.. Validation Acc: 0.6801\n",
            "Epoch 283/300.. Learning rate: 0.0004.. Train Loss: 0.0121.. Train Acc: 0.9996.. Validation Loss: 1.3906.. Validation Acc: 0.6783\n",
            "Epoch 284/300.. Learning rate: 0.0004.. Train Loss: 0.0120.. Train Acc: 0.9995.. Validation Loss: 1.3873.. Validation Acc: 0.6787\n",
            "Epoch 285/300.. Learning rate: 0.0003.. Train Loss: 0.0121.. Train Acc: 0.9995.. Validation Loss: 1.3825.. Validation Acc: 0.6820\n",
            "Epoch 286/300.. Learning rate: 0.0003.. Train Loss: 0.0119.. Train Acc: 0.9995.. Validation Loss: 1.3774.. Validation Acc: 0.6811\n",
            "Epoch 287/300.. Learning rate: 0.0002.. Train Loss: 0.0119.. Train Acc: 0.9996.. Validation Loss: 1.3830.. Validation Acc: 0.6779\n",
            "Epoch 288/300.. Learning rate: 0.0002.. Train Loss: 0.0120.. Train Acc: 0.9995.. Validation Loss: 1.3834.. Validation Acc: 0.6792\n",
            "Epoch 289/300.. Learning rate: 0.0002.. Train Loss: 0.0121.. Train Acc: 0.9995.. Validation Loss: 1.3888.. Validation Acc: 0.6758\n",
            "Epoch 290/300.. Learning rate: 0.0001.. Train Loss: 0.0122.. Train Acc: 0.9995.. Validation Loss: 1.3876.. Validation Acc: 0.6774\n",
            "Epoch 291/300.. Learning rate: 0.0001.. Train Loss: 0.0119.. Train Acc: 0.9996.. Validation Loss: 1.3876.. Validation Acc: 0.6722\n",
            "Epoch 292/300.. Learning rate: 0.0001.. Train Loss: 0.0119.. Train Acc: 0.9995.. Validation Loss: 1.3926.. Validation Acc: 0.6754\n",
            "Epoch 293/300.. Learning rate: 0.0001.. Train Loss: 0.0123.. Train Acc: 0.9994.. Validation Loss: 1.3851.. Validation Acc: 0.6761\n",
            "Epoch 294/300.. Learning rate: 0.0001.. Train Loss: 0.0121.. Train Acc: 0.9997.. Validation Loss: 1.3811.. Validation Acc: 0.6775\n",
            "Epoch 295/300.. Learning rate: 0.0000.. Train Loss: 0.0121.. Train Acc: 0.9997.. Validation Loss: 1.3906.. Validation Acc: 0.6755\n",
            "Epoch 296/300.. Learning rate: 0.0000.. Train Loss: 0.0121.. Train Acc: 0.9997.. Validation Loss: 1.3712.. Validation Acc: 0.6842\n",
            "Epoch 297/300.. Learning rate: 0.0000.. Train Loss: 0.0119.. Train Acc: 0.9996.. Validation Loss: 1.3811.. Validation Acc: 0.6801\n",
            "Epoch 298/300.. Learning rate: 0.0000.. Train Loss: 0.0116.. Train Acc: 0.9997.. Validation Loss: 1.3884.. Validation Acc: 0.6811\n",
            "Epoch 299/300.. Learning rate: 0.0000.. Train Loss: 0.0118.. Train Acc: 0.9996.. Validation Loss: 1.3854.. Validation Acc: 0.6812\n",
            "Epoch 300/300.. Learning rate: 0.0000.. Train Loss: 0.0121.. Train Acc: 0.9997.. Validation Loss: 1.3858.. Validation Acc: 0.6769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_acc(stat_training_loss, stat_val_loss, stat_training_acc, stat_val_acc, \"weightdecay_five\")"
      ],
      "metadata": {
        "id": "cEoHACLrYvTa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR = 0.05, LRS = cosine annealing, weight decay coefficient = λ = 1 × 10−4\n"
      ],
      "metadata": {
        "id": "qOWcRherIHoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.05"
      ],
      "metadata": {
        "id": "0OAnlToiHta-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])\n",
        "    ])\n",
        "\n",
        "# Split data set\n",
        "dataset = torchvision.datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(0.8 * num_train))  # 80% for training, 20% for validation\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[:split], indices[split:]\n",
        "\n",
        "train_sampler = data.sampler.SubsetRandomSampler(train_indices)\n",
        "val_sampler = data.sampler.SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=val_sampler)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFx0QGKkHtXH",
        "outputId": "2913bd54-583a-4fcd-ec31-8d73669ef139"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:06<00:00, 27104820.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = MobileNet(100)\n",
        "#print(model)\n",
        "model.cuda()\n",
        "\n",
        "# criterion\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "# scheduler\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=300, eta_min=0)"
      ],
      "metadata": {
        "id": "nzhSOtXOHtTc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stat_training_loss = []\n",
        "stat_val_loss = []\n",
        "stat_training_acc = []\n",
        "stat_val_acc = []"
      ],
      "metadata": {
        "id": "5mX_Wpq-HtPS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(300):\n",
        "    training_loss = 0\n",
        "    training_acc = 0\n",
        "    training_samples = 0\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    val_samples = 0\n",
        "    # training\n",
        "    model.train()\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "        optimizer.zero_grad()\n",
        "        logits = model.forward(imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, top_class = logits.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape).long()\n",
        "        training_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        training_loss += batch_size * loss.item()\n",
        "        training_samples += batch_size\n",
        "    # validation\n",
        "    model.eval()\n",
        "    for val_imgs, val_labels in valid_loader:\n",
        "        batch_size = val_imgs.shape[0]\n",
        "        val_logits = model.forward(val_imgs.cuda())\n",
        "        loss = criterion(val_logits, val_labels.cuda())\n",
        "        _, top_class = val_logits.topk(1, dim=1)\n",
        "        equals = top_class == val_labels.cuda().view(*top_class.shape)\n",
        "        val_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        val_loss += batch_size * loss.item()\n",
        "        val_samples += batch_size\n",
        "    assert val_samples == 10000\n",
        "    # update stats\n",
        "    stat_training_loss.append(training_loss/training_samples)\n",
        "    stat_val_loss.append(val_loss/val_samples)\n",
        "    stat_training_acc.append(training_acc/training_samples)\n",
        "    stat_val_acc.append(val_acc/val_samples)\n",
        "    # print\n",
        "    #print(f\"Epoch {(epoch+1):d}/{args.epochs:d}.. Learning rate: {scheduler.get_lr()[0]:.4f}.. Train loss: {(training_loss/training_samples):.4f}.. Train acc: {(training_acc/training_samples):.4f}.. Val loss: {(val_loss/val_samples):.4f}.. Val acc: {(val_acc/val_samples):.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{300}.. \"\n",
        "          f\"Learning rate: {scheduler.get_lr()[0]:.4f}.. \"\n",
        "          f\"Train Loss: {training_loss / training_samples:.4f}.. \"\n",
        "          f\"Train Acc: {training_acc / training_samples:.4f}.. \"\n",
        "          f\"Validation Loss: {val_loss / val_samples:.4f}.. \"\n",
        "          f\"Validation Acc: {val_acc / val_samples:.4f}\")\n",
        "    # lr scheduler\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZR64aUFHtJn",
        "outputId": "baf6273a-aea2-46f3-833b-e8acbad076d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300.. Learning rate: 0.0500.. Train Loss: 4.1714.. Train Acc: 0.0617.. Validation Loss: 3.7579.. Validation Acc: 0.1080\n",
            "Epoch 2/300.. Learning rate: 0.0500.. Train Loss: 3.6083.. Train Acc: 0.1382.. Validation Loss: 3.5356.. Validation Acc: 0.1545\n",
            "Epoch 3/300.. Learning rate: 0.0500.. Train Loss: 3.3299.. Train Acc: 0.1829.. Validation Loss: 3.3137.. Validation Acc: 0.1962\n",
            "Epoch 4/300.. Learning rate: 0.0500.. Train Loss: 3.1197.. Train Acc: 0.2220.. Validation Loss: 3.0923.. Validation Acc: 0.2270\n",
            "Epoch 5/300.. Learning rate: 0.0500.. Train Loss: 2.9411.. Train Acc: 0.2568.. Validation Loss: 3.0716.. Validation Acc: 0.2351\n",
            "Epoch 6/300.. Learning rate: 0.0500.. Train Loss: 2.7588.. Train Acc: 0.2893.. Validation Loss: 2.8649.. Validation Acc: 0.2781\n",
            "Epoch 7/300.. Learning rate: 0.0499.. Train Loss: 2.5862.. Train Acc: 0.3248.. Validation Loss: 2.6884.. Validation Acc: 0.3071\n",
            "Epoch 8/300.. Learning rate: 0.0499.. Train Loss: 2.4503.. Train Acc: 0.3510.. Validation Loss: 2.5488.. Validation Acc: 0.3398\n",
            "Epoch 9/300.. Learning rate: 0.0499.. Train Loss: 2.3133.. Train Acc: 0.3822.. Validation Loss: 2.4255.. Validation Acc: 0.3628\n",
            "Epoch 10/300.. Learning rate: 0.0499.. Train Loss: 2.1928.. Train Acc: 0.4089.. Validation Loss: 2.4551.. Validation Acc: 0.3639\n",
            "Epoch 11/300.. Learning rate: 0.0498.. Train Loss: 2.0864.. Train Acc: 0.4320.. Validation Loss: 2.3700.. Validation Acc: 0.3822\n",
            "Epoch 12/300.. Learning rate: 0.0498.. Train Loss: 1.9916.. Train Acc: 0.4501.. Validation Loss: 2.2713.. Validation Acc: 0.4046\n",
            "Epoch 13/300.. Learning rate: 0.0498.. Train Loss: 1.9084.. Train Acc: 0.4710.. Validation Loss: 2.2172.. Validation Acc: 0.4114\n",
            "Epoch 14/300.. Learning rate: 0.0497.. Train Loss: 1.8206.. Train Acc: 0.4910.. Validation Loss: 2.1583.. Validation Acc: 0.4225\n",
            "Epoch 15/300.. Learning rate: 0.0497.. Train Loss: 1.7517.. Train Acc: 0.5072.. Validation Loss: 2.1284.. Validation Acc: 0.4292\n",
            "Epoch 16/300.. Learning rate: 0.0497.. Train Loss: 1.6782.. Train Acc: 0.5255.. Validation Loss: 2.2175.. Validation Acc: 0.4170\n",
            "Epoch 17/300.. Learning rate: 0.0496.. Train Loss: 1.6126.. Train Acc: 0.5405.. Validation Loss: 2.0924.. Validation Acc: 0.4381\n",
            "Epoch 18/300.. Learning rate: 0.0496.. Train Loss: 1.5538.. Train Acc: 0.5537.. Validation Loss: 2.0092.. Validation Acc: 0.4639\n",
            "Epoch 19/300.. Learning rate: 0.0495.. Train Loss: 1.5069.. Train Acc: 0.5659.. Validation Loss: 1.9679.. Validation Acc: 0.4709\n",
            "Epoch 20/300.. Learning rate: 0.0495.. Train Loss: 1.4301.. Train Acc: 0.5831.. Validation Loss: 2.0099.. Validation Acc: 0.4649\n",
            "Epoch 21/300.. Learning rate: 0.0494.. Train Loss: 1.3793.. Train Acc: 0.5975.. Validation Loss: 2.0089.. Validation Acc: 0.4794\n",
            "Epoch 22/300.. Learning rate: 0.0493.. Train Loss: 1.3380.. Train Acc: 0.6085.. Validation Loss: 1.9470.. Validation Acc: 0.4876\n",
            "Epoch 23/300.. Learning rate: 0.0493.. Train Loss: 1.2855.. Train Acc: 0.6222.. Validation Loss: 1.9960.. Validation Acc: 0.4802\n",
            "Epoch 24/300.. Learning rate: 0.0492.. Train Loss: 1.2331.. Train Acc: 0.6341.. Validation Loss: 1.9390.. Validation Acc: 0.4953\n",
            "Epoch 25/300.. Learning rate: 0.0492.. Train Loss: 1.1971.. Train Acc: 0.6448.. Validation Loss: 1.9021.. Validation Acc: 0.4997\n",
            "Epoch 26/300.. Learning rate: 0.0491.. Train Loss: 1.1456.. Train Acc: 0.6574.. Validation Loss: 1.9148.. Validation Acc: 0.4974\n",
            "Epoch 27/300.. Learning rate: 0.0490.. Train Loss: 1.1040.. Train Acc: 0.6686.. Validation Loss: 1.9355.. Validation Acc: 0.5056\n",
            "Epoch 28/300.. Learning rate: 0.0489.. Train Loss: 1.0626.. Train Acc: 0.6798.. Validation Loss: 1.9222.. Validation Acc: 0.5063\n",
            "Epoch 29/300.. Learning rate: 0.0489.. Train Loss: 1.0316.. Train Acc: 0.6844.. Validation Loss: 1.8861.. Validation Acc: 0.5105\n",
            "Epoch 30/300.. Learning rate: 0.0488.. Train Loss: 0.9923.. Train Acc: 0.6974.. Validation Loss: 1.9198.. Validation Acc: 0.5069\n",
            "Epoch 31/300.. Learning rate: 0.0487.. Train Loss: 0.9533.. Train Acc: 0.7065.. Validation Loss: 1.9392.. Validation Acc: 0.5136\n",
            "Epoch 32/300.. Learning rate: 0.0486.. Train Loss: 0.9253.. Train Acc: 0.7145.. Validation Loss: 1.8910.. Validation Acc: 0.5249\n",
            "Epoch 33/300.. Learning rate: 0.0485.. Train Loss: 0.8779.. Train Acc: 0.7298.. Validation Loss: 1.9984.. Validation Acc: 0.5082\n",
            "Epoch 34/300.. Learning rate: 0.0484.. Train Loss: 0.8534.. Train Acc: 0.7362.. Validation Loss: 1.9392.. Validation Acc: 0.5204\n",
            "Epoch 35/300.. Learning rate: 0.0483.. Train Loss: 0.8122.. Train Acc: 0.7459.. Validation Loss: 1.9567.. Validation Acc: 0.5168\n",
            "Epoch 36/300.. Learning rate: 0.0482.. Train Loss: 0.7718.. Train Acc: 0.7560.. Validation Loss: 2.0586.. Validation Acc: 0.5078\n",
            "Epoch 37/300.. Learning rate: 0.0481.. Train Loss: 0.7490.. Train Acc: 0.7624.. Validation Loss: 2.0105.. Validation Acc: 0.5123\n",
            "Epoch 38/300.. Learning rate: 0.0480.. Train Loss: 0.7312.. Train Acc: 0.7688.. Validation Loss: 2.0778.. Validation Acc: 0.5072\n",
            "Epoch 39/300.. Learning rate: 0.0479.. Train Loss: 0.7020.. Train Acc: 0.7781.. Validation Loss: 2.0403.. Validation Acc: 0.5209\n",
            "Epoch 40/300.. Learning rate: 0.0478.. Train Loss: 0.6719.. Train Acc: 0.7861.. Validation Loss: 2.0359.. Validation Acc: 0.5186\n",
            "Epoch 41/300.. Learning rate: 0.0477.. Train Loss: 0.6366.. Train Acc: 0.7980.. Validation Loss: 2.0438.. Validation Acc: 0.5278\n",
            "Epoch 42/300.. Learning rate: 0.0476.. Train Loss: 0.6167.. Train Acc: 0.8046.. Validation Loss: 2.0527.. Validation Acc: 0.5224\n",
            "Epoch 43/300.. Learning rate: 0.0475.. Train Loss: 0.5927.. Train Acc: 0.8086.. Validation Loss: 2.0875.. Validation Acc: 0.5276\n",
            "Epoch 44/300.. Learning rate: 0.0474.. Train Loss: 0.5700.. Train Acc: 0.8166.. Validation Loss: 2.0760.. Validation Acc: 0.5247\n",
            "Epoch 45/300.. Learning rate: 0.0473.. Train Loss: 0.5484.. Train Acc: 0.8229.. Validation Loss: 2.0801.. Validation Acc: 0.5268\n",
            "Epoch 46/300.. Learning rate: 0.0472.. Train Loss: 0.5224.. Train Acc: 0.8302.. Validation Loss: 2.1108.. Validation Acc: 0.5280\n",
            "Epoch 47/300.. Learning rate: 0.0470.. Train Loss: 0.4897.. Train Acc: 0.8432.. Validation Loss: 2.1543.. Validation Acc: 0.5234\n",
            "Epoch 48/300.. Learning rate: 0.0469.. Train Loss: 0.4845.. Train Acc: 0.8427.. Validation Loss: 2.1586.. Validation Acc: 0.5256\n",
            "Epoch 49/300.. Learning rate: 0.0468.. Train Loss: 0.4579.. Train Acc: 0.8492.. Validation Loss: 2.2144.. Validation Acc: 0.5229\n",
            "Epoch 50/300.. Learning rate: 0.0467.. Train Loss: 0.4699.. Train Acc: 0.8460.. Validation Loss: 2.2195.. Validation Acc: 0.5215\n",
            "Epoch 51/300.. Learning rate: 0.0465.. Train Loss: 0.4299.. Train Acc: 0.8605.. Validation Loss: 2.2092.. Validation Acc: 0.5227\n",
            "Epoch 52/300.. Learning rate: 0.0464.. Train Loss: 0.4084.. Train Acc: 0.8663.. Validation Loss: 2.3423.. Validation Acc: 0.5158\n",
            "Epoch 53/300.. Learning rate: 0.0463.. Train Loss: 0.4073.. Train Acc: 0.8664.. Validation Loss: 2.2210.. Validation Acc: 0.5267\n",
            "Epoch 54/300.. Learning rate: 0.0461.. Train Loss: 0.3888.. Train Acc: 0.8730.. Validation Loss: 2.2003.. Validation Acc: 0.5304\n",
            "Epoch 55/300.. Learning rate: 0.0460.. Train Loss: 0.3478.. Train Acc: 0.8879.. Validation Loss: 2.3630.. Validation Acc: 0.5141\n",
            "Epoch 56/300.. Learning rate: 0.0458.. Train Loss: 0.3452.. Train Acc: 0.8873.. Validation Loss: 2.2568.. Validation Acc: 0.5327\n",
            "Epoch 57/300.. Learning rate: 0.0457.. Train Loss: 0.3499.. Train Acc: 0.8853.. Validation Loss: 2.2710.. Validation Acc: 0.5347\n",
            "Epoch 58/300.. Learning rate: 0.0455.. Train Loss: 0.3275.. Train Acc: 0.8928.. Validation Loss: 2.2989.. Validation Acc: 0.5221\n",
            "Epoch 59/300.. Learning rate: 0.0454.. Train Loss: 0.3376.. Train Acc: 0.8915.. Validation Loss: 2.3266.. Validation Acc: 0.5247\n",
            "Epoch 60/300.. Learning rate: 0.0452.. Train Loss: 0.3246.. Train Acc: 0.8941.. Validation Loss: 2.3202.. Validation Acc: 0.5289\n",
            "Epoch 61/300.. Learning rate: 0.0451.. Train Loss: 0.3050.. Train Acc: 0.9030.. Validation Loss: 2.3279.. Validation Acc: 0.5292\n",
            "Epoch 62/300.. Learning rate: 0.0449.. Train Loss: 0.2869.. Train Acc: 0.9068.. Validation Loss: 2.2736.. Validation Acc: 0.5373\n",
            "Epoch 63/300.. Learning rate: 0.0448.. Train Loss: 0.2823.. Train Acc: 0.9092.. Validation Loss: 2.3128.. Validation Acc: 0.5299\n",
            "Epoch 64/300.. Learning rate: 0.0446.. Train Loss: 0.2813.. Train Acc: 0.9106.. Validation Loss: 2.3238.. Validation Acc: 0.5370\n",
            "Epoch 65/300.. Learning rate: 0.0444.. Train Loss: 0.2724.. Train Acc: 0.9128.. Validation Loss: 2.3057.. Validation Acc: 0.5356\n",
            "Epoch 66/300.. Learning rate: 0.0443.. Train Loss: 0.2551.. Train Acc: 0.9166.. Validation Loss: 2.3315.. Validation Acc: 0.5368\n",
            "Epoch 67/300.. Learning rate: 0.0441.. Train Loss: 0.2513.. Train Acc: 0.9192.. Validation Loss: 2.3003.. Validation Acc: 0.5382\n",
            "Epoch 68/300.. Learning rate: 0.0439.. Train Loss: 0.2570.. Train Acc: 0.9162.. Validation Loss: 2.4066.. Validation Acc: 0.5249\n",
            "Epoch 69/300.. Learning rate: 0.0438.. Train Loss: 0.2407.. Train Acc: 0.9241.. Validation Loss: 2.3459.. Validation Acc: 0.5293\n",
            "Epoch 70/300.. Learning rate: 0.0436.. Train Loss: 0.2329.. Train Acc: 0.9254.. Validation Loss: 2.3880.. Validation Acc: 0.5315\n",
            "Epoch 71/300.. Learning rate: 0.0434.. Train Loss: 0.2150.. Train Acc: 0.9314.. Validation Loss: 2.3584.. Validation Acc: 0.5365\n",
            "Epoch 72/300.. Learning rate: 0.0432.. Train Loss: 0.2180.. Train Acc: 0.9302.. Validation Loss: 2.2743.. Validation Acc: 0.5457\n",
            "Epoch 73/300.. Learning rate: 0.0430.. Train Loss: 0.2156.. Train Acc: 0.9297.. Validation Loss: 2.3733.. Validation Acc: 0.5304\n",
            "Epoch 74/300.. Learning rate: 0.0429.. Train Loss: 0.2164.. Train Acc: 0.9300.. Validation Loss: 2.3237.. Validation Acc: 0.5435\n",
            "Epoch 75/300.. Learning rate: 0.0427.. Train Loss: 0.2204.. Train Acc: 0.9297.. Validation Loss: 2.3615.. Validation Acc: 0.5285\n",
            "Epoch 76/300.. Learning rate: 0.0425.. Train Loss: 0.2145.. Train Acc: 0.9312.. Validation Loss: 2.3652.. Validation Acc: 0.5370\n",
            "Epoch 77/300.. Learning rate: 0.0423.. Train Loss: 0.1881.. Train Acc: 0.9411.. Validation Loss: 2.3977.. Validation Acc: 0.5376\n",
            "Epoch 78/300.. Learning rate: 0.0421.. Train Loss: 0.1913.. Train Acc: 0.9393.. Validation Loss: 2.3719.. Validation Acc: 0.5351\n",
            "Epoch 79/300.. Learning rate: 0.0419.. Train Loss: 0.1842.. Train Acc: 0.9419.. Validation Loss: 2.3486.. Validation Acc: 0.5436\n",
            "Epoch 80/300.. Learning rate: 0.0417.. Train Loss: 0.1899.. Train Acc: 0.9405.. Validation Loss: 2.4146.. Validation Acc: 0.5272\n",
            "Epoch 81/300.. Learning rate: 0.0415.. Train Loss: 0.1968.. Train Acc: 0.9385.. Validation Loss: 2.4152.. Validation Acc: 0.5366\n",
            "Epoch 82/300.. Learning rate: 0.0413.. Train Loss: 0.1803.. Train Acc: 0.9419.. Validation Loss: 2.4141.. Validation Acc: 0.5352\n",
            "Epoch 83/300.. Learning rate: 0.0411.. Train Loss: 0.1744.. Train Acc: 0.9441.. Validation Loss: 2.3562.. Validation Acc: 0.5414\n",
            "Epoch 84/300.. Learning rate: 0.0409.. Train Loss: 0.1679.. Train Acc: 0.9466.. Validation Loss: 2.3898.. Validation Acc: 0.5334\n",
            "Epoch 85/300.. Learning rate: 0.0407.. Train Loss: 0.1856.. Train Acc: 0.9418.. Validation Loss: 2.3867.. Validation Acc: 0.5390\n",
            "Epoch 86/300.. Learning rate: 0.0405.. Train Loss: 0.1728.. Train Acc: 0.9443.. Validation Loss: 2.4907.. Validation Acc: 0.5204\n",
            "Epoch 87/300.. Learning rate: 0.0403.. Train Loss: 0.1815.. Train Acc: 0.9437.. Validation Loss: 2.4080.. Validation Acc: 0.5317\n",
            "Epoch 88/300.. Learning rate: 0.0401.. Train Loss: 0.1555.. Train Acc: 0.9521.. Validation Loss: 2.3680.. Validation Acc: 0.5436\n",
            "Epoch 89/300.. Learning rate: 0.0399.. Train Loss: 0.1579.. Train Acc: 0.9503.. Validation Loss: 2.3666.. Validation Acc: 0.5451\n",
            "Epoch 90/300.. Learning rate: 0.0397.. Train Loss: 0.1618.. Train Acc: 0.9495.. Validation Loss: 2.3666.. Validation Acc: 0.5382\n",
            "Epoch 91/300.. Learning rate: 0.0395.. Train Loss: 0.1440.. Train Acc: 0.9554.. Validation Loss: 2.3956.. Validation Acc: 0.5433\n",
            "Epoch 92/300.. Learning rate: 0.0393.. Train Loss: 0.1344.. Train Acc: 0.9587.. Validation Loss: 2.4095.. Validation Acc: 0.5379\n",
            "Epoch 93/300.. Learning rate: 0.0391.. Train Loss: 0.1550.. Train Acc: 0.9513.. Validation Loss: 2.4613.. Validation Acc: 0.5289\n",
            "Epoch 94/300.. Learning rate: 0.0388.. Train Loss: 0.1512.. Train Acc: 0.9518.. Validation Loss: 2.4172.. Validation Acc: 0.5361\n",
            "Epoch 95/300.. Learning rate: 0.0386.. Train Loss: 0.1457.. Train Acc: 0.9554.. Validation Loss: 2.3498.. Validation Acc: 0.5500\n",
            "Epoch 96/300.. Learning rate: 0.0384.. Train Loss: 0.1243.. Train Acc: 0.9619.. Validation Loss: 2.4142.. Validation Acc: 0.5468\n",
            "Epoch 97/300.. Learning rate: 0.0382.. Train Loss: 0.1318.. Train Acc: 0.9597.. Validation Loss: 2.3897.. Validation Acc: 0.5382\n",
            "Epoch 98/300.. Learning rate: 0.0380.. Train Loss: 0.1171.. Train Acc: 0.9650.. Validation Loss: 2.3700.. Validation Acc: 0.5444\n",
            "Epoch 99/300.. Learning rate: 0.0377.. Train Loss: 0.1203.. Train Acc: 0.9638.. Validation Loss: 2.4106.. Validation Acc: 0.5423\n",
            "Epoch 100/300.. Learning rate: 0.0375.. Train Loss: 0.1200.. Train Acc: 0.9637.. Validation Loss: 2.4210.. Validation Acc: 0.5419\n",
            "Epoch 101/300.. Learning rate: 0.0373.. Train Loss: 0.1252.. Train Acc: 0.9611.. Validation Loss: 2.4439.. Validation Acc: 0.5417\n",
            "Epoch 102/300.. Learning rate: 0.0370.. Train Loss: 0.1205.. Train Acc: 0.9637.. Validation Loss: 2.3956.. Validation Acc: 0.5465\n",
            "Epoch 103/300.. Learning rate: 0.0368.. Train Loss: 0.1261.. Train Acc: 0.9609.. Validation Loss: 2.3792.. Validation Acc: 0.5507\n",
            "Epoch 104/300.. Learning rate: 0.0366.. Train Loss: 0.1242.. Train Acc: 0.9624.. Validation Loss: 2.4163.. Validation Acc: 0.5429\n",
            "Epoch 105/300.. Learning rate: 0.0364.. Train Loss: 0.1195.. Train Acc: 0.9647.. Validation Loss: 2.4758.. Validation Acc: 0.5385\n",
            "Epoch 106/300.. Learning rate: 0.0361.. Train Loss: 0.1224.. Train Acc: 0.9618.. Validation Loss: 2.4042.. Validation Acc: 0.5421\n",
            "Epoch 107/300.. Learning rate: 0.0359.. Train Loss: 0.1174.. Train Acc: 0.9639.. Validation Loss: 2.4198.. Validation Acc: 0.5433\n",
            "Epoch 108/300.. Learning rate: 0.0356.. Train Loss: 0.1225.. Train Acc: 0.9620.. Validation Loss: 2.4027.. Validation Acc: 0.5449\n",
            "Epoch 109/300.. Learning rate: 0.0354.. Train Loss: 0.1138.. Train Acc: 0.9662.. Validation Loss: 2.3656.. Validation Acc: 0.5492\n",
            "Epoch 110/300.. Learning rate: 0.0352.. Train Loss: 0.1066.. Train Acc: 0.9679.. Validation Loss: 2.3724.. Validation Acc: 0.5462\n",
            "Epoch 111/300.. Learning rate: 0.0349.. Train Loss: 0.1035.. Train Acc: 0.9697.. Validation Loss: 2.4026.. Validation Acc: 0.5470\n",
            "Epoch 112/300.. Learning rate: 0.0347.. Train Loss: 0.0952.. Train Acc: 0.9717.. Validation Loss: 2.3818.. Validation Acc: 0.5460\n",
            "Epoch 113/300.. Learning rate: 0.0344.. Train Loss: 0.0972.. Train Acc: 0.9709.. Validation Loss: 2.3677.. Validation Acc: 0.5506\n",
            "Epoch 114/300.. Learning rate: 0.0342.. Train Loss: 0.0903.. Train Acc: 0.9740.. Validation Loss: 2.3592.. Validation Acc: 0.5559\n",
            "Epoch 115/300.. Learning rate: 0.0340.. Train Loss: 0.0827.. Train Acc: 0.9764.. Validation Loss: 2.3856.. Validation Acc: 0.5465\n",
            "Epoch 116/300.. Learning rate: 0.0337.. Train Loss: 0.0850.. Train Acc: 0.9748.. Validation Loss: 2.3781.. Validation Acc: 0.5523\n",
            "Epoch 117/300.. Learning rate: 0.0335.. Train Loss: 0.0832.. Train Acc: 0.9760.. Validation Loss: 2.3647.. Validation Acc: 0.5497\n",
            "Epoch 118/300.. Learning rate: 0.0332.. Train Loss: 0.0757.. Train Acc: 0.9784.. Validation Loss: 2.4035.. Validation Acc: 0.5515\n",
            "Epoch 119/300.. Learning rate: 0.0330.. Train Loss: 0.0879.. Train Acc: 0.9744.. Validation Loss: 2.3747.. Validation Acc: 0.5484\n",
            "Epoch 120/300.. Learning rate: 0.0327.. Train Loss: 0.0886.. Train Acc: 0.9738.. Validation Loss: 2.4235.. Validation Acc: 0.5445\n",
            "Epoch 121/300.. Learning rate: 0.0325.. Train Loss: 0.0896.. Train Acc: 0.9734.. Validation Loss: 2.4110.. Validation Acc: 0.5443\n",
            "Epoch 122/300.. Learning rate: 0.0322.. Train Loss: 0.0815.. Train Acc: 0.9766.. Validation Loss: 2.3983.. Validation Acc: 0.5510\n",
            "Epoch 123/300.. Learning rate: 0.0320.. Train Loss: 0.0701.. Train Acc: 0.9806.. Validation Loss: 2.3654.. Validation Acc: 0.5603\n",
            "Epoch 124/300.. Learning rate: 0.0317.. Train Loss: 0.0626.. Train Acc: 0.9832.. Validation Loss: 2.3369.. Validation Acc: 0.5610\n",
            "Epoch 125/300.. Learning rate: 0.0315.. Train Loss: 0.0665.. Train Acc: 0.9810.. Validation Loss: 2.3811.. Validation Acc: 0.5555\n",
            "Epoch 126/300.. Learning rate: 0.0312.. Train Loss: 0.0676.. Train Acc: 0.9812.. Validation Loss: 2.3695.. Validation Acc: 0.5530\n",
            "Epoch 127/300.. Learning rate: 0.0310.. Train Loss: 0.0646.. Train Acc: 0.9819.. Validation Loss: 2.3565.. Validation Acc: 0.5602\n",
            "Epoch 128/300.. Learning rate: 0.0307.. Train Loss: 0.0585.. Train Acc: 0.9840.. Validation Loss: 2.3609.. Validation Acc: 0.5595\n",
            "Epoch 129/300.. Learning rate: 0.0305.. Train Loss: 0.0598.. Train Acc: 0.9841.. Validation Loss: 2.3487.. Validation Acc: 0.5616\n",
            "Epoch 130/300.. Learning rate: 0.0302.. Train Loss: 0.0557.. Train Acc: 0.9850.. Validation Loss: 2.3466.. Validation Acc: 0.5639\n",
            "Epoch 131/300.. Learning rate: 0.0299.. Train Loss: 0.0593.. Train Acc: 0.9840.. Validation Loss: 2.3517.. Validation Acc: 0.5594\n",
            "Epoch 132/300.. Learning rate: 0.0297.. Train Loss: 0.0564.. Train Acc: 0.9849.. Validation Loss: 2.3217.. Validation Acc: 0.5591\n",
            "Epoch 133/300.. Learning rate: 0.0294.. Train Loss: 0.0499.. Train Acc: 0.9865.. Validation Loss: 2.3406.. Validation Acc: 0.5551\n",
            "Epoch 134/300.. Learning rate: 0.0292.. Train Loss: 0.0497.. Train Acc: 0.9867.. Validation Loss: 2.3256.. Validation Acc: 0.5622\n",
            "Epoch 135/300.. Learning rate: 0.0289.. Train Loss: 0.0443.. Train Acc: 0.9885.. Validation Loss: 2.3059.. Validation Acc: 0.5660\n",
            "Epoch 136/300.. Learning rate: 0.0287.. Train Loss: 0.0463.. Train Acc: 0.9885.. Validation Loss: 2.3672.. Validation Acc: 0.5602\n",
            "Epoch 137/300.. Learning rate: 0.0284.. Train Loss: 0.0460.. Train Acc: 0.9877.. Validation Loss: 2.3342.. Validation Acc: 0.5602\n",
            "Epoch 138/300.. Learning rate: 0.0281.. Train Loss: 0.0446.. Train Acc: 0.9889.. Validation Loss: 2.3304.. Validation Acc: 0.5609\n",
            "Epoch 139/300.. Learning rate: 0.0279.. Train Loss: 0.0361.. Train Acc: 0.9917.. Validation Loss: 2.2728.. Validation Acc: 0.5678\n",
            "Epoch 140/300.. Learning rate: 0.0276.. Train Loss: 0.0372.. Train Acc: 0.9907.. Validation Loss: 2.2723.. Validation Acc: 0.5726\n",
            "Epoch 141/300.. Learning rate: 0.0274.. Train Loss: 0.0327.. Train Acc: 0.9923.. Validation Loss: 2.2858.. Validation Acc: 0.5723\n",
            "Epoch 142/300.. Learning rate: 0.0271.. Train Loss: 0.0328.. Train Acc: 0.9922.. Validation Loss: 2.3042.. Validation Acc: 0.5661\n",
            "Epoch 143/300.. Learning rate: 0.0268.. Train Loss: 0.0337.. Train Acc: 0.9920.. Validation Loss: 2.2528.. Validation Acc: 0.5689\n",
            "Epoch 144/300.. Learning rate: 0.0266.. Train Loss: 0.0290.. Train Acc: 0.9940.. Validation Loss: 2.2529.. Validation Acc: 0.5727\n",
            "Epoch 145/300.. Learning rate: 0.0263.. Train Loss: 0.0241.. Train Acc: 0.9951.. Validation Loss: 2.2184.. Validation Acc: 0.5799\n",
            "Epoch 146/300.. Learning rate: 0.0260.. Train Loss: 0.0211.. Train Acc: 0.9959.. Validation Loss: 2.2310.. Validation Acc: 0.5735\n",
            "Epoch 147/300.. Learning rate: 0.0258.. Train Loss: 0.0234.. Train Acc: 0.9949.. Validation Loss: 2.2447.. Validation Acc: 0.5733\n",
            "Epoch 148/300.. Learning rate: 0.0255.. Train Loss: 0.0227.. Train Acc: 0.9960.. Validation Loss: 2.2185.. Validation Acc: 0.5716\n",
            "Epoch 149/300.. Learning rate: 0.0253.. Train Loss: 0.0167.. Train Acc: 0.9969.. Validation Loss: 2.1887.. Validation Acc: 0.5787\n",
            "Epoch 150/300.. Learning rate: 0.0250.. Train Loss: 0.0153.. Train Acc: 0.9970.. Validation Loss: 2.1888.. Validation Acc: 0.5710\n",
            "Epoch 151/300.. Learning rate: 0.0247.. Train Loss: 0.0172.. Train Acc: 0.9967.. Validation Loss: 2.1650.. Validation Acc: 0.5805\n",
            "Epoch 152/300.. Learning rate: 0.0245.. Train Loss: 0.0135.. Train Acc: 0.9978.. Validation Loss: 2.1776.. Validation Acc: 0.5776\n",
            "Epoch 153/300.. Learning rate: 0.0242.. Train Loss: 0.0112.. Train Acc: 0.9986.. Validation Loss: 2.1419.. Validation Acc: 0.5837\n",
            "Epoch 154/300.. Learning rate: 0.0240.. Train Loss: 0.0107.. Train Acc: 0.9985.. Validation Loss: 2.1062.. Validation Acc: 0.5847\n",
            "Epoch 155/300.. Learning rate: 0.0237.. Train Loss: 0.0122.. Train Acc: 0.9978.. Validation Loss: 2.1245.. Validation Acc: 0.5808\n",
            "Epoch 156/300.. Learning rate: 0.0234.. Train Loss: 0.0114.. Train Acc: 0.9984.. Validation Loss: 2.1015.. Validation Acc: 0.5817\n",
            "Epoch 157/300.. Learning rate: 0.0232.. Train Loss: 0.0108.. Train Acc: 0.9982.. Validation Loss: 2.0907.. Validation Acc: 0.5820\n",
            "Epoch 158/300.. Learning rate: 0.0229.. Train Loss: 0.0086.. Train Acc: 0.9989.. Validation Loss: 2.0716.. Validation Acc: 0.5893\n",
            "Epoch 159/300.. Learning rate: 0.0227.. Train Loss: 0.0077.. Train Acc: 0.9991.. Validation Loss: 2.0604.. Validation Acc: 0.5894\n",
            "Epoch 160/300.. Learning rate: 0.0224.. Train Loss: 0.0075.. Train Acc: 0.9990.. Validation Loss: 2.0608.. Validation Acc: 0.5876\n",
            "Epoch 161/300.. Learning rate: 0.0221.. Train Loss: 0.0069.. Train Acc: 0.9990.. Validation Loss: 2.0551.. Validation Acc: 0.5896\n",
            "Epoch 162/300.. Learning rate: 0.0219.. Train Loss: 0.0067.. Train Acc: 0.9991.. Validation Loss: 2.0243.. Validation Acc: 0.5923\n",
            "Epoch 163/300.. Learning rate: 0.0216.. Train Loss: 0.0054.. Train Acc: 0.9994.. Validation Loss: 2.0113.. Validation Acc: 0.5936\n",
            "Epoch 164/300.. Learning rate: 0.0214.. Train Loss: 0.0056.. Train Acc: 0.9993.. Validation Loss: 2.0104.. Validation Acc: 0.5943\n",
            "Epoch 165/300.. Learning rate: 0.0211.. Train Loss: 0.0052.. Train Acc: 0.9995.. Validation Loss: 1.9976.. Validation Acc: 0.5937\n",
            "Epoch 166/300.. Learning rate: 0.0208.. Train Loss: 0.0055.. Train Acc: 0.9993.. Validation Loss: 1.9877.. Validation Acc: 0.5941\n",
            "Epoch 167/300.. Learning rate: 0.0206.. Train Loss: 0.0049.. Train Acc: 0.9993.. Validation Loss: 1.9650.. Validation Acc: 0.5951\n",
            "Epoch 168/300.. Learning rate: 0.0203.. Train Loss: 0.0048.. Train Acc: 0.9994.. Validation Loss: 1.9675.. Validation Acc: 0.5962\n",
            "Epoch 169/300.. Learning rate: 0.0201.. Train Loss: 0.0049.. Train Acc: 0.9995.. Validation Loss: 1.9430.. Validation Acc: 0.5980\n",
            "Epoch 170/300.. Learning rate: 0.0198.. Train Loss: 0.0048.. Train Acc: 0.9996.. Validation Loss: 1.9572.. Validation Acc: 0.5964\n",
            "Epoch 171/300.. Learning rate: 0.0195.. Train Loss: 0.0045.. Train Acc: 0.9996.. Validation Loss: 1.9449.. Validation Acc: 0.5942\n",
            "Epoch 172/300.. Learning rate: 0.0193.. Train Loss: 0.0045.. Train Acc: 0.9994.. Validation Loss: 1.9466.. Validation Acc: 0.5966\n",
            "Epoch 173/300.. Learning rate: 0.0190.. Train Loss: 0.0046.. Train Acc: 0.9994.. Validation Loss: 1.9340.. Validation Acc: 0.5980\n",
            "Epoch 174/300.. Learning rate: 0.0188.. Train Loss: 0.0046.. Train Acc: 0.9995.. Validation Loss: 1.9223.. Validation Acc: 0.5978\n",
            "Epoch 175/300.. Learning rate: 0.0185.. Train Loss: 0.0047.. Train Acc: 0.9995.. Validation Loss: 1.9109.. Validation Acc: 0.6026\n",
            "Epoch 176/300.. Learning rate: 0.0183.. Train Loss: 0.0046.. Train Acc: 0.9995.. Validation Loss: 1.9041.. Validation Acc: 0.6011\n",
            "Epoch 177/300.. Learning rate: 0.0180.. Train Loss: 0.0044.. Train Acc: 0.9995.. Validation Loss: 1.8982.. Validation Acc: 0.6019\n",
            "Epoch 178/300.. Learning rate: 0.0178.. Train Loss: 0.0044.. Train Acc: 0.9994.. Validation Loss: 1.8884.. Validation Acc: 0.5990\n",
            "Epoch 179/300.. Learning rate: 0.0175.. Train Loss: 0.0042.. Train Acc: 0.9995.. Validation Loss: 1.8922.. Validation Acc: 0.6012\n",
            "Epoch 180/300.. Learning rate: 0.0173.. Train Loss: 0.0043.. Train Acc: 0.9996.. Validation Loss: 1.8900.. Validation Acc: 0.5990\n",
            "Epoch 181/300.. Learning rate: 0.0170.. Train Loss: 0.0044.. Train Acc: 0.9996.. Validation Loss: 1.8642.. Validation Acc: 0.6052\n",
            "Epoch 182/300.. Learning rate: 0.0168.. Train Loss: 0.0042.. Train Acc: 0.9996.. Validation Loss: 1.8815.. Validation Acc: 0.6036\n",
            "Epoch 183/300.. Learning rate: 0.0165.. Train Loss: 0.0041.. Train Acc: 0.9996.. Validation Loss: 1.8703.. Validation Acc: 0.6010\n",
            "Epoch 184/300.. Learning rate: 0.0163.. Train Loss: 0.0042.. Train Acc: 0.9995.. Validation Loss: 1.8558.. Validation Acc: 0.6052\n",
            "Epoch 185/300.. Learning rate: 0.0160.. Train Loss: 0.0038.. Train Acc: 0.9996.. Validation Loss: 1.8524.. Validation Acc: 0.6062\n",
            "Epoch 186/300.. Learning rate: 0.0158.. Train Loss: 0.0041.. Train Acc: 0.9996.. Validation Loss: 1.8531.. Validation Acc: 0.6009\n",
            "Epoch 187/300.. Learning rate: 0.0156.. Train Loss: 0.0041.. Train Acc: 0.9996.. Validation Loss: 1.8490.. Validation Acc: 0.5980\n",
            "Epoch 188/300.. Learning rate: 0.0153.. Train Loss: 0.0043.. Train Acc: 0.9995.. Validation Loss: 1.8461.. Validation Acc: 0.6014\n",
            "Epoch 189/300.. Learning rate: 0.0151.. Train Loss: 0.0040.. Train Acc: 0.9996.. Validation Loss: 1.8378.. Validation Acc: 0.6039\n",
            "Epoch 190/300.. Learning rate: 0.0148.. Train Loss: 0.0040.. Train Acc: 0.9996.. Validation Loss: 1.8347.. Validation Acc: 0.6022\n",
            "Epoch 191/300.. Learning rate: 0.0146.. Train Loss: 0.0040.. Train Acc: 0.9995.. Validation Loss: 1.8447.. Validation Acc: 0.6053\n",
            "Epoch 192/300.. Learning rate: 0.0144.. Train Loss: 0.0039.. Train Acc: 0.9996.. Validation Loss: 1.8223.. Validation Acc: 0.6048\n",
            "Epoch 193/300.. Learning rate: 0.0141.. Train Loss: 0.0042.. Train Acc: 0.9995.. Validation Loss: 1.8301.. Validation Acc: 0.6053\n",
            "Epoch 194/300.. Learning rate: 0.0139.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.8179.. Validation Acc: 0.6055\n",
            "Epoch 195/300.. Learning rate: 0.0137.. Train Loss: 0.0040.. Train Acc: 0.9997.. Validation Loss: 1.8253.. Validation Acc: 0.6052\n",
            "Epoch 196/300.. Learning rate: 0.0134.. Train Loss: 0.0039.. Train Acc: 0.9997.. Validation Loss: 1.8146.. Validation Acc: 0.6047\n",
            "Epoch 197/300.. Learning rate: 0.0132.. Train Loss: 0.0039.. Train Acc: 0.9996.. Validation Loss: 1.8035.. Validation Acc: 0.6037\n",
            "Epoch 198/300.. Learning rate: 0.0130.. Train Loss: 0.0037.. Train Acc: 0.9997.. Validation Loss: 1.8076.. Validation Acc: 0.6033\n",
            "Epoch 199/300.. Learning rate: 0.0127.. Train Loss: 0.0037.. Train Acc: 0.9997.. Validation Loss: 1.8045.. Validation Acc: 0.6064\n",
            "Epoch 200/300.. Learning rate: 0.0125.. Train Loss: 0.0040.. Train Acc: 0.9996.. Validation Loss: 1.8066.. Validation Acc: 0.6058\n",
            "Epoch 201/300.. Learning rate: 0.0123.. Train Loss: 0.0040.. Train Acc: 0.9996.. Validation Loss: 1.8007.. Validation Acc: 0.6054\n",
            "Epoch 202/300.. Learning rate: 0.0121.. Train Loss: 0.0041.. Train Acc: 0.9996.. Validation Loss: 1.7796.. Validation Acc: 0.6075\n",
            "Epoch 203/300.. Learning rate: 0.0118.. Train Loss: 0.0041.. Train Acc: 0.9995.. Validation Loss: 1.7802.. Validation Acc: 0.6104\n",
            "Epoch 204/300.. Learning rate: 0.0116.. Train Loss: 0.0040.. Train Acc: 0.9995.. Validation Loss: 1.8109.. Validation Acc: 0.6046\n",
            "Epoch 205/300.. Learning rate: 0.0114.. Train Loss: 0.0040.. Train Acc: 0.9996.. Validation Loss: 1.8019.. Validation Acc: 0.6042\n",
            "Epoch 206/300.. Learning rate: 0.0112.. Train Loss: 0.0039.. Train Acc: 0.9996.. Validation Loss: 1.8032.. Validation Acc: 0.6039\n",
            "Epoch 207/300.. Learning rate: 0.0110.. Train Loss: 0.0040.. Train Acc: 0.9996.. Validation Loss: 1.7826.. Validation Acc: 0.6072\n",
            "Epoch 208/300.. Learning rate: 0.0107.. Train Loss: 0.0039.. Train Acc: 0.9997.. Validation Loss: 1.7936.. Validation Acc: 0.6070\n",
            "Epoch 209/300.. Learning rate: 0.0105.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.7928.. Validation Acc: 0.6060\n",
            "Epoch 210/300.. Learning rate: 0.0103.. Train Loss: 0.0039.. Train Acc: 0.9996.. Validation Loss: 1.7909.. Validation Acc: 0.6047\n",
            "Epoch 211/300.. Learning rate: 0.0101.. Train Loss: 0.0039.. Train Acc: 0.9996.. Validation Loss: 1.7916.. Validation Acc: 0.6044\n",
            "Epoch 212/300.. Learning rate: 0.0099.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.7753.. Validation Acc: 0.6101\n",
            "Epoch 213/300.. Learning rate: 0.0097.. Train Loss: 0.0037.. Train Acc: 0.9996.. Validation Loss: 1.7671.. Validation Acc: 0.6100\n",
            "Epoch 214/300.. Learning rate: 0.0095.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.7720.. Validation Acc: 0.6070\n",
            "Epoch 215/300.. Learning rate: 0.0093.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.7697.. Validation Acc: 0.6081\n",
            "Epoch 216/300.. Learning rate: 0.0091.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.7780.. Validation Acc: 0.6069\n",
            "Epoch 217/300.. Learning rate: 0.0089.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.7905.. Validation Acc: 0.6048\n",
            "Epoch 218/300.. Learning rate: 0.0087.. Train Loss: 0.0038.. Train Acc: 0.9996.. Validation Loss: 1.7646.. Validation Acc: 0.6074\n",
            "Epoch 219/300.. Learning rate: 0.0085.. Train Loss: 0.0039.. Train Acc: 0.9996.. Validation Loss: 1.7687.. Validation Acc: 0.6101\n",
            "Epoch 220/300.. Learning rate: 0.0083.. Train Loss: 0.0037.. Train Acc: 0.9998.. Validation Loss: 1.7864.. Validation Acc: 0.6061\n",
            "Epoch 221/300.. Learning rate: 0.0081.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.7702.. Validation Acc: 0.6041\n",
            "Epoch 222/300.. Learning rate: 0.0079.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.7764.. Validation Acc: 0.6023\n",
            "Epoch 223/300.. Learning rate: 0.0077.. Train Loss: 0.0037.. Train Acc: 0.9997.. Validation Loss: 1.7646.. Validation Acc: 0.6067\n",
            "Epoch 224/300.. Learning rate: 0.0075.. Train Loss: 0.0036.. Train Acc: 0.9997.. Validation Loss: 1.7640.. Validation Acc: 0.6117\n",
            "Epoch 225/300.. Learning rate: 0.0073.. Train Loss: 0.0037.. Train Acc: 0.9997.. Validation Loss: 1.7669.. Validation Acc: 0.6053\n",
            "Epoch 226/300.. Learning rate: 0.0071.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.7815.. Validation Acc: 0.6052\n",
            "Epoch 227/300.. Learning rate: 0.0070.. Train Loss: 0.0039.. Train Acc: 0.9996.. Validation Loss: 1.7849.. Validation Acc: 0.6044\n",
            "Epoch 228/300.. Learning rate: 0.0068.. Train Loss: 0.0037.. Train Acc: 0.9998.. Validation Loss: 1.7566.. Validation Acc: 0.6099\n",
            "Epoch 229/300.. Learning rate: 0.0066.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.7705.. Validation Acc: 0.6083\n",
            "Epoch 230/300.. Learning rate: 0.0064.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.7701.. Validation Acc: 0.6061\n",
            "Epoch 231/300.. Learning rate: 0.0062.. Train Loss: 0.0037.. Train Acc: 0.9997.. Validation Loss: 1.7663.. Validation Acc: 0.6094\n",
            "Epoch 232/300.. Learning rate: 0.0061.. Train Loss: 0.0038.. Train Acc: 0.9997.. Validation Loss: 1.7618.. Validation Acc: 0.6093\n",
            "Epoch 233/300.. Learning rate: 0.0059.. Train Loss: 0.0037.. Train Acc: 0.9996.. Validation Loss: 1.7711.. Validation Acc: 0.6118\n",
            "Epoch 234/300.. Learning rate: 0.0057.. Train Loss: 0.0037.. Train Acc: 0.9997.. Validation Loss: 1.7463.. Validation Acc: 0.6093\n",
            "Epoch 235/300.. Learning rate: 0.0056.. Train Loss: 0.0036.. Train Acc: 0.9997.. Validation Loss: 1.7678.. Validation Acc: 0.6073\n",
            "Epoch 236/300.. Learning rate: 0.0054.. Train Loss: 0.0036.. Train Acc: 0.9997.. Validation Loss: 1.7738.. Validation Acc: 0.6062\n",
            "Epoch 237/300.. Learning rate: 0.0052.. Train Loss: 0.0036.. Train Acc: 0.9997.. Validation Loss: 1.7628.. Validation Acc: 0.6040\n",
            "Epoch 238/300.. Learning rate: 0.0051.. Train Loss: 0.0036.. Train Acc: 0.9997.. Validation Loss: 1.7673.. Validation Acc: 0.6072\n",
            "Epoch 239/300.. Learning rate: 0.0049.. Train Loss: 0.0037.. Train Acc: 0.9997.. Validation Loss: 1.7602.. Validation Acc: 0.6075\n",
            "Epoch 240/300.. Learning rate: 0.0048.. Train Loss: 0.0036.. Train Acc: 0.9997.. Validation Loss: 1.7560.. Validation Acc: 0.6088\n",
            "Epoch 241/300.. Learning rate: 0.0046.. Train Loss: 0.0036.. Train Acc: 0.9998.. Validation Loss: 1.7593.. Validation Acc: 0.6062\n",
            "Epoch 242/300.. Learning rate: 0.0045.. Train Loss: 0.0035.. Train Acc: 0.9997.. Validation Loss: 1.7605.. Validation Acc: 0.6095\n",
            "Epoch 243/300.. Learning rate: 0.0043.. Train Loss: 0.0036.. Train Acc: 0.9997.. Validation Loss: 1.7446.. Validation Acc: 0.6065\n",
            "Epoch 244/300.. Learning rate: 0.0042.. Train Loss: 0.0035.. Train Acc: 0.9999.. Validation Loss: 1.7528.. Validation Acc: 0.6062\n",
            "Epoch 245/300.. Learning rate: 0.0040.. Train Loss: 0.0036.. Train Acc: 0.9997.. Validation Loss: 1.7647.. Validation Acc: 0.6038\n",
            "Epoch 246/300.. Learning rate: 0.0039.. Train Loss: 0.0035.. Train Acc: 0.9997.. Validation Loss: 1.7632.. Validation Acc: 0.6095\n",
            "Epoch 247/300.. Learning rate: 0.0038.. Train Loss: 0.0035.. Train Acc: 0.9998.. Validation Loss: 1.7690.. Validation Acc: 0.6098\n",
            "Epoch 248/300.. Learning rate: 0.0036.. Train Loss: 0.0036.. Train Acc: 0.9998.. Validation Loss: 1.7545.. Validation Acc: 0.6073\n",
            "Epoch 249/300.. Learning rate: 0.0035.. Train Loss: 0.0035.. Train Acc: 0.9998.. Validation Loss: 1.7600.. Validation Acc: 0.6078\n",
            "Epoch 250/300.. Learning rate: 0.0034.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7591.. Validation Acc: 0.6058\n",
            "Epoch 251/300.. Learning rate: 0.0032.. Train Loss: 0.0035.. Train Acc: 0.9998.. Validation Loss: 1.7586.. Validation Acc: 0.6102\n",
            "Epoch 252/300.. Learning rate: 0.0031.. Train Loss: 0.0036.. Train Acc: 0.9998.. Validation Loss: 1.7576.. Validation Acc: 0.6064\n",
            "Epoch 253/300.. Learning rate: 0.0030.. Train Loss: 0.0036.. Train Acc: 0.9997.. Validation Loss: 1.7624.. Validation Acc: 0.6068\n",
            "Epoch 254/300.. Learning rate: 0.0028.. Train Loss: 0.0036.. Train Acc: 0.9997.. Validation Loss: 1.7599.. Validation Acc: 0.6064\n",
            "Epoch 255/300.. Learning rate: 0.0027.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7526.. Validation Acc: 0.6055\n",
            "Epoch 256/300.. Learning rate: 0.0026.. Train Loss: 0.0035.. Train Acc: 0.9998.. Validation Loss: 1.7445.. Validation Acc: 0.6108\n",
            "Epoch 257/300.. Learning rate: 0.0025.. Train Loss: 0.0035.. Train Acc: 0.9998.. Validation Loss: 1.7505.. Validation Acc: 0.6094\n",
            "Epoch 258/300.. Learning rate: 0.0024.. Train Loss: 0.0036.. Train Acc: 0.9996.. Validation Loss: 1.7483.. Validation Acc: 0.6099\n",
            "Epoch 259/300.. Learning rate: 0.0023.. Train Loss: 0.0036.. Train Acc: 0.9997.. Validation Loss: 1.7479.. Validation Acc: 0.6082\n",
            "Epoch 260/300.. Learning rate: 0.0022.. Train Loss: 0.0035.. Train Acc: 0.9998.. Validation Loss: 1.7373.. Validation Acc: 0.6108\n",
            "Epoch 261/300.. Learning rate: 0.0021.. Train Loss: 0.0035.. Train Acc: 0.9998.. Validation Loss: 1.7454.. Validation Acc: 0.6112\n",
            "Epoch 262/300.. Learning rate: 0.0020.. Train Loss: 0.0037.. Train Acc: 0.9998.. Validation Loss: 1.7446.. Validation Acc: 0.6083\n",
            "Epoch 263/300.. Learning rate: 0.0019.. Train Loss: 0.0035.. Train Acc: 0.9997.. Validation Loss: 1.7439.. Validation Acc: 0.6084\n",
            "Epoch 264/300.. Learning rate: 0.0018.. Train Loss: 0.0035.. Train Acc: 0.9999.. Validation Loss: 1.7286.. Validation Acc: 0.6106\n",
            "Epoch 265/300.. Learning rate: 0.0017.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7498.. Validation Acc: 0.6064\n",
            "Epoch 266/300.. Learning rate: 0.0016.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7453.. Validation Acc: 0.6082\n",
            "Epoch 267/300.. Learning rate: 0.0015.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7478.. Validation Acc: 0.6119\n",
            "Epoch 268/300.. Learning rate: 0.0014.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7561.. Validation Acc: 0.6100\n",
            "Epoch 269/300.. Learning rate: 0.0013.. Train Loss: 0.0034.. Train Acc: 0.9999.. Validation Loss: 1.7503.. Validation Acc: 0.6095\n",
            "Epoch 270/300.. Learning rate: 0.0012.. Train Loss: 0.0033.. Train Acc: 0.9998.. Validation Loss: 1.7414.. Validation Acc: 0.6077\n",
            "Epoch 271/300.. Learning rate: 0.0011.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7491.. Validation Acc: 0.6069\n",
            "Epoch 272/300.. Learning rate: 0.0011.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7555.. Validation Acc: 0.6112\n",
            "Epoch 273/300.. Learning rate: 0.0010.. Train Loss: 0.0035.. Train Acc: 0.9998.. Validation Loss: 1.7424.. Validation Acc: 0.6096\n",
            "Epoch 274/300.. Learning rate: 0.0009.. Train Loss: 0.0034.. Train Acc: 0.9997.. Validation Loss: 1.7437.. Validation Acc: 0.6117\n",
            "Epoch 275/300.. Learning rate: 0.0009.. Train Loss: 0.0035.. Train Acc: 0.9997.. Validation Loss: 1.7520.. Validation Acc: 0.6087\n",
            "Epoch 276/300.. Learning rate: 0.0008.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7506.. Validation Acc: 0.6105\n",
            "Epoch 277/300.. Learning rate: 0.0007.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7549.. Validation Acc: 0.6081\n",
            "Epoch 278/300.. Learning rate: 0.0007.. Train Loss: 0.0034.. Train Acc: 0.9997.. Validation Loss: 1.7454.. Validation Acc: 0.6067\n",
            "Epoch 279/300.. Learning rate: 0.0006.. Train Loss: 0.0033.. Train Acc: 0.9998.. Validation Loss: 1.7325.. Validation Acc: 0.6092\n",
            "Epoch 280/300.. Learning rate: 0.0005.. Train Loss: 0.0033.. Train Acc: 0.9999.. Validation Loss: 1.7414.. Validation Acc: 0.6090\n",
            "Epoch 281/300.. Learning rate: 0.0005.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7540.. Validation Acc: 0.6086\n",
            "Epoch 282/300.. Learning rate: 0.0004.. Train Loss: 0.0034.. Train Acc: 0.9997.. Validation Loss: 1.7459.. Validation Acc: 0.6141\n",
            "Epoch 283/300.. Learning rate: 0.0004.. Train Loss: 0.0034.. Train Acc: 0.9997.. Validation Loss: 1.7455.. Validation Acc: 0.6081\n",
            "Epoch 284/300.. Learning rate: 0.0004.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7665.. Validation Acc: 0.6075\n",
            "Epoch 285/300.. Learning rate: 0.0003.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7435.. Validation Acc: 0.6130\n",
            "Epoch 286/300.. Learning rate: 0.0003.. Train Loss: 0.0034.. Train Acc: 0.9997.. Validation Loss: 1.7436.. Validation Acc: 0.6081\n",
            "Epoch 287/300.. Learning rate: 0.0002.. Train Loss: 0.0033.. Train Acc: 0.9999.. Validation Loss: 1.7430.. Validation Acc: 0.6090\n",
            "Epoch 288/300.. Learning rate: 0.0002.. Train Loss: 0.0033.. Train Acc: 0.9999.. Validation Loss: 1.7492.. Validation Acc: 0.6084\n",
            "Epoch 289/300.. Learning rate: 0.0002.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7569.. Validation Acc: 0.6031\n",
            "Epoch 290/300.. Learning rate: 0.0001.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7425.. Validation Acc: 0.6073\n",
            "Epoch 291/300.. Learning rate: 0.0001.. Train Loss: 0.0033.. Train Acc: 0.9998.. Validation Loss: 1.7533.. Validation Acc: 0.6081\n",
            "Epoch 292/300.. Learning rate: 0.0001.. Train Loss: 0.0033.. Train Acc: 0.9998.. Validation Loss: 1.7551.. Validation Acc: 0.6067\n",
            "Epoch 293/300.. Learning rate: 0.0001.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7394.. Validation Acc: 0.6062\n",
            "Epoch 294/300.. Learning rate: 0.0001.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7465.. Validation Acc: 0.6094\n",
            "Epoch 295/300.. Learning rate: 0.0000.. Train Loss: 0.0035.. Train Acc: 0.9998.. Validation Loss: 1.7513.. Validation Acc: 0.6073\n",
            "Epoch 296/300.. Learning rate: 0.0000.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7533.. Validation Acc: 0.6087\n",
            "Epoch 297/300.. Learning rate: 0.0000.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7396.. Validation Acc: 0.6102\n",
            "Epoch 298/300.. Learning rate: 0.0000.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7605.. Validation Acc: 0.6056\n",
            "Epoch 299/300.. Learning rate: 0.0000.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7543.. Validation Acc: 0.6088\n",
            "Epoch 300/300.. Learning rate: 0.0000.. Train Loss: 0.0034.. Train Acc: 0.9998.. Validation Loss: 1.7456.. Validation Acc: 0.6058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_acc(stat_training_loss, stat_val_loss, stat_training_acc, stat_val_acc, \"weightdecay_one\")"
      ],
      "metadata": {
        "id": "0VpSSpmGIl3j"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation - Mixup"
      ],
      "metadata": {
        "id": "BTe18DW5jpE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import beta\n",
        "\n",
        "# Set the hyperparameter α\n",
        "alpha = 0.2\n",
        "\n",
        "# Define the beta distribution\n",
        "x = np.linspace(0, 1, 1000)\n",
        "pdf = beta.pdf(x, alpha, alpha)\n",
        "\n",
        "# Plot the PDF\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(x, pdf, label=f'α = {alpha}')\n",
        "plt.title('Beta Distribution PDF')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "dMChCRPSjs0B",
        "outputId": "5f432fd6-336e-400b-f295-9d1ec76b3053"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.05\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])\n",
        "    ])\n",
        "\n",
        "# Split data set\n",
        "dataset = torchvision.datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
        "num_train = len(dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(0.8 * num_train))  # 80% for training, 20% for validation\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[:split], indices[split:]\n",
        "\n",
        "train_sampler = data.sampler.SubsetRandomSampler(train_indices)\n",
        "val_sampler = data.sampler.SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=val_sampler)\n",
        "\n",
        "# model\n",
        "model = MobileNet(100)\n",
        "#print(model)\n",
        "model.cuda()\n",
        "\n",
        "# criterion\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# scheduler\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=300, eta_min=0)\n",
        "\n",
        "stat_training_loss = []\n",
        "stat_val_loss = []\n",
        "stat_training_acc = []\n",
        "stat_val_acc = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRoqgzd4pBLN",
        "outputId": "644b4671-6d46-4de1-f274-f13821344f2e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.2\n",
        "num_classes = 100\n",
        "for epoch in range(300):\n",
        "    training_loss = 0\n",
        "    training_acc = 0\n",
        "    training_samples = 0\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    val_samples = 0\n",
        "    # training\n",
        "    model.train()\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # Generate mixup factors and permute batch\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "        index = torch.randperm(imgs.size(0)).cuda()\n",
        "\n",
        "        # Convert labels to one-hot encodings\n",
        "        mixed_labels_one_hot = lam * F.one_hot(labels, num_classes=num_classes) + (1 - lam) * F.one_hot(labels[index], num_classes=num_classes)\n",
        "\n",
        "        # Convert one-hot encodings back to class indices\n",
        "        mixed_labels_indices = torch.argmax(mixed_labels_one_hot, dim=1)\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "        optimizer.zero_grad()\n",
        "        logits = model.forward(imgs)\n",
        "        loss = criterion(logits, mixed_labels_indices)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, top_class = logits.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape).long()\n",
        "        training_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        training_loss += batch_size * loss.item()\n",
        "        training_samples += batch_size\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    for val_imgs, val_labels in valid_loader:\n",
        "        batch_size = val_imgs.shape[0]\n",
        "        val_logits = model.forward(val_imgs.cuda())\n",
        "        loss = criterion(val_logits, val_labels.cuda())\n",
        "        _, top_class = val_logits.topk(1, dim=1)\n",
        "        equals = top_class == val_labels.cuda().view(*top_class.shape)\n",
        "        val_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "        val_loss += batch_size * loss.item()\n",
        "        val_samples += batch_size\n",
        "    assert val_samples == 10000\n",
        "    # update stats\n",
        "    stat_training_loss.append(training_loss/training_samples)\n",
        "    stat_val_loss.append(val_loss/val_samples)\n",
        "    stat_training_acc.append(training_acc/training_samples)\n",
        "    stat_val_acc.append(val_acc/val_samples)\n",
        "    # print\n",
        "    #print(f\"Epoch {(epoch+1):d}/{args.epochs:d}.. Learning rate: {scheduler.get_lr()[0]:.4f}.. Train loss: {(training_loss/training_samples):.4f}.. Train acc: {(training_acc/training_samples):.4f}.. Val loss: {(val_loss/val_samples):.4f}.. Val acc: {(val_acc/val_samples):.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{300}.. \"\n",
        "          f\"Learning rate: {scheduler.get_lr()[0]:.4f}.. \"\n",
        "          f\"Train Loss: {training_loss / training_samples:.4f}.. \"\n",
        "          f\"Train Acc: {training_acc / training_samples:.4f}.. \"\n",
        "          f\"Validation Loss: {val_loss / val_samples:.4f}.. \"\n",
        "          f\"Validation Acc: {val_acc / val_samples:.4f}\")\n",
        "    # lr scheduler\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHaXhD7IIR87",
        "outputId": "eeeec276-d019-4268-8e86-03d75d4c0611"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300.. Learning rate: 0.0500.. Train Loss: 4.5951.. Train Acc: 0.0328.. Validation Loss: 4.3972.. Validation Acc: 0.0571\n",
            "Epoch 2/300.. Learning rate: 0.0500.. Train Loss: 4.4889.. Train Acc: 0.0619.. Validation Loss: 4.1484.. Validation Acc: 0.0767\n",
            "Epoch 3/300.. Learning rate: 0.0500.. Train Loss: 4.4388.. Train Acc: 0.0873.. Validation Loss: 4.0449.. Validation Acc: 0.0912\n",
            "Epoch 4/300.. Learning rate: 0.0500.. Train Loss: 4.3552.. Train Acc: 0.1040.. Validation Loss: 3.9870.. Validation Acc: 0.1071\n",
            "Epoch 5/300.. Learning rate: 0.0500.. Train Loss: 4.3814.. Train Acc: 0.1270.. Validation Loss: 3.9240.. Validation Acc: 0.1169\n",
            "Epoch 6/300.. Learning rate: 0.0500.. Train Loss: 4.3675.. Train Acc: 0.1379.. Validation Loss: 3.9439.. Validation Acc: 0.1436\n",
            "Epoch 7/300.. Learning rate: 0.0499.. Train Loss: 4.3390.. Train Acc: 0.1508.. Validation Loss: 3.7883.. Validation Acc: 0.1533\n",
            "Epoch 8/300.. Learning rate: 0.0499.. Train Loss: 4.2550.. Train Acc: 0.1679.. Validation Loss: 3.6796.. Validation Acc: 0.1659\n",
            "Epoch 9/300.. Learning rate: 0.0499.. Train Loss: 4.2357.. Train Acc: 0.1784.. Validation Loss: 3.6658.. Validation Acc: 0.1581\n",
            "Epoch 10/300.. Learning rate: 0.0499.. Train Loss: 4.2937.. Train Acc: 0.1897.. Validation Loss: 3.8508.. Validation Acc: 0.1539\n",
            "Epoch 11/300.. Learning rate: 0.0498.. Train Loss: 4.2669.. Train Acc: 0.1952.. Validation Loss: 3.4872.. Validation Acc: 0.1964\n",
            "Epoch 12/300.. Learning rate: 0.0498.. Train Loss: 4.2596.. Train Acc: 0.2133.. Validation Loss: 3.6143.. Validation Acc: 0.2082\n",
            "Epoch 13/300.. Learning rate: 0.0498.. Train Loss: 4.2190.. Train Acc: 0.2262.. Validation Loss: 3.7258.. Validation Acc: 0.1767\n",
            "Epoch 14/300.. Learning rate: 0.0497.. Train Loss: 4.1274.. Train Acc: 0.2422.. Validation Loss: 3.3333.. Validation Acc: 0.2194\n",
            "Epoch 15/300.. Learning rate: 0.0497.. Train Loss: 4.1793.. Train Acc: 0.2559.. Validation Loss: 3.5002.. Validation Acc: 0.2364\n",
            "Epoch 16/300.. Learning rate: 0.0497.. Train Loss: 4.2542.. Train Acc: 0.2687.. Validation Loss: 3.4040.. Validation Acc: 0.2479\n",
            "Epoch 17/300.. Learning rate: 0.0496.. Train Loss: 4.1217.. Train Acc: 0.2768.. Validation Loss: 3.2135.. Validation Acc: 0.2582\n",
            "Epoch 18/300.. Learning rate: 0.0496.. Train Loss: 4.1177.. Train Acc: 0.2849.. Validation Loss: 3.2634.. Validation Acc: 0.2623\n",
            "Epoch 19/300.. Learning rate: 0.0495.. Train Loss: 4.0351.. Train Acc: 0.2997.. Validation Loss: 3.1133.. Validation Acc: 0.2848\n",
            "Epoch 20/300.. Learning rate: 0.0495.. Train Loss: 4.0279.. Train Acc: 0.3085.. Validation Loss: 3.1638.. Validation Acc: 0.3026\n",
            "Epoch 21/300.. Learning rate: 0.0494.. Train Loss: 4.0414.. Train Acc: 0.3209.. Validation Loss: 3.3428.. Validation Acc: 0.2538\n",
            "Epoch 22/300.. Learning rate: 0.0493.. Train Loss: 3.9523.. Train Acc: 0.3303.. Validation Loss: 3.1325.. Validation Acc: 0.2843\n",
            "Epoch 23/300.. Learning rate: 0.0493.. Train Loss: 4.0590.. Train Acc: 0.3326.. Validation Loss: 3.2591.. Validation Acc: 0.3041\n",
            "Epoch 24/300.. Learning rate: 0.0492.. Train Loss: 3.9571.. Train Acc: 0.3478.. Validation Loss: 3.1548.. Validation Acc: 0.2675\n",
            "Epoch 25/300.. Learning rate: 0.0492.. Train Loss: 3.9005.. Train Acc: 0.3504.. Validation Loss: 3.0253.. Validation Acc: 0.2983\n",
            "Epoch 26/300.. Learning rate: 0.0491.. Train Loss: 3.8798.. Train Acc: 0.3550.. Validation Loss: 3.1613.. Validation Acc: 0.2778\n",
            "Epoch 27/300.. Learning rate: 0.0490.. Train Loss: 3.9450.. Train Acc: 0.3659.. Validation Loss: 3.1035.. Validation Acc: 0.2931\n",
            "Epoch 28/300.. Learning rate: 0.0489.. Train Loss: 3.8399.. Train Acc: 0.3711.. Validation Loss: 2.9402.. Validation Acc: 0.3520\n",
            "Epoch 29/300.. Learning rate: 0.0489.. Train Loss: 3.9072.. Train Acc: 0.3761.. Validation Loss: 2.9116.. Validation Acc: 0.3210\n",
            "Epoch 30/300.. Learning rate: 0.0488.. Train Loss: 3.9411.. Train Acc: 0.3784.. Validation Loss: 3.2983.. Validation Acc: 0.2986\n",
            "Epoch 31/300.. Learning rate: 0.0487.. Train Loss: 3.9534.. Train Acc: 0.3897.. Validation Loss: 2.8447.. Validation Acc: 0.3599\n",
            "Epoch 32/300.. Learning rate: 0.0486.. Train Loss: 3.9422.. Train Acc: 0.3883.. Validation Loss: 3.1221.. Validation Acc: 0.3166\n",
            "Epoch 33/300.. Learning rate: 0.0485.. Train Loss: 3.9092.. Train Acc: 0.3837.. Validation Loss: 3.1734.. Validation Acc: 0.3266\n",
            "Epoch 34/300.. Learning rate: 0.0484.. Train Loss: 3.8393.. Train Acc: 0.3944.. Validation Loss: 2.8975.. Validation Acc: 0.3468\n",
            "Epoch 35/300.. Learning rate: 0.0483.. Train Loss: 3.9187.. Train Acc: 0.3944.. Validation Loss: 2.8799.. Validation Acc: 0.3715\n",
            "Epoch 36/300.. Learning rate: 0.0482.. Train Loss: 3.8501.. Train Acc: 0.4027.. Validation Loss: 2.9555.. Validation Acc: 0.3242\n",
            "Epoch 37/300.. Learning rate: 0.0481.. Train Loss: 3.8521.. Train Acc: 0.4046.. Validation Loss: 3.2051.. Validation Acc: 0.3479\n",
            "Epoch 38/300.. Learning rate: 0.0480.. Train Loss: 3.9788.. Train Acc: 0.4078.. Validation Loss: 2.9086.. Validation Acc: 0.3733\n",
            "Epoch 39/300.. Learning rate: 0.0479.. Train Loss: 3.9674.. Train Acc: 0.4068.. Validation Loss: 3.1949.. Validation Acc: 0.2909\n",
            "Epoch 40/300.. Learning rate: 0.0478.. Train Loss: 3.9589.. Train Acc: 0.4068.. Validation Loss: 2.9146.. Validation Acc: 0.3775\n",
            "Epoch 41/300.. Learning rate: 0.0477.. Train Loss: 3.8014.. Train Acc: 0.4173.. Validation Loss: 3.1713.. Validation Acc: 0.3331\n",
            "Epoch 42/300.. Learning rate: 0.0476.. Train Loss: 3.8863.. Train Acc: 0.4135.. Validation Loss: 3.1591.. Validation Acc: 0.3264\n",
            "Epoch 43/300.. Learning rate: 0.0475.. Train Loss: 3.8603.. Train Acc: 0.4152.. Validation Loss: 2.8769.. Validation Acc: 0.3820\n",
            "Epoch 44/300.. Learning rate: 0.0474.. Train Loss: 3.7790.. Train Acc: 0.4185.. Validation Loss: 3.1428.. Validation Acc: 0.3417\n",
            "Epoch 45/300.. Learning rate: 0.0473.. Train Loss: 3.8934.. Train Acc: 0.4160.. Validation Loss: 3.0106.. Validation Acc: 0.3352\n",
            "Epoch 46/300.. Learning rate: 0.0472.. Train Loss: 3.7631.. Train Acc: 0.4260.. Validation Loss: 2.9789.. Validation Acc: 0.3087\n",
            "Epoch 47/300.. Learning rate: 0.0470.. Train Loss: 3.8264.. Train Acc: 0.4176.. Validation Loss: 2.9026.. Validation Acc: 0.3606\n",
            "Epoch 48/300.. Learning rate: 0.0469.. Train Loss: 3.8437.. Train Acc: 0.4324.. Validation Loss: 2.5980.. Validation Acc: 0.4099\n",
            "Epoch 49/300.. Learning rate: 0.0468.. Train Loss: 3.8356.. Train Acc: 0.4293.. Validation Loss: 2.7246.. Validation Acc: 0.3695\n",
            "Epoch 50/300.. Learning rate: 0.0467.. Train Loss: 3.7656.. Train Acc: 0.4250.. Validation Loss: 2.8304.. Validation Acc: 0.3535\n",
            "Epoch 51/300.. Learning rate: 0.0465.. Train Loss: 3.8118.. Train Acc: 0.4341.. Validation Loss: 2.7113.. Validation Acc: 0.3768\n",
            "Epoch 52/300.. Learning rate: 0.0464.. Train Loss: 3.8772.. Train Acc: 0.4410.. Validation Loss: 2.6626.. Validation Acc: 0.3947\n",
            "Epoch 53/300.. Learning rate: 0.0463.. Train Loss: 3.8243.. Train Acc: 0.4425.. Validation Loss: 2.8049.. Validation Acc: 0.3835\n",
            "Epoch 54/300.. Learning rate: 0.0461.. Train Loss: 3.8825.. Train Acc: 0.4392.. Validation Loss: 2.7835.. Validation Acc: 0.3889\n",
            "Epoch 55/300.. Learning rate: 0.0460.. Train Loss: 3.8807.. Train Acc: 0.4390.. Validation Loss: 2.9554.. Validation Acc: 0.3993\n",
            "Epoch 56/300.. Learning rate: 0.0458.. Train Loss: 3.9202.. Train Acc: 0.4448.. Validation Loss: 2.6855.. Validation Acc: 0.3857\n",
            "Epoch 57/300.. Learning rate: 0.0457.. Train Loss: 3.7774.. Train Acc: 0.4298.. Validation Loss: 2.8231.. Validation Acc: 0.3644\n",
            "Epoch 58/300.. Learning rate: 0.0455.. Train Loss: 3.7829.. Train Acc: 0.4420.. Validation Loss: 2.8286.. Validation Acc: 0.3857\n",
            "Epoch 59/300.. Learning rate: 0.0454.. Train Loss: 3.7749.. Train Acc: 0.4422.. Validation Loss: 2.9805.. Validation Acc: 0.3689\n",
            "Epoch 60/300.. Learning rate: 0.0452.. Train Loss: 3.7226.. Train Acc: 0.4526.. Validation Loss: 2.5660.. Validation Acc: 0.4038\n",
            "Epoch 61/300.. Learning rate: 0.0451.. Train Loss: 3.8770.. Train Acc: 0.4464.. Validation Loss: 2.6885.. Validation Acc: 0.4052\n",
            "Epoch 62/300.. Learning rate: 0.0449.. Train Loss: 3.6537.. Train Acc: 0.4540.. Validation Loss: 2.8031.. Validation Acc: 0.3629\n",
            "Epoch 63/300.. Learning rate: 0.0448.. Train Loss: 3.7632.. Train Acc: 0.4558.. Validation Loss: 2.6267.. Validation Acc: 0.3782\n",
            "Epoch 64/300.. Learning rate: 0.0446.. Train Loss: 3.7101.. Train Acc: 0.4549.. Validation Loss: 2.5967.. Validation Acc: 0.4096\n",
            "Epoch 65/300.. Learning rate: 0.0444.. Train Loss: 3.8958.. Train Acc: 0.4577.. Validation Loss: 2.5650.. Validation Acc: 0.4230\n",
            "Epoch 66/300.. Learning rate: 0.0443.. Train Loss: 3.8683.. Train Acc: 0.4535.. Validation Loss: 2.7008.. Validation Acc: 0.4264\n",
            "Epoch 67/300.. Learning rate: 0.0441.. Train Loss: 3.8096.. Train Acc: 0.4602.. Validation Loss: 2.7369.. Validation Acc: 0.3827\n",
            "Epoch 68/300.. Learning rate: 0.0439.. Train Loss: 3.8401.. Train Acc: 0.4502.. Validation Loss: 2.5833.. Validation Acc: 0.4165\n",
            "Epoch 69/300.. Learning rate: 0.0438.. Train Loss: 3.9396.. Train Acc: 0.4530.. Validation Loss: 2.9958.. Validation Acc: 0.3737\n",
            "Epoch 70/300.. Learning rate: 0.0436.. Train Loss: 3.7885.. Train Acc: 0.4571.. Validation Loss: 2.7445.. Validation Acc: 0.4065\n",
            "Epoch 71/300.. Learning rate: 0.0434.. Train Loss: 3.9067.. Train Acc: 0.4577.. Validation Loss: 2.7060.. Validation Acc: 0.4124\n",
            "Epoch 72/300.. Learning rate: 0.0432.. Train Loss: 3.7274.. Train Acc: 0.4585.. Validation Loss: 2.5341.. Validation Acc: 0.4173\n",
            "Epoch 73/300.. Learning rate: 0.0430.. Train Loss: 3.9430.. Train Acc: 0.4547.. Validation Loss: 3.0482.. Validation Acc: 0.3799\n",
            "Epoch 74/300.. Learning rate: 0.0429.. Train Loss: 3.7446.. Train Acc: 0.4625.. Validation Loss: 2.7007.. Validation Acc: 0.3901\n",
            "Epoch 75/300.. Learning rate: 0.0427.. Train Loss: 3.7715.. Train Acc: 0.4625.. Validation Loss: 3.0780.. Validation Acc: 0.3052\n",
            "Epoch 76/300.. Learning rate: 0.0425.. Train Loss: 3.8609.. Train Acc: 0.4635.. Validation Loss: 2.6618.. Validation Acc: 0.4311\n",
            "Epoch 77/300.. Learning rate: 0.0423.. Train Loss: 3.8063.. Train Acc: 0.4666.. Validation Loss: 2.6697.. Validation Acc: 0.4095\n",
            "Epoch 78/300.. Learning rate: 0.0421.. Train Loss: 3.7084.. Train Acc: 0.4644.. Validation Loss: 2.6912.. Validation Acc: 0.4211\n",
            "Epoch 79/300.. Learning rate: 0.0419.. Train Loss: 3.7847.. Train Acc: 0.4705.. Validation Loss: 2.7171.. Validation Acc: 0.3849\n",
            "Epoch 80/300.. Learning rate: 0.0417.. Train Loss: 3.8367.. Train Acc: 0.4679.. Validation Loss: 2.7404.. Validation Acc: 0.4038\n",
            "Epoch 81/300.. Learning rate: 0.0415.. Train Loss: 3.7315.. Train Acc: 0.4714.. Validation Loss: 2.4607.. Validation Acc: 0.4338\n",
            "Epoch 82/300.. Learning rate: 0.0413.. Train Loss: 3.8553.. Train Acc: 0.4694.. Validation Loss: 2.7881.. Validation Acc: 0.3657\n",
            "Epoch 83/300.. Learning rate: 0.0411.. Train Loss: 3.6758.. Train Acc: 0.4707.. Validation Loss: 2.8072.. Validation Acc: 0.3838\n",
            "Epoch 84/300.. Learning rate: 0.0409.. Train Loss: 3.7660.. Train Acc: 0.4775.. Validation Loss: 2.7210.. Validation Acc: 0.3799\n",
            "Epoch 85/300.. Learning rate: 0.0407.. Train Loss: 3.7694.. Train Acc: 0.4733.. Validation Loss: 2.6606.. Validation Acc: 0.4002\n",
            "Epoch 86/300.. Learning rate: 0.0405.. Train Loss: 3.7657.. Train Acc: 0.4751.. Validation Loss: 3.0403.. Validation Acc: 0.3744\n",
            "Epoch 87/300.. Learning rate: 0.0403.. Train Loss: 3.7903.. Train Acc: 0.4757.. Validation Loss: 2.6317.. Validation Acc: 0.4218\n",
            "Epoch 88/300.. Learning rate: 0.0401.. Train Loss: 3.8988.. Train Acc: 0.4742.. Validation Loss: 3.1577.. Validation Acc: 0.3478\n",
            "Epoch 89/300.. Learning rate: 0.0399.. Train Loss: 3.7535.. Train Acc: 0.4758.. Validation Loss: 2.5342.. Validation Acc: 0.4363\n",
            "Epoch 90/300.. Learning rate: 0.0397.. Train Loss: 3.7455.. Train Acc: 0.4801.. Validation Loss: 2.8010.. Validation Acc: 0.3547\n",
            "Epoch 91/300.. Learning rate: 0.0395.. Train Loss: 3.8320.. Train Acc: 0.4792.. Validation Loss: 2.6652.. Validation Acc: 0.4421\n",
            "Epoch 92/300.. Learning rate: 0.0393.. Train Loss: 3.7818.. Train Acc: 0.4844.. Validation Loss: 2.6259.. Validation Acc: 0.4360\n",
            "Epoch 93/300.. Learning rate: 0.0391.. Train Loss: 3.7270.. Train Acc: 0.4852.. Validation Loss: 2.7143.. Validation Acc: 0.4383\n",
            "Epoch 94/300.. Learning rate: 0.0388.. Train Loss: 3.9298.. Train Acc: 0.4850.. Validation Loss: 2.9072.. Validation Acc: 0.3636\n",
            "Epoch 95/300.. Learning rate: 0.0386.. Train Loss: 3.7590.. Train Acc: 0.4871.. Validation Loss: 2.5680.. Validation Acc: 0.4216\n",
            "Epoch 96/300.. Learning rate: 0.0384.. Train Loss: 3.5943.. Train Acc: 0.4847.. Validation Loss: 2.7340.. Validation Acc: 0.3858\n",
            "Epoch 97/300.. Learning rate: 0.0382.. Train Loss: 3.7431.. Train Acc: 0.4757.. Validation Loss: 2.6054.. Validation Acc: 0.4392\n",
            "Epoch 98/300.. Learning rate: 0.0380.. Train Loss: 3.8788.. Train Acc: 0.4926.. Validation Loss: 3.0352.. Validation Acc: 0.3623\n",
            "Epoch 99/300.. Learning rate: 0.0377.. Train Loss: 3.7554.. Train Acc: 0.4907.. Validation Loss: 2.6065.. Validation Acc: 0.4054\n",
            "Epoch 100/300.. Learning rate: 0.0375.. Train Loss: 3.7536.. Train Acc: 0.4867.. Validation Loss: 2.6193.. Validation Acc: 0.4259\n",
            "Epoch 101/300.. Learning rate: 0.0373.. Train Loss: 3.8087.. Train Acc: 0.4868.. Validation Loss: 2.8134.. Validation Acc: 0.4285\n",
            "Epoch 102/300.. Learning rate: 0.0370.. Train Loss: 3.6837.. Train Acc: 0.4877.. Validation Loss: 2.5634.. Validation Acc: 0.4288\n",
            "Epoch 103/300.. Learning rate: 0.0368.. Train Loss: 3.8096.. Train Acc: 0.4940.. Validation Loss: 2.5722.. Validation Acc: 0.4495\n",
            "Epoch 104/300.. Learning rate: 0.0366.. Train Loss: 3.7734.. Train Acc: 0.4970.. Validation Loss: 2.5489.. Validation Acc: 0.4422\n",
            "Epoch 105/300.. Learning rate: 0.0364.. Train Loss: 3.8752.. Train Acc: 0.4942.. Validation Loss: 2.5303.. Validation Acc: 0.4467\n",
            "Epoch 106/300.. Learning rate: 0.0361.. Train Loss: 3.7540.. Train Acc: 0.4965.. Validation Loss: 2.7601.. Validation Acc: 0.4312\n",
            "Epoch 107/300.. Learning rate: 0.0359.. Train Loss: 3.8585.. Train Acc: 0.4908.. Validation Loss: 2.6167.. Validation Acc: 0.4424\n",
            "Epoch 108/300.. Learning rate: 0.0356.. Train Loss: 3.6774.. Train Acc: 0.4996.. Validation Loss: 2.4371.. Validation Acc: 0.4383\n",
            "Epoch 109/300.. Learning rate: 0.0354.. Train Loss: 3.8129.. Train Acc: 0.4953.. Validation Loss: 2.5756.. Validation Acc: 0.4476\n",
            "Epoch 110/300.. Learning rate: 0.0352.. Train Loss: 3.7705.. Train Acc: 0.4951.. Validation Loss: 2.6679.. Validation Acc: 0.4195\n",
            "Epoch 111/300.. Learning rate: 0.0349.. Train Loss: 3.6621.. Train Acc: 0.4964.. Validation Loss: 2.4928.. Validation Acc: 0.4256\n",
            "Epoch 112/300.. Learning rate: 0.0347.. Train Loss: 3.7507.. Train Acc: 0.4965.. Validation Loss: 2.6167.. Validation Acc: 0.4230\n",
            "Epoch 113/300.. Learning rate: 0.0344.. Train Loss: 3.8299.. Train Acc: 0.5062.. Validation Loss: 2.5108.. Validation Acc: 0.4423\n",
            "Epoch 114/300.. Learning rate: 0.0342.. Train Loss: 3.7027.. Train Acc: 0.5014.. Validation Loss: 2.6971.. Validation Acc: 0.4094\n",
            "Epoch 115/300.. Learning rate: 0.0340.. Train Loss: 3.8572.. Train Acc: 0.4995.. Validation Loss: 2.5611.. Validation Acc: 0.4303\n",
            "Epoch 116/300.. Learning rate: 0.0337.. Train Loss: 3.8174.. Train Acc: 0.5062.. Validation Loss: 2.4894.. Validation Acc: 0.4481\n",
            "Epoch 117/300.. Learning rate: 0.0335.. Train Loss: 3.6677.. Train Acc: 0.5070.. Validation Loss: 2.6944.. Validation Acc: 0.4178\n",
            "Epoch 118/300.. Learning rate: 0.0332.. Train Loss: 3.7121.. Train Acc: 0.5107.. Validation Loss: 2.7101.. Validation Acc: 0.4005\n",
            "Epoch 119/300.. Learning rate: 0.0330.. Train Loss: 3.7220.. Train Acc: 0.5100.. Validation Loss: 2.5754.. Validation Acc: 0.4324\n",
            "Epoch 120/300.. Learning rate: 0.0327.. Train Loss: 3.6625.. Train Acc: 0.5099.. Validation Loss: 2.5943.. Validation Acc: 0.4335\n",
            "Epoch 121/300.. Learning rate: 0.0325.. Train Loss: 3.6653.. Train Acc: 0.5057.. Validation Loss: 2.5234.. Validation Acc: 0.4489\n",
            "Epoch 122/300.. Learning rate: 0.0322.. Train Loss: 3.7231.. Train Acc: 0.5091.. Validation Loss: 2.4959.. Validation Acc: 0.4515\n",
            "Epoch 123/300.. Learning rate: 0.0320.. Train Loss: 3.7920.. Train Acc: 0.5134.. Validation Loss: 2.5890.. Validation Acc: 0.4286\n",
            "Epoch 124/300.. Learning rate: 0.0317.. Train Loss: 3.7379.. Train Acc: 0.5199.. Validation Loss: 2.4410.. Validation Acc: 0.4639\n",
            "Epoch 125/300.. Learning rate: 0.0315.. Train Loss: 3.7534.. Train Acc: 0.5175.. Validation Loss: 2.4584.. Validation Acc: 0.4705\n",
            "Epoch 126/300.. Learning rate: 0.0312.. Train Loss: 3.6982.. Train Acc: 0.5145.. Validation Loss: 2.5908.. Validation Acc: 0.4643\n",
            "Epoch 127/300.. Learning rate: 0.0310.. Train Loss: 3.7293.. Train Acc: 0.5271.. Validation Loss: 2.3925.. Validation Acc: 0.4497\n",
            "Epoch 128/300.. Learning rate: 0.0307.. Train Loss: 3.6088.. Train Acc: 0.5208.. Validation Loss: 2.3137.. Validation Acc: 0.4646\n",
            "Epoch 129/300.. Learning rate: 0.0305.. Train Loss: 3.8025.. Train Acc: 0.5167.. Validation Loss: 2.6350.. Validation Acc: 0.4695\n",
            "Epoch 130/300.. Learning rate: 0.0302.. Train Loss: 3.7785.. Train Acc: 0.5277.. Validation Loss: 2.6468.. Validation Acc: 0.4507\n",
            "Epoch 131/300.. Learning rate: 0.0299.. Train Loss: 3.6415.. Train Acc: 0.5246.. Validation Loss: 2.4286.. Validation Acc: 0.4679\n",
            "Epoch 132/300.. Learning rate: 0.0297.. Train Loss: 3.6907.. Train Acc: 0.5235.. Validation Loss: 2.4484.. Validation Acc: 0.4668\n",
            "Epoch 133/300.. Learning rate: 0.0294.. Train Loss: 3.8251.. Train Acc: 0.5229.. Validation Loss: 2.4238.. Validation Acc: 0.4856\n",
            "Epoch 134/300.. Learning rate: 0.0292.. Train Loss: 3.7186.. Train Acc: 0.5302.. Validation Loss: 2.6360.. Validation Acc: 0.4660\n",
            "Epoch 135/300.. Learning rate: 0.0289.. Train Loss: 3.5067.. Train Acc: 0.5292.. Validation Loss: 2.5629.. Validation Acc: 0.4349\n",
            "Epoch 136/300.. Learning rate: 0.0287.. Train Loss: 3.6708.. Train Acc: 0.5375.. Validation Loss: 2.4433.. Validation Acc: 0.4660\n",
            "Epoch 137/300.. Learning rate: 0.0284.. Train Loss: 3.7447.. Train Acc: 0.5403.. Validation Loss: 2.4335.. Validation Acc: 0.4740\n",
            "Epoch 138/300.. Learning rate: 0.0281.. Train Loss: 3.6617.. Train Acc: 0.5401.. Validation Loss: 2.4245.. Validation Acc: 0.4620\n",
            "Epoch 139/300.. Learning rate: 0.0279.. Train Loss: 3.6822.. Train Acc: 0.5382.. Validation Loss: 2.4035.. Validation Acc: 0.4981\n",
            "Epoch 140/300.. Learning rate: 0.0276.. Train Loss: 3.7982.. Train Acc: 0.5376.. Validation Loss: 2.5016.. Validation Acc: 0.4664\n",
            "Epoch 141/300.. Learning rate: 0.0274.. Train Loss: 3.6922.. Train Acc: 0.5390.. Validation Loss: 2.3523.. Validation Acc: 0.4951\n",
            "Epoch 142/300.. Learning rate: 0.0271.. Train Loss: 3.7247.. Train Acc: 0.5400.. Validation Loss: 2.7591.. Validation Acc: 0.4494\n",
            "Epoch 143/300.. Learning rate: 0.0268.. Train Loss: 3.6572.. Train Acc: 0.5419.. Validation Loss: 2.3685.. Validation Acc: 0.4737\n",
            "Epoch 144/300.. Learning rate: 0.0266.. Train Loss: 3.5932.. Train Acc: 0.5434.. Validation Loss: 2.2325.. Validation Acc: 0.4894\n",
            "Epoch 145/300.. Learning rate: 0.0263.. Train Loss: 3.7276.. Train Acc: 0.5382.. Validation Loss: 2.4212.. Validation Acc: 0.4920\n",
            "Epoch 146/300.. Learning rate: 0.0260.. Train Loss: 3.7659.. Train Acc: 0.5461.. Validation Loss: 2.4859.. Validation Acc: 0.4749\n",
            "Epoch 147/300.. Learning rate: 0.0258.. Train Loss: 3.7059.. Train Acc: 0.5489.. Validation Loss: 2.4579.. Validation Acc: 0.4977\n",
            "Epoch 148/300.. Learning rate: 0.0255.. Train Loss: 3.8641.. Train Acc: 0.5422.. Validation Loss: 2.7893.. Validation Acc: 0.4505\n",
            "Epoch 149/300.. Learning rate: 0.0253.. Train Loss: 3.5907.. Train Acc: 0.5495.. Validation Loss: 2.3099.. Validation Acc: 0.4955\n",
            "Epoch 150/300.. Learning rate: 0.0250.. Train Loss: 3.6048.. Train Acc: 0.5526.. Validation Loss: 2.6410.. Validation Acc: 0.4464\n",
            "Epoch 151/300.. Learning rate: 0.0247.. Train Loss: 3.6972.. Train Acc: 0.5502.. Validation Loss: 2.4026.. Validation Acc: 0.4893\n",
            "Epoch 152/300.. Learning rate: 0.0245.. Train Loss: 3.6647.. Train Acc: 0.5560.. Validation Loss: 2.2471.. Validation Acc: 0.4990\n",
            "Epoch 153/300.. Learning rate: 0.0242.. Train Loss: 3.6025.. Train Acc: 0.5575.. Validation Loss: 2.4230.. Validation Acc: 0.4790\n",
            "Epoch 154/300.. Learning rate: 0.0240.. Train Loss: 3.4861.. Train Acc: 0.5606.. Validation Loss: 2.4105.. Validation Acc: 0.4641\n",
            "Epoch 155/300.. Learning rate: 0.0237.. Train Loss: 3.6183.. Train Acc: 0.5586.. Validation Loss: 2.2537.. Validation Acc: 0.5029\n",
            "Epoch 156/300.. Learning rate: 0.0234.. Train Loss: 3.6296.. Train Acc: 0.5587.. Validation Loss: 2.4335.. Validation Acc: 0.4788\n",
            "Epoch 157/300.. Learning rate: 0.0232.. Train Loss: 3.7311.. Train Acc: 0.5686.. Validation Loss: 2.6747.. Validation Acc: 0.4709\n",
            "Epoch 158/300.. Learning rate: 0.0229.. Train Loss: 3.4999.. Train Acc: 0.5712.. Validation Loss: 2.1294.. Validation Acc: 0.5131\n",
            "Epoch 159/300.. Learning rate: 0.0227.. Train Loss: 3.7335.. Train Acc: 0.5706.. Validation Loss: 2.3182.. Validation Acc: 0.5147\n",
            "Epoch 160/300.. Learning rate: 0.0224.. Train Loss: 3.7158.. Train Acc: 0.5713.. Validation Loss: 2.6986.. Validation Acc: 0.4597\n",
            "Epoch 161/300.. Learning rate: 0.0221.. Train Loss: 3.5427.. Train Acc: 0.5734.. Validation Loss: 2.4753.. Validation Acc: 0.4889\n",
            "Epoch 162/300.. Learning rate: 0.0219.. Train Loss: 3.3912.. Train Acc: 0.5677.. Validation Loss: 2.2783.. Validation Acc: 0.4977\n",
            "Epoch 163/300.. Learning rate: 0.0216.. Train Loss: 3.6750.. Train Acc: 0.5728.. Validation Loss: 2.3615.. Validation Acc: 0.5110\n",
            "Epoch 164/300.. Learning rate: 0.0214.. Train Loss: 3.5839.. Train Acc: 0.5836.. Validation Loss: 2.4610.. Validation Acc: 0.4599\n",
            "Epoch 165/300.. Learning rate: 0.0211.. Train Loss: 3.6418.. Train Acc: 0.5771.. Validation Loss: 2.1858.. Validation Acc: 0.5120\n",
            "Epoch 166/300.. Learning rate: 0.0208.. Train Loss: 3.6052.. Train Acc: 0.5796.. Validation Loss: 2.2447.. Validation Acc: 0.5166\n",
            "Epoch 167/300.. Learning rate: 0.0206.. Train Loss: 3.6985.. Train Acc: 0.5816.. Validation Loss: 2.2849.. Validation Acc: 0.5201\n",
            "Epoch 168/300.. Learning rate: 0.0203.. Train Loss: 3.5440.. Train Acc: 0.5828.. Validation Loss: 2.3253.. Validation Acc: 0.5145\n",
            "Epoch 169/300.. Learning rate: 0.0201.. Train Loss: 3.6480.. Train Acc: 0.5849.. Validation Loss: 2.5199.. Validation Acc: 0.5139\n",
            "Epoch 170/300.. Learning rate: 0.0198.. Train Loss: 3.6022.. Train Acc: 0.5884.. Validation Loss: 2.4203.. Validation Acc: 0.4949\n",
            "Epoch 171/300.. Learning rate: 0.0195.. Train Loss: 3.5783.. Train Acc: 0.5900.. Validation Loss: 2.1710.. Validation Acc: 0.5336\n",
            "Epoch 172/300.. Learning rate: 0.0193.. Train Loss: 3.5040.. Train Acc: 0.5897.. Validation Loss: 2.2146.. Validation Acc: 0.5224\n",
            "Epoch 173/300.. Learning rate: 0.0190.. Train Loss: 3.6036.. Train Acc: 0.5917.. Validation Loss: 2.5315.. Validation Acc: 0.5230\n",
            "Epoch 174/300.. Learning rate: 0.0188.. Train Loss: 3.5583.. Train Acc: 0.5971.. Validation Loss: 2.1487.. Validation Acc: 0.5181\n",
            "Epoch 175/300.. Learning rate: 0.0185.. Train Loss: 3.5844.. Train Acc: 0.5929.. Validation Loss: 2.1270.. Validation Acc: 0.5232\n",
            "Epoch 176/300.. Learning rate: 0.0183.. Train Loss: 3.5455.. Train Acc: 0.5997.. Validation Loss: 2.2395.. Validation Acc: 0.5320\n",
            "Epoch 177/300.. Learning rate: 0.0180.. Train Loss: 3.4776.. Train Acc: 0.6024.. Validation Loss: 2.2779.. Validation Acc: 0.5227\n",
            "Epoch 178/300.. Learning rate: 0.0178.. Train Loss: 3.6723.. Train Acc: 0.6065.. Validation Loss: 2.3076.. Validation Acc: 0.5294\n",
            "Epoch 179/300.. Learning rate: 0.0175.. Train Loss: 3.6594.. Train Acc: 0.5978.. Validation Loss: 2.1743.. Validation Acc: 0.5420\n",
            "Epoch 180/300.. Learning rate: 0.0173.. Train Loss: 3.4594.. Train Acc: 0.6082.. Validation Loss: 2.0652.. Validation Acc: 0.5404\n",
            "Epoch 181/300.. Learning rate: 0.0170.. Train Loss: 3.6377.. Train Acc: 0.6076.. Validation Loss: 2.4276.. Validation Acc: 0.5230\n",
            "Epoch 182/300.. Learning rate: 0.0168.. Train Loss: 3.4280.. Train Acc: 0.6077.. Validation Loss: 2.3316.. Validation Acc: 0.4972\n",
            "Epoch 183/300.. Learning rate: 0.0165.. Train Loss: 3.5035.. Train Acc: 0.6120.. Validation Loss: 2.3243.. Validation Acc: 0.5109\n",
            "Epoch 184/300.. Learning rate: 0.0163.. Train Loss: 3.5649.. Train Acc: 0.6180.. Validation Loss: 2.1722.. Validation Acc: 0.5360\n",
            "Epoch 185/300.. Learning rate: 0.0160.. Train Loss: 3.6112.. Train Acc: 0.6191.. Validation Loss: 2.2191.. Validation Acc: 0.5349\n",
            "Epoch 186/300.. Learning rate: 0.0158.. Train Loss: 3.6453.. Train Acc: 0.6206.. Validation Loss: 2.3232.. Validation Acc: 0.5450\n",
            "Epoch 187/300.. Learning rate: 0.0156.. Train Loss: 3.6334.. Train Acc: 0.6228.. Validation Loss: 2.1368.. Validation Acc: 0.5457\n",
            "Epoch 188/300.. Learning rate: 0.0153.. Train Loss: 3.5248.. Train Acc: 0.6216.. Validation Loss: 2.2482.. Validation Acc: 0.5463\n",
            "Epoch 189/300.. Learning rate: 0.0151.. Train Loss: 3.5963.. Train Acc: 0.6270.. Validation Loss: 2.0833.. Validation Acc: 0.5493\n",
            "Epoch 190/300.. Learning rate: 0.0148.. Train Loss: 3.4677.. Train Acc: 0.6286.. Validation Loss: 2.2301.. Validation Acc: 0.5588\n",
            "Epoch 191/300.. Learning rate: 0.0146.. Train Loss: 3.4726.. Train Acc: 0.6282.. Validation Loss: 2.1280.. Validation Acc: 0.5586\n",
            "Epoch 192/300.. Learning rate: 0.0144.. Train Loss: 3.5073.. Train Acc: 0.6337.. Validation Loss: 2.1664.. Validation Acc: 0.5520\n",
            "Epoch 193/300.. Learning rate: 0.0141.. Train Loss: 3.4106.. Train Acc: 0.6343.. Validation Loss: 2.3358.. Validation Acc: 0.5143\n",
            "Epoch 194/300.. Learning rate: 0.0139.. Train Loss: 3.6075.. Train Acc: 0.6341.. Validation Loss: 2.1353.. Validation Acc: 0.5457\n",
            "Epoch 195/300.. Learning rate: 0.0137.. Train Loss: 3.4965.. Train Acc: 0.6408.. Validation Loss: 2.1986.. Validation Acc: 0.5448\n",
            "Epoch 196/300.. Learning rate: 0.0134.. Train Loss: 3.5302.. Train Acc: 0.6422.. Validation Loss: 2.0559.. Validation Acc: 0.5647\n",
            "Epoch 197/300.. Learning rate: 0.0132.. Train Loss: 3.5060.. Train Acc: 0.6453.. Validation Loss: 2.0823.. Validation Acc: 0.5425\n",
            "Epoch 198/300.. Learning rate: 0.0130.. Train Loss: 3.5041.. Train Acc: 0.6448.. Validation Loss: 1.9432.. Validation Acc: 0.5650\n",
            "Epoch 199/300.. Learning rate: 0.0127.. Train Loss: 3.5006.. Train Acc: 0.6456.. Validation Loss: 2.0026.. Validation Acc: 0.5690\n",
            "Epoch 200/300.. Learning rate: 0.0125.. Train Loss: 3.5919.. Train Acc: 0.6512.. Validation Loss: 2.2056.. Validation Acc: 0.5487\n",
            "Epoch 201/300.. Learning rate: 0.0123.. Train Loss: 3.4412.. Train Acc: 0.6558.. Validation Loss: 2.1841.. Validation Acc: 0.5252\n",
            "Epoch 202/300.. Learning rate: 0.0121.. Train Loss: 3.6749.. Train Acc: 0.6458.. Validation Loss: 2.2041.. Validation Acc: 0.5638\n",
            "Epoch 203/300.. Learning rate: 0.0118.. Train Loss: 3.3141.. Train Acc: 0.6580.. Validation Loss: 2.0024.. Validation Acc: 0.5637\n",
            "Epoch 204/300.. Learning rate: 0.0116.. Train Loss: 3.2873.. Train Acc: 0.6647.. Validation Loss: 2.0010.. Validation Acc: 0.5597\n",
            "Epoch 205/300.. Learning rate: 0.0114.. Train Loss: 3.6401.. Train Acc: 0.6609.. Validation Loss: 2.2325.. Validation Acc: 0.5750\n",
            "Epoch 206/300.. Learning rate: 0.0112.. Train Loss: 3.3179.. Train Acc: 0.6662.. Validation Loss: 2.1550.. Validation Acc: 0.5639\n",
            "Epoch 207/300.. Learning rate: 0.0110.. Train Loss: 3.5686.. Train Acc: 0.6693.. Validation Loss: 2.1266.. Validation Acc: 0.5662\n",
            "Epoch 208/300.. Learning rate: 0.0107.. Train Loss: 3.6241.. Train Acc: 0.6742.. Validation Loss: 2.3695.. Validation Acc: 0.5527\n",
            "Epoch 209/300.. Learning rate: 0.0105.. Train Loss: 3.5106.. Train Acc: 0.6736.. Validation Loss: 2.0450.. Validation Acc: 0.5779\n",
            "Epoch 210/300.. Learning rate: 0.0103.. Train Loss: 3.3956.. Train Acc: 0.6714.. Validation Loss: 2.0490.. Validation Acc: 0.5693\n",
            "Epoch 211/300.. Learning rate: 0.0101.. Train Loss: 3.4760.. Train Acc: 0.6787.. Validation Loss: 2.0773.. Validation Acc: 0.5677\n",
            "Epoch 212/300.. Learning rate: 0.0099.. Train Loss: 3.3833.. Train Acc: 0.6787.. Validation Loss: 2.0484.. Validation Acc: 0.5861\n",
            "Epoch 213/300.. Learning rate: 0.0097.. Train Loss: 3.5180.. Train Acc: 0.6833.. Validation Loss: 2.1379.. Validation Acc: 0.5736\n",
            "Epoch 214/300.. Learning rate: 0.0095.. Train Loss: 3.4370.. Train Acc: 0.6897.. Validation Loss: 2.0720.. Validation Acc: 0.5770\n",
            "Epoch 215/300.. Learning rate: 0.0093.. Train Loss: 3.4520.. Train Acc: 0.6897.. Validation Loss: 2.0255.. Validation Acc: 0.5803\n",
            "Epoch 216/300.. Learning rate: 0.0091.. Train Loss: 3.5143.. Train Acc: 0.6945.. Validation Loss: 2.0418.. Validation Acc: 0.5766\n",
            "Epoch 217/300.. Learning rate: 0.0089.. Train Loss: 3.6499.. Train Acc: 0.6911.. Validation Loss: 2.1156.. Validation Acc: 0.5784\n",
            "Epoch 218/300.. Learning rate: 0.0087.. Train Loss: 3.3769.. Train Acc: 0.7014.. Validation Loss: 2.0839.. Validation Acc: 0.5809\n",
            "Epoch 219/300.. Learning rate: 0.0085.. Train Loss: 3.4337.. Train Acc: 0.6956.. Validation Loss: 2.0513.. Validation Acc: 0.5769\n",
            "Epoch 220/300.. Learning rate: 0.0083.. Train Loss: 3.3259.. Train Acc: 0.7050.. Validation Loss: 2.0596.. Validation Acc: 0.5752\n",
            "Epoch 221/300.. Learning rate: 0.0081.. Train Loss: 3.5061.. Train Acc: 0.7029.. Validation Loss: 2.0203.. Validation Acc: 0.5841\n",
            "Epoch 222/300.. Learning rate: 0.0079.. Train Loss: 3.3925.. Train Acc: 0.7141.. Validation Loss: 1.9751.. Validation Acc: 0.5863\n",
            "Epoch 223/300.. Learning rate: 0.0077.. Train Loss: 3.4108.. Train Acc: 0.7142.. Validation Loss: 1.9631.. Validation Acc: 0.5783\n",
            "Epoch 224/300.. Learning rate: 0.0075.. Train Loss: 3.6057.. Train Acc: 0.7125.. Validation Loss: 2.2051.. Validation Acc: 0.5796\n",
            "Epoch 225/300.. Learning rate: 0.0073.. Train Loss: 3.5251.. Train Acc: 0.7190.. Validation Loss: 2.0220.. Validation Acc: 0.6019\n",
            "Epoch 226/300.. Learning rate: 0.0071.. Train Loss: 3.1821.. Train Acc: 0.7210.. Validation Loss: 1.9429.. Validation Acc: 0.5940\n",
            "Epoch 227/300.. Learning rate: 0.0070.. Train Loss: 3.4252.. Train Acc: 0.7239.. Validation Loss: 1.9190.. Validation Acc: 0.5983\n",
            "Epoch 228/300.. Learning rate: 0.0068.. Train Loss: 3.2110.. Train Acc: 0.7329.. Validation Loss: 1.9175.. Validation Acc: 0.6051\n",
            "Epoch 229/300.. Learning rate: 0.0066.. Train Loss: 3.4588.. Train Acc: 0.7298.. Validation Loss: 2.1017.. Validation Acc: 0.5898\n",
            "Epoch 230/300.. Learning rate: 0.0064.. Train Loss: 3.3933.. Train Acc: 0.7339.. Validation Loss: 2.1733.. Validation Acc: 0.5856\n",
            "Epoch 231/300.. Learning rate: 0.0062.. Train Loss: 3.3603.. Train Acc: 0.7385.. Validation Loss: 2.0142.. Validation Acc: 0.6000\n",
            "Epoch 232/300.. Learning rate: 0.0061.. Train Loss: 3.2905.. Train Acc: 0.7393.. Validation Loss: 2.0560.. Validation Acc: 0.5971\n",
            "Epoch 233/300.. Learning rate: 0.0059.. Train Loss: 3.3291.. Train Acc: 0.7448.. Validation Loss: 2.0448.. Validation Acc: 0.5945\n",
            "Epoch 234/300.. Learning rate: 0.0057.. Train Loss: 3.4618.. Train Acc: 0.7471.. Validation Loss: 1.9576.. Validation Acc: 0.6098\n",
            "Epoch 235/300.. Learning rate: 0.0056.. Train Loss: 3.3583.. Train Acc: 0.7528.. Validation Loss: 1.9205.. Validation Acc: 0.6076\n",
            "Epoch 236/300.. Learning rate: 0.0054.. Train Loss: 3.2200.. Train Acc: 0.7534.. Validation Loss: 1.8478.. Validation Acc: 0.6122\n",
            "Epoch 237/300.. Learning rate: 0.0052.. Train Loss: 3.2747.. Train Acc: 0.7588.. Validation Loss: 1.9595.. Validation Acc: 0.6091\n",
            "Epoch 238/300.. Learning rate: 0.0051.. Train Loss: 3.1915.. Train Acc: 0.7615.. Validation Loss: 1.9259.. Validation Acc: 0.6049\n",
            "Epoch 239/300.. Learning rate: 0.0049.. Train Loss: 3.3176.. Train Acc: 0.7657.. Validation Loss: 1.8246.. Validation Acc: 0.6120\n",
            "Epoch 240/300.. Learning rate: 0.0048.. Train Loss: 3.2967.. Train Acc: 0.7649.. Validation Loss: 1.8925.. Validation Acc: 0.6134\n",
            "Epoch 241/300.. Learning rate: 0.0046.. Train Loss: 3.3345.. Train Acc: 0.7735.. Validation Loss: 1.8718.. Validation Acc: 0.6168\n",
            "Epoch 242/300.. Learning rate: 0.0045.. Train Loss: 3.2076.. Train Acc: 0.7775.. Validation Loss: 1.7903.. Validation Acc: 0.6189\n",
            "Epoch 243/300.. Learning rate: 0.0043.. Train Loss: 3.0860.. Train Acc: 0.7809.. Validation Loss: 1.8838.. Validation Acc: 0.6105\n",
            "Epoch 244/300.. Learning rate: 0.0042.. Train Loss: 3.3682.. Train Acc: 0.7809.. Validation Loss: 1.9769.. Validation Acc: 0.6225\n",
            "Epoch 245/300.. Learning rate: 0.0040.. Train Loss: 3.2754.. Train Acc: 0.7879.. Validation Loss: 1.9055.. Validation Acc: 0.6162\n",
            "Epoch 246/300.. Learning rate: 0.0039.. Train Loss: 3.2749.. Train Acc: 0.7911.. Validation Loss: 1.8110.. Validation Acc: 0.6271\n",
            "Epoch 247/300.. Learning rate: 0.0038.. Train Loss: 3.4082.. Train Acc: 0.7910.. Validation Loss: 1.9104.. Validation Acc: 0.6176\n",
            "Epoch 248/300.. Learning rate: 0.0036.. Train Loss: 3.1276.. Train Acc: 0.7985.. Validation Loss: 1.8722.. Validation Acc: 0.6196\n",
            "Epoch 249/300.. Learning rate: 0.0035.. Train Loss: 3.3150.. Train Acc: 0.7983.. Validation Loss: 1.8447.. Validation Acc: 0.6233\n",
            "Epoch 250/300.. Learning rate: 0.0034.. Train Loss: 3.4443.. Train Acc: 0.8058.. Validation Loss: 1.9331.. Validation Acc: 0.6248\n",
            "Epoch 251/300.. Learning rate: 0.0032.. Train Loss: 3.2766.. Train Acc: 0.8099.. Validation Loss: 1.8736.. Validation Acc: 0.6290\n",
            "Epoch 252/300.. Learning rate: 0.0031.. Train Loss: 3.2603.. Train Acc: 0.8121.. Validation Loss: 1.8876.. Validation Acc: 0.6299\n",
            "Epoch 253/300.. Learning rate: 0.0030.. Train Loss: 3.3618.. Train Acc: 0.8136.. Validation Loss: 1.9857.. Validation Acc: 0.6319\n",
            "Epoch 254/300.. Learning rate: 0.0028.. Train Loss: 3.2642.. Train Acc: 0.8218.. Validation Loss: 1.7998.. Validation Acc: 0.6382\n",
            "Epoch 255/300.. Learning rate: 0.0027.. Train Loss: 3.2430.. Train Acc: 0.8217.. Validation Loss: 1.9300.. Validation Acc: 0.6273\n",
            "Epoch 256/300.. Learning rate: 0.0026.. Train Loss: 3.0994.. Train Acc: 0.8240.. Validation Loss: 1.8246.. Validation Acc: 0.6340\n",
            "Epoch 257/300.. Learning rate: 0.0025.. Train Loss: 3.2057.. Train Acc: 0.8318.. Validation Loss: 1.8357.. Validation Acc: 0.6341\n",
            "Epoch 258/300.. Learning rate: 0.0024.. Train Loss: 3.0532.. Train Acc: 0.8355.. Validation Loss: 1.7141.. Validation Acc: 0.6375\n",
            "Epoch 259/300.. Learning rate: 0.0023.. Train Loss: 3.2238.. Train Acc: 0.8386.. Validation Loss: 1.8112.. Validation Acc: 0.6323\n",
            "Epoch 260/300.. Learning rate: 0.0022.. Train Loss: 3.3058.. Train Acc: 0.8407.. Validation Loss: 1.8492.. Validation Acc: 0.6393\n",
            "Epoch 261/300.. Learning rate: 0.0021.. Train Loss: 3.3416.. Train Acc: 0.8475.. Validation Loss: 1.8407.. Validation Acc: 0.6352\n",
            "Epoch 262/300.. Learning rate: 0.0020.. Train Loss: 3.2753.. Train Acc: 0.8459.. Validation Loss: 1.8437.. Validation Acc: 0.6356\n",
            "Epoch 263/300.. Learning rate: 0.0019.. Train Loss: 3.1620.. Train Acc: 0.8532.. Validation Loss: 1.8582.. Validation Acc: 0.6370\n",
            "Epoch 264/300.. Learning rate: 0.0018.. Train Loss: 3.0962.. Train Acc: 0.8557.. Validation Loss: 1.9020.. Validation Acc: 0.6379\n",
            "Epoch 265/300.. Learning rate: 0.0017.. Train Loss: 3.5063.. Train Acc: 0.8572.. Validation Loss: 1.9947.. Validation Acc: 0.6318\n",
            "Epoch 266/300.. Learning rate: 0.0016.. Train Loss: 3.2235.. Train Acc: 0.8628.. Validation Loss: 1.8484.. Validation Acc: 0.6436\n",
            "Epoch 267/300.. Learning rate: 0.0015.. Train Loss: 2.9814.. Train Acc: 0.8642.. Validation Loss: 1.8246.. Validation Acc: 0.6372\n",
            "Epoch 268/300.. Learning rate: 0.0014.. Train Loss: 3.2215.. Train Acc: 0.8693.. Validation Loss: 1.8976.. Validation Acc: 0.6397\n",
            "Epoch 269/300.. Learning rate: 0.0013.. Train Loss: 3.3549.. Train Acc: 0.8711.. Validation Loss: 1.8526.. Validation Acc: 0.6470\n",
            "Epoch 270/300.. Learning rate: 0.0012.. Train Loss: 3.1865.. Train Acc: 0.8742.. Validation Loss: 1.9073.. Validation Acc: 0.6474\n",
            "Epoch 271/300.. Learning rate: 0.0011.. Train Loss: 3.0679.. Train Acc: 0.8778.. Validation Loss: 1.8483.. Validation Acc: 0.6454\n",
            "Epoch 272/300.. Learning rate: 0.0011.. Train Loss: 3.2351.. Train Acc: 0.8809.. Validation Loss: 1.7930.. Validation Acc: 0.6479\n",
            "Epoch 273/300.. Learning rate: 0.0010.. Train Loss: 3.1033.. Train Acc: 0.8811.. Validation Loss: 1.8036.. Validation Acc: 0.6462\n",
            "Epoch 274/300.. Learning rate: 0.0009.. Train Loss: 3.1060.. Train Acc: 0.8863.. Validation Loss: 1.8114.. Validation Acc: 0.6451\n",
            "Epoch 275/300.. Learning rate: 0.0009.. Train Loss: 3.3228.. Train Acc: 0.8880.. Validation Loss: 1.8601.. Validation Acc: 0.6419\n",
            "Epoch 276/300.. Learning rate: 0.0008.. Train Loss: 3.0764.. Train Acc: 0.8898.. Validation Loss: 1.8443.. Validation Acc: 0.6479\n",
            "Epoch 277/300.. Learning rate: 0.0007.. Train Loss: 3.0540.. Train Acc: 0.8921.. Validation Loss: 1.7813.. Validation Acc: 0.6482\n",
            "Epoch 278/300.. Learning rate: 0.0007.. Train Loss: 3.0598.. Train Acc: 0.8950.. Validation Loss: 1.7858.. Validation Acc: 0.6508\n",
            "Epoch 279/300.. Learning rate: 0.0006.. Train Loss: 3.1833.. Train Acc: 0.8986.. Validation Loss: 1.8535.. Validation Acc: 0.6472\n",
            "Epoch 280/300.. Learning rate: 0.0005.. Train Loss: 2.9623.. Train Acc: 0.8993.. Validation Loss: 1.7767.. Validation Acc: 0.6500\n",
            "Epoch 281/300.. Learning rate: 0.0005.. Train Loss: 3.1389.. Train Acc: 0.9011.. Validation Loss: 1.7760.. Validation Acc: 0.6528\n",
            "Epoch 282/300.. Learning rate: 0.0004.. Train Loss: 3.1907.. Train Acc: 0.9036.. Validation Loss: 1.8421.. Validation Acc: 0.6521\n",
            "Epoch 283/300.. Learning rate: 0.0004.. Train Loss: 3.2039.. Train Acc: 0.9064.. Validation Loss: 1.8760.. Validation Acc: 0.6479\n",
            "Epoch 284/300.. Learning rate: 0.0004.. Train Loss: 3.1319.. Train Acc: 0.9076.. Validation Loss: 1.8288.. Validation Acc: 0.6561\n",
            "Epoch 285/300.. Learning rate: 0.0003.. Train Loss: 3.2016.. Train Acc: 0.9093.. Validation Loss: 1.8584.. Validation Acc: 0.6492\n",
            "Epoch 286/300.. Learning rate: 0.0003.. Train Loss: 3.2585.. Train Acc: 0.9104.. Validation Loss: 1.8711.. Validation Acc: 0.6481\n",
            "Epoch 287/300.. Learning rate: 0.0002.. Train Loss: 3.3183.. Train Acc: 0.9132.. Validation Loss: 1.8888.. Validation Acc: 0.6544\n",
            "Epoch 288/300.. Learning rate: 0.0002.. Train Loss: 3.1197.. Train Acc: 0.9120.. Validation Loss: 1.8538.. Validation Acc: 0.6518\n",
            "Epoch 289/300.. Learning rate: 0.0002.. Train Loss: 3.2779.. Train Acc: 0.9119.. Validation Loss: 1.8758.. Validation Acc: 0.6514\n",
            "Epoch 290/300.. Learning rate: 0.0001.. Train Loss: 2.9989.. Train Acc: 0.9149.. Validation Loss: 1.8239.. Validation Acc: 0.6543\n",
            "Epoch 291/300.. Learning rate: 0.0001.. Train Loss: 3.1191.. Train Acc: 0.9131.. Validation Loss: 1.8371.. Validation Acc: 0.6535\n",
            "Epoch 292/300.. Learning rate: 0.0001.. Train Loss: 3.1517.. Train Acc: 0.9142.. Validation Loss: 1.8300.. Validation Acc: 0.6568\n",
            "Epoch 293/300.. Learning rate: 0.0001.. Train Loss: 3.0853.. Train Acc: 0.9149.. Validation Loss: 1.8370.. Validation Acc: 0.6523\n",
            "Epoch 294/300.. Learning rate: 0.0001.. Train Loss: 3.4871.. Train Acc: 0.9147.. Validation Loss: 1.8682.. Validation Acc: 0.6544\n",
            "Epoch 295/300.. Learning rate: 0.0000.. Train Loss: 3.2898.. Train Acc: 0.9186.. Validation Loss: 1.8654.. Validation Acc: 0.6544\n",
            "Epoch 296/300.. Learning rate: 0.0000.. Train Loss: 3.1626.. Train Acc: 0.9170.. Validation Loss: 1.8573.. Validation Acc: 0.6573\n",
            "Epoch 297/300.. Learning rate: 0.0000.. Train Loss: 3.2052.. Train Acc: 0.9163.. Validation Loss: 1.8704.. Validation Acc: 0.6537\n",
            "Epoch 298/300.. Learning rate: 0.0000.. Train Loss: 3.1560.. Train Acc: 0.9181.. Validation Loss: 1.8681.. Validation Acc: 0.6526\n",
            "Epoch 299/300.. Learning rate: 0.0000.. Train Loss: 3.0011.. Train Acc: 0.9185.. Validation Loss: 1.8631.. Validation Acc: 0.6557\n",
            "Epoch 300/300.. Learning rate: 0.0000.. Train Loss: 3.0548.. Train Acc: 0.9166.. Validation Loss: 1.8675.. Validation Acc: 0.6556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_acc(stat_training_loss, stat_val_loss, stat_training_acc, stat_val_acc, \"mixup_2\")"
      ],
      "metadata": {
        "id": "J4_p0uNApA_W"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Set"
      ],
      "metadata": {
        "id": "6-S33dwBFO6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test dataset\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])\n",
        "    ])\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, transform=test_transform, download=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "test_acc = 0\n",
        "test_samples = 0\n",
        "\n",
        "for test_imgs, test_labels in test_loader:\n",
        "    batch_size = test_imgs.shape[0]\n",
        "    with torch.no_grad():\n",
        "        test_logits = model(test_imgs.cuda())\n",
        "    _, top_class = test_logits.topk(1, dim=1)\n",
        "    equals = top_class == test_labels.cuda().view(*top_class.shape)\n",
        "    test_acc += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "    test_samples += batch_size\n",
        "\n",
        "assert test_samples == len(test_loader.dataset)\n",
        "\n",
        "# Calculate and print the test accuracy\n",
        "test_accuracy = test_acc / test_samples\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V28VWBRYFOoi",
        "outputId": "f37b4175-3825-4be5-f12f-c46b073a772c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Test Accuracy: 0.6511\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}